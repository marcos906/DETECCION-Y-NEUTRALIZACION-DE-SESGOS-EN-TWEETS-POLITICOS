{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4379f134-6c43-4425-b5c6-3bbbe6230a90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cargados 500 tweets de tweets_griegos_stanza_1_500.json\n",
      "Cargados 500 tweets de tweets_griegos_stanza_501_1000.json\n",
      "Total combinado: 1000 tweets\n",
      "✅ Todos los tweets guardados en tweets_españoles_evaluados_completo.json\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Archivos de entrada\n",
    "input_files = [\n",
    "    \"tweets_griegos_stanza_1_500.json\",\n",
    "    \"tweets_griegos_stanza_501_1000.json\"\n",
    "]\n",
    "output_file = \"tweets_españoles_evaluados_completo.json\"\n",
    "\n",
    "all_tweets = []\n",
    "\n",
    "for path in input_files:\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        data = json.load(f)\n",
    "        print(f\"Cargados {len(data)} tweets de {path}\")\n",
    "        # Asegurarse de que 'data' es una lista\n",
    "        if isinstance(data, list):\n",
    "            all_tweets.extend(data)\n",
    "        else:\n",
    "            raise ValueError(f\"El archivo {path} no contiene una lista de tweets.\")\n",
    "\n",
    "print(f\"Total combinado: {len(all_tweets)} tweets\")\n",
    "\n",
    "# Guardar resultado\n",
    "with open(output_file, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(all_tweets, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "print(f\"✅ Todos los tweets guardados en {output_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f95bf344-ea12-47d0-8540-55f8cfefc285",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Metadatos añadidos a 1000 tweets. Archivo guardado en 'tweets_griegos_con_meta.json'.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import csv\n",
    "\n",
    "# 1) Rutas de entrada y salida\n",
    "json_input  = \"tweets_griegos_evaluados_completo.json\"\n",
    "csv_input   = \"grecia_anotados/gr_combined.csv\"                # CSV con columnas: id, label, annotator\n",
    "json_output = \"tweets_griegos_con_meta.json\"\n",
    "\n",
    "# 2) Leer registros del CSV\n",
    "records = []\n",
    "with open(csv_input, newline='', encoding='utf-8') as f:\n",
    "    reader = csv.DictReader(f)\n",
    "    for row in reader:\n",
    "        records.append(row)\n",
    "\n",
    "# 3) Cargar el JSON combinado\n",
    "with open(json_input, \"r\", encoding=\"utf-8\") as f:\n",
    "    tweets = json.load(f)\n",
    "\n",
    "# 4) Verificar que coincidan en longitud\n",
    "if len(records) != len(tweets):\n",
    "    raise ValueError(f\"El CSV tiene {len(records)} filas, pero el JSON tiene {len(tweets)} tweets.\")\n",
    "\n",
    "# 5) Asignar id, label y annotator\n",
    "for rec, tweet in zip(records, tweets):\n",
    "    tweet[\"id\"]        = rec[\"id\"]\n",
    "    tweet[\"label\"]     = rec.get(\"label\")\n",
    "    tweet[\"annotator\"] = rec.get(\"annotator\")\n",
    "\n",
    "# 6) Guardar el JSON resultante\n",
    "with open(json_output, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(tweets, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "print(f\"✅ Metadatos añadidos a {len(tweets)} tweets. Archivo guardado en '{json_output}'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e13d15fe-cd88-4c17-8045-005a78500ec8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de tweets: 1000\n",
      "Número total de replies: 3082\n",
      "Media de replies por tweet: 3.08\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "INPUT_JSON = 'spain/Completado/tweets_españoles_evaluados_completo.json'\n",
    "\n",
    "# Cargar archivo JSON\n",
    "with open(INPUT_JSON, 'r', encoding='utf-8') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# Número de tweets\n",
    "num_tweets = len(data)\n",
    "\n",
    "# Número total de replies\n",
    "total_replies = sum(len(item.get('replies', [])) for item in data)\n",
    "\n",
    "# Media de replies por tweet\n",
    "avg_replies = total_replies / num_tweets if num_tweets > 0 else 0\n",
    "\n",
    "print(f\"Número de tweets: {num_tweets}\")\n",
    "print(f\"Número total de replies: {total_replies}\")\n",
    "print(f\"Media de replies por tweet: {avg_replies:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "36e31b26-ed9a-4117-b897-e1159be37b30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Guardados 172 usuarios únicos con tweets en 'users_españoles.json'.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import unicodedata\n",
    "from collections import defaultdict\n",
    "\n",
    "# Rutas de entrada y salida\n",
    "input_path = \"spain/Completado/tweets_españoles_evaluados_completo.json\"\n",
    "output_path = \"users_españoles.json\"\n",
    "\n",
    "# Función para normalizar nombres\n",
    "def normalize_name(name):\n",
    "    name = name.lower().strip()\n",
    "    name = unicodedata.normalize('NFKD', name)\n",
    "    name = ''.join(c for c in name if not unicodedata.combining(c))\n",
    "    name = name.replace(\"(\", \"\").replace(\")\", \"\")\n",
    "    return \" \".join(name.split())\n",
    "\n",
    "# Carga de tweets\n",
    "with open(input_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# Para evitar duplicados y asociar tweet IDs\n",
    "users_dict = {}\n",
    "seen_usernames = set()\n",
    "\n",
    "# Para agrupar los tweet IDs por usuario original (raw_user)\n",
    "user_to_ids = defaultdict(list)\n",
    "\n",
    "for item in data:\n",
    "    raw_user = item.get(\"user\", \"\").strip()\n",
    "    tweet_id = item.get(\"id\")\n",
    "    party = item.get(\"mp_party\")\n",
    "\n",
    "    if not raw_user or raw_user.startswith(\"Error al extraer usuario\"):\n",
    "        continue\n",
    "\n",
    "    # Extraer nombre y @usuario\n",
    "    if \"\\n\" in raw_user:\n",
    "        lines = [line.strip() for line in raw_user.splitlines() if line.strip()]\n",
    "        if len(lines) >= 2 and lines[-1].startswith(\"@\"):\n",
    "            name = \" \".join(lines[:-1])\n",
    "            username = lines[-1]\n",
    "        else:\n",
    "            continue\n",
    "    else:\n",
    "        tokens = raw_user.split()\n",
    "        username = None\n",
    "        for t in reversed(tokens):\n",
    "            if t.startswith(\"@\"):\n",
    "                username = t\n",
    "                break\n",
    "        if username:\n",
    "            name = raw_user[: raw_user.rfind(username)].strip()\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "    # Agregar tweet ID\n",
    "    if tweet_id:\n",
    "        user_to_ids[username].append(tweet_id)\n",
    "\n",
    "    # Si ya se procesó este username, solo agregamos el tweet\n",
    "    if username in seen_usernames:\n",
    "        continue\n",
    "\n",
    "    seen_usernames.add(username)\n",
    "    users_dict[username] = {\n",
    "        \"name\": name,\n",
    "        \"user\": username,\n",
    "        \"party\": party,\n",
    "        \"normalized_name\": normalize_name(name),\n",
    "        \"tweet_ids\": []  # se añadirá más abajo\n",
    "    }\n",
    "\n",
    "# Añadir los IDs recolectados\n",
    "for username, tweet_ids in user_to_ids.items():\n",
    "    if username in users_dict:\n",
    "        users_dict[username][\"tweet_ids\"] = tweet_ids\n",
    "\n",
    "# Exportar a JSON\n",
    "users = list(users_dict.values())\n",
    "with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(users, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "print(f\"✅ Guardados {len(users)} usuarios únicos con tweets en '{output_path}'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8e9149f2-7351-4e43-94e5-3b1f7e578e4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Asignados 1000 IDs. Salvo en 'Tweets_españoles_id.json'.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import re\n",
    "\n",
    "# 1) Rutas de tus archivos\n",
    "json_input  = \"tweets_españoles_anotados_finales.json\"     # tu JSON sin IDs\n",
    "txt_input   = \"tweets_id.txt\"          # el archivo de log con \"Procesando tweet ID: <id>\"\n",
    "json_output = \"Tweets_españoles_id.json\"     # salida con IDs asignados\n",
    "\n",
    "# 2) Extraer la lista de IDs del txt en el orden en que aparecen\n",
    "ids = []\n",
    "with open(txt_input, \"r\", encoding=\"utf-8\") as f:\n",
    "    for line in f:\n",
    "        m = re.search(r\"Procesando tweet ID:\\s*(\\d+)\", line)\n",
    "        if m:\n",
    "            ids.append(m.group(1))\n",
    "\n",
    "# 3) Cargar tu JSON original\n",
    "with open(json_input, \"r\", encoding=\"utf-8\") as f:\n",
    "    tweets = json.load(f)\n",
    "\n",
    "# 4) Verificar que concuerden\n",
    "if len(ids) != len(tweets):\n",
    "    raise ValueError(f\"Tengo {len(ids)} IDs en el txt pero {len(tweets)} tweets en el JSON.\")\n",
    "\n",
    "# 5) Asignar cada ID a su tweet correspondiente\n",
    "for idx, tweet in enumerate(tweets):\n",
    "    tweet[\"id\"] = ids[idx]\n",
    "\n",
    "# 6) Guardar el JSON resultante\n",
    "with open(json_output, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(tweets, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "print(f\"✅ Asignados {len(ids)} IDs. Salvo en '{json_output}'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "78c78c57-b2b9-473b-a433-0820a7466a52",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ No se encontró usuario para: Daniel Senderos\n",
      "⚠️ No se encontró usuario para: María Jesus moro almaraz\n",
      "⚠️ No se encontró usuario para: Víctor Sánchezdel Real\n",
      "⚠️ No se encontró usuario para: Odón Elorza\n",
      "⚠️ No se encontró usuario para: Joan Capdevila\n",
      "⚠️ No se encontró usuario para: Juan Cuatrecasas Asúa\n",
      "⚠️ No se encontró usuario para: Federico. J. Contreras\n",
      "⚠️ No se encontró usuario para: Rocío De Meer\n",
      "⚠️ No se encontró usuario para: Jose Luis Aceves\n",
      "⚠️ No se encontró usuario para: María Luz Martínez Seijo\n",
      "⚠️ No se encontró usuario para: José Ramírez del Río\n",
      "⚠️ No se encontró usuario para: Jaume Alonso-Cuevillas\n",
      "⚠️ No se encontró usuario para: Maria Dantas\n",
      "⚠️ No se encontró usuario para: Concepción Cañadell\n",
      "⚠️ No se encontró usuario para: Lídia Guinart Moreno\n",
      "⚠️ No se encontró usuario para: Belén Fernández\n",
      "⚠️ No se encontró usuario para: Joan Baldoví\n",
      "⚠️ No se encontró usuario para: Pablo Iglesias\n",
      "⚠️ No se encontró usuario para: Sònia Guerra López\n",
      "⚠️ No se encontró usuario para: Bego Nasarre\n",
      "⚠️ No se encontró usuario para: Isabel Franco\n",
      "⚠️ No se encontró usuario para: Eva Patricia Bueno\n",
      "\n",
      "✅ JSON final guardado en: tweets_españoles_completos2.json\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "import json\n",
    "import unicodedata\n",
    "\n",
    "# — Rutas de entrada/salida —\n",
    "TWEETS_JSON    = 'spain/Completado/tweets_españoles_evaluados_completo.json'\n",
    "DETAILS_JSON   = 'spain/politicos_españoles_con_edad.json'\n",
    "USERS_JSON     = 'spain/users_españoles.json'\n",
    "OUTPUT_JSON    = 'tweets_españoles_completos2.json'\n",
    "\n",
    "# — Función para normalizar texto —\n",
    "def normalize(text):\n",
    "    text = text.lower().strip()\n",
    "    text = unicodedata.normalize('NFKD', text)\n",
    "    return ''.join(c for c in text if not unicodedata.combining(c))\n",
    "\n",
    "# — Carga de datos —\n",
    "with open(TWEETS_JSON, encoding='utf-8') as f:\n",
    "    all_tweets = json.load(f)\n",
    "\n",
    "with open(DETAILS_JSON, encoding='utf-8') as f:\n",
    "    politicos = json.load(f)\n",
    "\n",
    "with open(USERS_JSON, encoding='utf-8') as f:\n",
    "    user_info = json.load(f)\n",
    "\n",
    "# — Mapeo rápido de ID → tweet —\n",
    "id_to_tweet = {str(tw['id']): tw for tw in all_tweets}\n",
    "\n",
    "# — Mapeo de nombre normalizado → @usuario —\n",
    "name_to_user = {normalize(u['name']): u for u in user_info}\n",
    "\n",
    "# — Construir resultado final —\n",
    "final = {}\n",
    "for pol in politicos:\n",
    "    normname = normalize(pol['name'])\n",
    "    user_entry = name_to_user.get(normname)\n",
    "\n",
    "    if not user_entry:\n",
    "        print(f\"⚠️ No se encontró usuario para: {pol['name']}\")\n",
    "        continue\n",
    "\n",
    "    tweet_ids = user_entry.get(\"tweet_ids\", [])\n",
    "    tweet_objs = []\n",
    "    for tid in tweet_ids:\n",
    "        t = id_to_tweet.get(str(tid))\n",
    "        if t:\n",
    "            tweet_objs.append({\n",
    "                'id':         t.get('id'),\n",
    "                'text':       t.get('text'),\n",
    "                'valoration': t.get('valoration'),\n",
    "                'replies':    t.get('replies', [])\n",
    "            })\n",
    "        else:\n",
    "            print(f\"❌ Tweet ID {tid} no encontrado en dataset.\")\n",
    "\n",
    "    final[normname] = {\n",
    "        'name':   pol['name'],\n",
    "        'user':   user_entry.get('user'),\n",
    "        'age':    pol.get('age'),\n",
    "        'party':  pol.get('party'),\n",
    "        'gender': pol.get('gender'),\n",
    "        'tweets': tweet_objs\n",
    "    }\n",
    "\n",
    "# — Guardar resultado —\n",
    "output = list(final.values())\n",
    "with open(OUTPUT_JSON, 'w', encoding='utf-8') as f:\n",
    "    json.dump(output, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "print(f\"\\n✅ JSON final guardado en: {OUTPUT_JSON}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1932d16d-30af-412e-bf0f-163118993e7c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 Estadísticas generales\n",
      "👤 Número de usuarios:       1000\n",
      "💬 Total de tweets:          0\n",
      "💭 Total de respuestas:      0\n",
      "📈 Promedio respuestas/tweet:0.00\n",
      "\n",
      "⚠️ Usuarios sin tweets:\n",
      "  - Juan López de Uralde\n",
      "@juralde\n",
      "·\n",
      "Nov 7, 2021\n",
      "  - Gloria Elizo\n",
      "@GloriaElizo\n",
      "  - Guillermo Prudencio\n",
      "@guilleprudencio\n",
      "·\n",
      "Feb 19, 2021\n",
      "  - Andrés Lorite\n",
      "@AndresLorite\n",
      "  - Inés Sabanés\n",
      "@isabanes\n",
      "  - José Alcaraz Martos\n",
      "@fjosealcaraz\n",
      "  - Marisa Saavedra\n",
      "@MarisaSaavedraM\n",
      "  - Daniel Senderos/\n",
      "@danielsenderos\n",
      "  - Jaume Asens\n",
      "@Jaumeasens\n",
      "  - Pilar Marcos\n",
      "@pilarmarcosd\n",
      "·\n",
      "Sep 9, 2021\n",
      "  - Marta Martín Llaguno\n",
      "@martamartirio\n",
      "  - Marisa Saavedra\n",
      "@MarisaSaavedraM\n",
      "  - Marisa Saavedra\n",
      "@MarisaSaavedraM\n",
      "  - Error al extraer usuario de 1356204051105460227 tras 3 intentos.\n",
      "  - Inès Gumà Mitjà\n",
      "@inheis\n",
      "·\n",
      "Aug 28, 2021\n",
      "  - Diego Gago Bugarín\n",
      "@DiegoGagoB\n",
      "  - Error al extraer usuario de 1444931213400199170 tras 3 intentos.\n",
      "  - Miriam Nogueras\n",
      "@miriamnoguerasM\n",
      "·\n",
      "Sep 23, 2021\n",
      "  - Miguel Gutiérrez\n",
      "@MGutierrezCs\n",
      "  - Rosa Romero\n",
      "@rosaromerocr\n",
      "  - Carla Toscano\n",
      "@eledhmel\n",
      "·\n",
      "Feb 5, 2021\n",
      "  - Fco. J. Contreras\n",
      "@fjconpe\n",
      "·\n",
      "Aug 28, 2021\n",
      "  - Castiel\n",
      "@Castiel_Perez\n",
      "·\n",
      "Jun 18, 2021\n",
      "  - Rosa Romero\n",
      "@rosaromerocr\n",
      "  - Odón Elorza Activista por la Democracia\n",
      "@odonelorza2011\n",
      "·\n",
      "Nov 26, 2021\n",
      "  - Juan Luis Soto Buril\n",
      "@juanluissotoadd\n",
      "  - Pilar Cancela/\n",
      "@PiliCancela\n",
      "  - Néstor Rego\n",
      "@NestorRego\n",
      "  - Pedro Sánchez\n",
      "@sanchezcastejon\n",
      "  - Odón Elorza Activista por la Democracia\n",
      "@odonelorza2011\n",
      "·\n",
      "Jul 22, 2021\n",
      "  - Daniel Senderos/\n",
      "@danielsenderos\n",
      "  - Daniel Senderos/\n",
      "@danielsenderos\n",
      "  - Laura Borràs\n",
      "@LauraBorras\n",
      "  - Antonio Saorín.#YoApoyoAlGobierno\n",
      "@marxiniano\n",
      "·\n",
      "Dec 14, 2021\n",
      "  - Héctor Gómez\n",
      "@Hectorgomezh\n",
      "  - mjesus moro almaraz\n",
      "@MoroMjesus\n",
      "  - Junts per Catalunya\n",
      "@JuntsXCat\n",
      "·\n",
      "Jan 26, 2021\n",
      "  - Ines Granollers\n",
      "@InesGranollers\n",
      "  - Ricardo Chamorro Delmo\n",
      "@rchamode\n",
      "  - Alberto Garzón\n",
      "@agarzon\n",
      "  - Mario Garcés Sanagustín\n",
      "@MarioGarcesSan\n",
      "  - Jose Antonio Rodríguez Salas \n",
      "@JoseantonioJun\n",
      "  - Carla Toscano\n",
      "@eledhmel\n",
      "·\n",
      "Nov 14, 2021\n",
      "  - Juan López de Uralde\n",
      "@juralde\n",
      "  - Macarena Olona\n",
      "@Macarena_Olona\n",
      "  - Patricia Rueda\n",
      "@_patricia_rueda\n",
      "  - Nieves Ulayar.\n",
      "@nulayar\n",
      "·\n",
      "Mar 27, 2021\n",
      "  - Macarena Olona\n",
      "@Macarena_Olona\n",
      "  - Error al extraer usuario de 1353983962507575296 tras 3 intentos.\n",
      "  - Carmen Riolobos\n",
      "@CarmenRiolobos\n",
      "  - VíctorSánchezdelReal\n",
      "@sanchezdelreal\n",
      "  - Daniel Senderos/\n",
      "@danielsenderos\n",
      "  - Eloy Suárez Lamata\n",
      "@eloysuarezl\n",
      "  - Odón Elorza Activista por la Democracia\n",
      "@odonelorza2011\n",
      "  - Isabel\n",
      "@Belisa82754991\n",
      "·\n",
      "Oct 24, 2021\n",
      "  - Rodrigo Jiménez Revuelta\n",
      "@rodrijr111\n",
      "  - Ana Vázquez Blanco\n",
      "@anadebande\n",
      "  - Eloy Suárez Lamata\n",
      "@eloysuarezl\n",
      "  - Daniel Senderos/\n",
      "@danielsenderos\n",
      "  - Fuensanta Lima\n",
      "@fuensantalima\n",
      "  - Carla Toscano\n",
      "@eledhmel\n",
      "  - Jami Matamala Alsina\n",
      "@jami_matamala\n",
      "·\n",
      "Apr 1, 2021\n",
      "  - Error al extraer usuario de 1453980082972803076 tras 3 intentos.\n",
      "  - Daniel Senderos/\n",
      "@danielsenderos\n",
      "  - Daniel Senderos/\n",
      "@danielsenderos\n",
      "  - Genís Boadella\n",
      "@GenisBoadella\n",
      "  - Daniel Senderos/\n",
      "@danielsenderos\n",
      "  - José Alcaraz Martos\n",
      "@fjosealcaraz\n",
      "  - Pilar Marcos\n",
      "@pilarmarcosd\n",
      "  - Meritxell Batet\n",
      "@meritxell_batet\n",
      "·\n",
      "Jan 26, 2021\n",
      "  - VíctorSánchezdelReal\n",
      "@sanchezdelreal\n",
      "  - Victor Píriz Maya\n",
      "@vicpiriz1975\n",
      "  - VíctorSánchezdelReal\n",
      "@sanchezdelreal\n",
      "  - Error al extraer usuario de 1456244674264551427 tras 3 intentos.\n",
      "  - Carlos Fidalgo\n",
      "@CarlosFidalgoG\n",
      "·\n",
      "Oct 3, 2021\n",
      "  - Joan Capdevila ن\n",
      "@capdevilajoan\n",
      "  - Fernando Varela\n",
      "@Fervabi\n",
      "·\n",
      "May 11, 2021\n",
      "  - Daniel Senderos/\n",
      "@danielsenderos\n",
      "  - Jordi Évole\n",
      "@jordievole\n",
      "·\n",
      "Jan 17, 2021\n",
      "  - Pilar Marcos\n",
      "@pilarmarcosd\n",
      "  - Mario / マリウス\n",
      "@mario_gix\n",
      "·\n",
      "Oct 18, 2021\n",
      "  - Juan Cuatrecasas Asúa/\n",
      "@CuatrecasasJuan\n",
      "  - Juan Cuatrecasas Asúa/\n",
      "@CuatrecasasJuan\n",
      "  - Pere Joan Pons Sampietro\n",
      "@perejoanpons\n",
      "  - Victor Píriz Maya\n",
      "@vicpiriz1975\n",
      "  - José Alcaraz Martos\n",
      "@fjosealcaraz\n",
      "  - Sabah صباح\n",
      "@Sabah_Yacoubi\n",
      "·\n",
      "Apr 23, 2021\n",
      "  - Daniel Senderos/\n",
      "@danielsenderos\n",
      "  - Agustín Almodóbar Barceló\n",
      "@aalmodobar\n",
      "  - Carmen Riolobos\n",
      "@CarmenRiolobos\n",
      "  - Fco. J. Contreras\n",
      "@fjconpe\n",
      "  - Jesús Cobos\n",
      "@j_cobos\n",
      "·\n",
      "Apr 14, 2021\n",
      "  - José Alcaraz Martos\n",
      "@fjosealcaraz\n",
      "  - VíctorSánchezdelReal\n",
      "@sanchezdelreal\n",
      "  - Martina Velarde\n",
      "@MartinaVelardeG\n",
      "·\n",
      "Sep 27, 2021\n",
      "  - 100%Andaluza\n",
      "@CristinaCabezon\n",
      "·\n",
      "Oct 17, 2021\n",
      "  - Pau Marí-Klose\n",
      "@pmklose\n",
      "  - Ines Granollers\n",
      "@InesGranollers\n",
      "  - Mariona Illamola Dausà\n",
      "@MarionaID\n",
      "  - Yolanda Díaz\n",
      "@Yolanda_Diaz_\n",
      "  - Ricardo Chamorro Delmo\n",
      "@rchamode\n",
      "  - sol cruz guzman\n",
      "@solcruzguzman\n",
      "  - Inés Arrimadas\n",
      "@InesArrimadas\n",
      "  - Error al extraer usuario de 1365950788460281856 tras 3 intentos.\n",
      "  - Daniel Senderos/\n",
      "@danielsenderos\n",
      "·\n",
      "Aug 19, 2021\n",
      "  - Ione Belarra\n",
      "@ionebelarra\n",
      "  - Error al extraer usuario de 1475867310661513216 tras 3 intentos.\n",
      "  - Edurne Uriarte\n",
      "@EdurneUriarte\n",
      "  - Rocío De Meer ن\n",
      "@MeerRocio\n",
      "  - Carla Toscano\n",
      "@eledhmel\n",
      "·\n",
      "Feb 19, 2021\n",
      "  - Iván Espinosa de los Monteros\n",
      "@ivanedlm\n",
      "  - Arnau Ramírez\n",
      "@arnauramirez\n",
      "  - Emilio del Valle\n",
      "@edelvallerod\n",
      "  - Malena Nevado\n",
      "@malenanevado\n",
      "  - Néstor Rego\n",
      "@NestorRego\n",
      "  - \n",
      "  - Pere Joan Pons Sampietro\n",
      "@perejoanpons\n",
      "·\n",
      "Jun 15, 2021\n",
      "  - Víctor González\n",
      "@vicpiedra\n",
      "  - Ana Zurita\n",
      "@AnaZurita7\n",
      "  - Daniel Senderos/\n",
      "@danielsenderos\n",
      "  - Toni Lopez\n",
      "@tonilopez_Vox\n",
      "·\n",
      "Sep 3, 2021\n",
      "  - Sergio Gutierrez\n",
      "@Sergio_GP\n",
      "·\n",
      "Aug 10, 2021\n",
      "  - Georgina Trias\n",
      "@georginatrias10\n",
      "  - Pere Joan Pons Sampietro\n",
      "@perejoanpons\n",
      "  - Jose Luis Aceves/\n",
      "@JLAceves\n",
      "  - Íñigo Errejón\n",
      "@ierrejon\n",
      "  - Daniel Senderos/\n",
      "@danielsenderos\n",
      "  - Fuensanta Lima\n",
      "@fuensantalima\n",
      "  - Hèctor López Bofill\n",
      "@lopezbofill\n",
      "·\n",
      "Jul 25, 2021\n",
      "  - Rodrigo Jiménez Revuelta\n",
      "@rodrijr111\n",
      "  - ESPolítica\n",
      "@ESPpolitica_TW\n",
      "·\n",
      "Sep 23, 2021\n",
      "  - Xavier Eritja Ciuró\n",
      "@xavieritja\n",
      "  - Cristina Esteban Calonje\n",
      "@CrisCalonje\n",
      "  - Error al extraer usuario de 1359887073235329029 tras 3 intentos.\n",
      "  - José Alcaraz Martos\n",
      "@fjosealcaraz\n",
      "  - VíctorSánchezdelReal\n",
      "@sanchezdelreal\n",
      "  - Error al extraer usuario de 1450563371259072519 tras 3 intentos.\n",
      "  - Carmen Riolobos\n",
      "@CarmenRiolobos\n",
      "  - Lola Gómez\n",
      "@lolagmnews\n",
      "·\n",
      "Feb 9, 2021\n",
      "  - Mario Garcés Sanagustín\n",
      "@MarioGarcesSan\n",
      "·\n",
      "Aug 3, 2021\n",
      "  - Mireia Vehí\n",
      "@Mireia_veca\n",
      "  - Victor Píriz Maya\n",
      "@vicpiriz1975\n",
      "  - Mercè Perea Conillas\n",
      "@MercePerea\n",
      "  - Maria Dantas (@mariadantas.bsky.social)\n",
      "@_Maria_Dantas_\n",
      "·\n",
      "Feb 10, 2021\n",
      "  - Santiago Abascal\n",
      "@Santi_ABASCAL\n",
      "  - Ángeles Marra \\\n",
      "@AngelesMarra\n",
      "  - NUET\n",
      "@NUET\n",
      "  - Juan de la Rosa\n",
      "@jdelarosa100\n",
      "·\n",
      "Jul 19, 2021\n",
      "  - Daniel Senderos/\n",
      "@danielsenderos\n",
      "  - fran\n",
      "@flacambra1975\n",
      "·\n",
      "Nov 4, 2021\n",
      "  - Beatriz Micaela Carrillo de los Reyes\n",
      "@BeaMCarrillo\n",
      "·\n",
      "May 30, 2021\n",
      "  - Fco. J. Contreras\n",
      "@fjconpe\n",
      "  - Ana Zurita\n",
      "@AnaZurita7\n",
      "  - José Alcaraz Martos\n",
      "@fjosealcaraz\n",
      "  - Cayetana Álvarez de Toledo\n",
      "@cayetanaAT\n",
      "  - Error al extraer usuario de 1386642603182002176 tras 3 intentos.\n",
      "  - Mercè Perea Conillas\n",
      "@MercePerea\n",
      "  - Martina Velarde\n",
      "@MartinaVelardeG\n",
      "·\n",
      "Nov 1, 2021\n",
      "  - Edurne Uriarte\n",
      "@EdurneUriarte\n",
      "  - José Belmonte\n",
      "@JbsJos\n",
      "·\n",
      "Feb 18, 2021\n",
      "  - M Luz Martínez Seijo\n",
      "@luzseijo\n",
      "  - Rubén Manso Olivar\n",
      "@rubenmansolivar\n",
      "  - Fco. J. Contreras\n",
      "@fjconpe\n",
      "  - Néstor Rego\n",
      "@NestorRego\n",
      "  - #DefensaTurnoLibre\n",
      "@defturnolibre\n",
      "·\n",
      "Nov 12, 2021\n",
      "  - Ana Zurita\n",
      "@AnaZurita7\n",
      "  - Flòscul Llavallol i Bracons\n",
      "@Rampoina\n",
      "·\n",
      "Jun 23, 2021\n",
      "  - Joan Margall Sastre\n",
      "@joanmargall\n",
      "  - José Ramírez del Río ن\n",
      "@joseramirezdel2\n",
      "  - Jon Inarritu\n",
      "@JonInarritu\n",
      "  - Error al extraer usuario de 1357070890807271428 tras 3 intentos.\n",
      "  - Martina Velarde\n",
      "@MartinaVelardeG\n",
      "  - Error al extraer usuario de 1419427790886248449 tras 3 intentos.\n",
      "  - Pedro Casares\n",
      "@pedro_casares\n",
      "  - Agustín Almodóbar Barceló\n",
      "@aalmodobar\n",
      "  - VíctorSánchezdelReal\n",
      "@sanchezdelreal\n",
      "  - Santi Navarro Anglí\n",
      "@Sanagli\n",
      "·\n",
      "Oct 5, 2021\n",
      "  - Roberto Morís\n",
      "@MorisSiero\n",
      "  - Pepe Ortiz Vejer\n",
      "@vejer_ortiz\n",
      "  - Error al extraer usuario de 1425414550258585601 tras 3 intentos.\n",
      "  - Agustín Almodóbar Barceló\n",
      "@aalmodobar\n",
      "  - MARIA CARLEX\n",
      "@MCarlex\n",
      "·\n",
      "Mar 9, 2021\n",
      "  - Jaume Alonso-Cuevillas i Sayrol (JACS)\n",
      "@JACS_JaumeACS\n",
      "  - Daniel Senderos/\n",
      "@danielsenderos\n",
      "·\n",
      "Dec 2, 2021\n",
      "  - Montse Mínguez\n",
      "@montseminguez\n",
      "  - Daniel Senderos/\n",
      "@danielsenderos\n",
      "  - Pilar Cancela/\n",
      "@PiliCancela\n",
      "·\n",
      "Jan 10, 2021\n",
      "  - Meritxell Batet\n",
      "@meritxell_batet\n",
      "  - Agustín Almodóbar Barceló\n",
      "@aalmodobar\n",
      "  - Íñigo Errejón\n",
      "@ierrejon\n",
      "  - Sergio Álvarez\n",
      "@SergioSariegu\n",
      "·\n",
      "Oct 4, 2021\n",
      "  - Macarena Olona\n",
      "@Macarena_Olona\n",
      "  - Pedro Sánchez\n",
      "@sanchezcastejon\n",
      "  - José Alcaraz Martos\n",
      "@fjosealcaraz\n",
      "  - Macarena Olona\n",
      "@Macarena_Olona\n",
      "  - Carmela Silva\n",
      "@carmelasilva\n",
      "·\n",
      "Jul 14, 2021\n",
      "  - Cesar Ramos\n",
      "@CesarJRamos\n",
      "  - Ana Oramas\n",
      "@anioramas\n",
      "  - @LaLidieta\n",
      "@lalidieta\n",
      "·\n",
      "Oct 19, 2021\n",
      "  - Antón Gómez-Reino Varela\n",
      "@AntonGomezReino\n",
      "  - Agustín Almodóbar Barceló\n",
      "@aalmodobar\n",
      "  - Ana Pastor Julián\n",
      "@anapastorjulian\n",
      "  - Carmen Navarro Lacoba\n",
      "@CnLacoba\n",
      "  - Pau Marí-Klose\n",
      "@pmklose\n",
      "·\n",
      "Jan 28, 2021\n",
      "  - Daniel Senderos/\n",
      "@danielsenderos\n",
      "  - Ignacio López Cano\n",
      "@nasholop\n",
      "  - Carme Garcia Suarez\n",
      "@carmegarciasu\n",
      "·\n",
      "Oct 29, 2021\n",
      "  - Sigueme por Sevilla\n",
      "@AM322422\n",
      "·\n",
      "Jun 6, 2021\n",
      "  - Macarena Olona\n",
      "@Macarena_Olona\n",
      "  - Fco. J. Contreras\n",
      "@fjconpe\n",
      "  - Gerardo Pisarello\n",
      "@G_Pisarello\n",
      "·\n",
      "May 31, 2021\n",
      "  - Mazzinguerzetta\n",
      "@Mazzinguerzett1\n",
      "·\n",
      "Feb 2, 2021\n",
      "  - Ione Belarra\n",
      "@ionebelarra\n",
      "  - Teodoro García Egea\n",
      "@TeoGarciaEgea\n",
      "  - Daniel Senderos/\n",
      "@danielsenderos\n",
      "  - Carla Toscano\n",
      "@eledhmel\n",
      "·\n",
      "Jan 5, 2021\n",
      "  - Error al extraer usuario de 1349010882873991169 tras 3 intentos.\n",
      "  - Cayetana Álvarez de Toledo\n",
      "@cayetanaAT\n",
      "  - Marta Martín Llaguno\n",
      "@martamartirio\n",
      "  - Mariona Illamola Dausà\n",
      "@MarionaID\n",
      "  - mjesus moro almaraz\n",
      "@MoroMjesus\n",
      "  - Daniel Senderos/\n",
      "@danielsenderos\n",
      "  - Arnau Ramírez\n",
      "@arnauramirez\n",
      "  - María Muñoz\n",
      "@mariadelamiel\n",
      "  - Error al extraer usuario de 1374977300803022850 tras 3 intentos.\n",
      "  - Ignacio Garriga\n",
      "@Igarrigavaz\n",
      "  - VíctorSánchezdelReal\n",
      "@sanchezdelreal\n",
      "  - Rubén Manso Olivar\n",
      "@rubenmansolivar\n",
      "  - Agustín Almodóbar Barceló\n",
      "@aalmodobar\n",
      "  - Santiago Abascal\n",
      "@Santi_ABASCAL\n",
      "·\n",
      "Apr 8, 2021\n",
      "  - Maria Dantas (@mariadantas.bsky.social)\n",
      "@_Maria_Dantas_\n",
      "  - Pau Marí-Klose\n",
      "@pmklose\n",
      "·\n",
      "Jan 8, 2021\n",
      "  - Valentina Martinez\n",
      "@valentinam\n",
      "  - Pablo Sáez\n",
      "@PabloSaezAM\n",
      "  - Rubén Manso Olivar\n",
      "@rubenmansolivar\n",
      "·\n",
      "Oct 2, 2021\n",
      "  - Alberto Garzón\n",
      "@agarzon\n",
      "·\n",
      "Jan 8, 2021\n",
      "  - Concep Cañadell\n",
      "@conceptermens\n",
      "  - Rosa Romero\n",
      "@rosaromerocr\n",
      "  - Error al extraer usuario de 1423180009619996674 tras 3 intentos.\n",
      "  - Pablo Sáez\n",
      "@PabloSaezAM\n",
      "  - Daniel Senderos/\n",
      "@danielsenderos\n",
      "  - Fernando Gonzalez de la Higuera Solis\n",
      "@Fernand43573512\n",
      "·\n",
      "Dec 31, 2021\n",
      "  - Bea Fanjul\n",
      "@bea_fanjul\n",
      "  - Montse Mínguez\n",
      "@montseminguez\n",
      "  - Error al extraer usuario de 1461051135339470850 tras 3 intentos.\n",
      "  - VíctorSánchezdelReal\n",
      "@sanchezdelreal\n",
      "  - Pepe Ortiz Vejer\n",
      "@vejer_ortiz\n",
      "  - Junts per Catalunya Congrés i Senat\n",
      "@JuntsxCatMadrid\n",
      "·\n",
      "Mar 23, 2021\n",
      "  - JD\n",
      "@jes_dav_\n",
      "·\n",
      "Mar 23, 2021\n",
      "  - Daniel Senderos/\n",
      "@danielsenderos\n",
      "  - Miquel Jerez\n",
      "@miqueljerez\n",
      "  - Rubén Manso Olivar\n",
      "@rubenmansolivar\n",
      "  - Marisa Saavedra\n",
      "@MarisaSaavedraM\n",
      "  - Maria Dantas (@mariadantas.bsky.social)\n",
      "@_Maria_Dantas_\n",
      "·\n",
      "Mar 17, 2021\n",
      "  - Iván Espinosa de los Monteros\n",
      "@ivanedlm\n",
      "  - Víctor González\n",
      "@vicpiedra\n",
      "  - José Ignacio Echániz\n",
      "@JIEchaniz\n",
      "  - Omar Anguita Pérez\n",
      "@AnguitaOmar\n",
      "  - Joan Duran i Ferrer\n",
      "@joanduranf\n",
      "·\n",
      "Jul 6, 2021\n",
      "  - Omar Anguita Pérez\n",
      "@AnguitaOmar\n",
      "  - Fco. J. Contreras\n",
      "@fjconpe\n",
      "  - Ana Vázquez Blanco\n",
      "@anadebande\n",
      "  - Marina Trades\n",
      "@cat_nordic\n",
      "·\n",
      "Feb 2, 2021\n",
      "  - Jorge Casas Neira\n",
      "@JorgeCasasNeira\n",
      "·\n",
      "Sep 8, 2021\n",
      "  - Carmen Riolobos\n",
      "@CarmenRiolobos\n",
      "  - Daniel Senderos/\n",
      "@danielsenderos\n",
      "  - Andrés Lorite\n",
      "@AndresLorite\n",
      "  - VíctorSánchezdelReal\n",
      "@sanchezdelreal\n",
      "·\n",
      "Apr 4, 2021\n",
      "  - Omar Anguita Pérez\n",
      "@AnguitaOmar\n",
      "  - José Alcaraz Martos\n",
      "@fjosealcaraz\n",
      "  - Malena Nevado\n",
      "@malenanevado\n",
      "·\n",
      "Dec 11, 2021\n",
      "  - Mariona Illamola Dausà\n",
      "@MarionaID\n",
      "  - Edurne Uriarte\n",
      "@EdurneUriarte\n",
      "  - Sofía Hernanz Costa\n",
      "@Hernanzsofia\n",
      "  - Rubén Manso Olivar\n",
      "@rubenmansolivar\n",
      "·\n",
      "Feb 14, 2021\n",
      "  - VíctorSánchezdelReal\n",
      "@sanchezdelreal\n",
      "  - Error al extraer usuario de 1438563996962021376 tras 3 intentos.\n",
      "  - VíctorSánchezdelReal\n",
      "@sanchezdelreal\n",
      "·\n",
      "Sep 19, 2021\n",
      "  - Carmen Riolobos\n",
      "@CarmenRiolobos\n",
      "  - Magdalena Valerio\n",
      "@mvalerio_gu\n",
      "·\n",
      "Dec 29, 2021\n",
      "  - Lídia Guinart Moreno/\n",
      "@lidiaguinart\n",
      "  - Andrea Fernández.\n",
      "@afernb\n",
      "·\n",
      "Aug 14, 2021\n",
      "  - Rocío De Meer ن\n",
      "@MeerRocio\n",
      "  - Marta Rosique i Saltor\n",
      "@MartaRosiq\n",
      "  - José Zaragoza\n",
      "@J_Zaragoza_\n",
      "  - Georgina Trias\n",
      "@georginatrias10\n",
      "  - Chopenawer\n",
      "@dchopenawer\n",
      "·\n",
      "Feb 4, 2021\n",
      "  - Georgina Trias\n",
      "@georginatrias10\n",
      "·\n",
      "Sep 8, 2021\n",
      "  - Can Pixa\n",
      "@CPIXA1\n",
      "·\n",
      "Mar 11, 2021\n",
      "  - Daniel Senderos/\n",
      "@danielsenderos\n",
      "  - Error al extraer usuario de 1434612581004718083 tras 3 intentos.\n",
      "  - Maria Dantas (@mariadantas.bsky.social)\n",
      "@_Maria_Dantas_\n",
      "  - Alberto Herrero\n",
      "@herrerobono\n",
      "  - Rosa Romero\n",
      "@rosaromerocr\n",
      "  - Carmen Andrés Añón\n",
      "@carmenandres_\n",
      "  - Javier Benegas\n",
      "@BenegasJ\n",
      "·\n",
      "Mar 29, 2021\n",
      "  - Pilar Cancela/\n",
      "@PiliCancela\n",
      "  - Fco. J. Contreras\n",
      "@fjconpe\n",
      "  - Daniel Senderos/\n",
      "@danielsenderos\n",
      "  - Jaume Asens\n",
      "@Jaumeasens\n",
      "  - Belén Fernández/\n",
      "@BelenFCasero\n",
      "  - Oskar Matute\n",
      "@OskarMatute\n",
      "  - Arnau Ramírez\n",
      "@arnauramirez\n",
      "  - Error al extraer usuario de 1444780438510358531 tras 3 intentos.\n",
      "  - Mario Garcés Sanagustín\n",
      "@MarioGarcesSan\n",
      "  - Marisa Saavedra\n",
      "@MarisaSaavedraM\n",
      "  - Iván Espinosa de los Monteros\n",
      "@ivanedlm\n",
      "  - Daniel Senderos/\n",
      "@danielsenderos\n",
      "  - Agustín Almodóbar Barceló\n",
      "@aalmodobar\n",
      "  - Pepe Ortiz Vejer\n",
      "@vejer_ortiz\n",
      "  - Jaume Asens\n",
      "@Jaumeasens\n",
      "  - Laura Borràs\n",
      "@LauraBorras\n",
      "  - Reyes Romero\n",
      "@rromerovilches\n",
      "·\n",
      "Apr 21, 2021\n",
      "  - Marta Martín Llaguno\n",
      "@martamartirio\n",
      "  - Inés Arrimadas\n",
      "@InesArrimadas\n",
      "  - Laura Borràs\n",
      "@LauraBorras\n",
      "  - 𝐆𝐚𝐛𝐫𝐢𝐞𝐥 𝐄𝐥𝐨𝐫𝐫𝐢𝐚𝐠𝐚\n",
      "@gabrielorriaga\n",
      "·\n",
      "Jun 22, 2021\n",
      "  - Pilar Marcos\n",
      "@pilarmarcosd\n",
      "  - Error al extraer usuario de 1475937662490062849 tras 3 intentos.\n",
      "  - Sebastian Ledesma Ma\n",
      "@SebastianLede15\n",
      "  - Ricardo Chamorro Delmo\n",
      "@rchamode\n",
      "  - Ignacio Garriga\n",
      "@Igarrigavaz\n",
      "  - Emilio del Valle\n",
      "@edelvallerod\n",
      "  - Maria Dantas (@mariadantas.bsky.social)\n",
      "@_Maria_Dantas_\n",
      "·\n",
      "Jul 7, 2021\n",
      "  - VíctorSánchezdelReal\n",
      "@sanchezdelreal\n",
      "  - Inés Arrimadas\n",
      "@InesArrimadas\n",
      "  - Víctor González\n",
      "@vicpiedra\n",
      "  - Daniel Senderos/\n",
      "@danielsenderos\n",
      "  - Pilar Marcos\n",
      "@pilarmarcosd\n",
      "  - VíctorSánchezdelReal\n",
      "@sanchezdelreal\n",
      "·\n",
      "Feb 19, 2021\n",
      "  - Nuria Varela\n",
      "@NuriaVarela\n",
      "·\n",
      "Mar 24, 2021\n",
      "  - Daniel Senderos/\n",
      "@danielsenderos\n",
      "  - Odón Elorza Activista por la Democracia\n",
      "@odonelorza2011\n",
      "·\n",
      "Mar 28, 2021\n",
      "  - VíctorSánchezdelReal\n",
      "@sanchezdelreal\n",
      "  - Ángeles Marra \\\n",
      "@AngelesMarra\n",
      "  - Íñigo Errejón\n",
      "@ierrejon\n",
      "  - Juanjo Aizcorbe Torra\n",
      "@JuanjoAizcorbe\n",
      "  - Error al extraer usuario de 1359959517681901580 tras 3 intentos.\n",
      "  - Error al extraer usuario de 1458767236748001289 tras 3 intentos.\n",
      "  - Íñigo Errejón\n",
      "@ierrejon\n",
      "  - Joan Mena\n",
      "@joanmena\n",
      "·\n",
      "Nov 23, 2021\n",
      "  - Mercè Perea Conillas\n",
      "@MercePerea\n",
      "  - Pablo Casado Blanco\n",
      "@pablocasado_\n",
      "  - Albert Botran Pahissa\n",
      "@albertbotran\n",
      "  - Miriam Nogueras\n",
      "@miriamnoguerasM\n",
      "  - Yolanda Díaz\n",
      "@Yolanda_Diaz_\n",
      "  - Cesar Ramos\n",
      "@CesarJRamos\n",
      "  - Rocío De Meer ن\n",
      "@MeerRocio\n",
      "  - Pau Marí-Klose\n",
      "@pmklose\n",
      "  - Inés Sabanés\n",
      "@isabanes\n",
      "  - Susana Sumelzo Jordán\n",
      "@SSumelzo\n",
      "  - Antònia Jover\n",
      "@Antonia_Jover_\n",
      "  - Error al extraer usuario de 1368934094546042882 tras 3 intentos.\n",
      "  - Daniel Senderos/\n",
      "@danielsenderos\n",
      "  - Malena Nevado\n",
      "@malenanevado\n",
      "·\n",
      "Dec 21, 2021\n",
      "  - Edmundo Bal\n",
      "@BalEdmundo\n",
      "  - María Guijarro\n",
      "@Maritxu30\n",
      "·\n",
      "Apr 13, 2021\n",
      "  - María Muñoz\n",
      "@mariadelamiel\n",
      "·\n",
      "Oct 14, 2021\n",
      "  - Alicia García\n",
      "@AliciaGarcia_Av\n",
      "  - SETI I\n",
      "@rameneses1\n",
      "·\n",
      "Aug 2, 2021\n",
      "  - 𝗗𝗘𝗦𝗖𝗢𝗡𝗢𝗖𝗜𝗗𝗢 𝕏\n",
      "@J_V_Madrid\n",
      "·\n",
      "Dec 20, 2021\n",
      "  - Martina Velarde\n",
      "@MartinaVelardeG\n",
      "  - Miguel Á. Castellón\n",
      "@mcastellonPP\n",
      "  - Joan Baldoví ;)\n",
      "@joanbaldovi\n",
      "  - Susana Sumelzo Jordán\n",
      "@SSumelzo\n",
      "  - Ricardo Chamorro Delmo\n",
      "@rchamode\n",
      "  - Gabriel Rufián\n",
      "@gabrielrufian\n",
      "  - Ana Pastor Julián\n",
      "@anapastorjulian\n",
      "  - Carlos García Adanero\n",
      "@GarciaAdanero\n",
      "·\n",
      "Feb 25, 2021\n",
      "  - Error al extraer usuario de 1468518558149795845 tras 3 intentos.\n",
      "  - Martina Velarde\n",
      "@MartinaVelardeG\n",
      "·\n",
      "Sep 27, 2021\n",
      "  - Francisco J. Delgado\n",
      "@PadreFJD\n",
      "·\n",
      "Apr 12, 2021\n",
      "  - Error al extraer usuario de 1475871667083694082 tras 3 intentos.\n",
      "  - Íñigo Errejón\n",
      "@ierrejon\n",
      "  - Fernando Gutiérrez Díaz de Otazu\n",
      "@otazu35\n",
      "  - Txema Guijarro\n",
      "@TxemaGuijarro\n",
      "  - José Ramírez del Río ن\n",
      "@joseramirezdel2\n",
      "  - Emilio del Valle\n",
      "@edelvallerod\n",
      "  - Belén Fernández/\n",
      "@BelenFCasero\n",
      "  - Macarena Olona\n",
      "@Macarena_Olona\n",
      "·\n",
      "Dec 7, 2021\n",
      "  - Ángeles Marra \\\n",
      "@AngelesMarra\n",
      "  - German Renau\n",
      "@germanrenau\n",
      "  - Daniel Senderos/\n",
      "@danielsenderos\n",
      "  - Alberto Garzón\n",
      "@agarzon\n",
      "  - Agustín Almodóbar Barceló\n",
      "@aalmodobar\n",
      "  - Malena Nevado\n",
      "@malenanevado\n",
      "  - Juli Martínez Amorós\n",
      "@eljuliet_bnv\n",
      "·\n",
      "Nov 23, 2021\n",
      "  - Daniel Senderos/\n",
      "@danielsenderos\n",
      "  - Maria Dantas (@mariadantas.bsky.social)\n",
      "@_Maria_Dantas_\n",
      "  - Rodrigo Jiménez Revuelta\n",
      "@rodrijr111\n",
      "  - Ana Vázquez Blanco\n",
      "@anadebande\n",
      "  - Jose Antonio Rodríguez Salas \n",
      "@JoseantonioJun\n",
      "·\n",
      "Dec 25, 2021\n",
      "  - Marga Prohens\n",
      "@MargaProhens\n",
      "  - Daniel Senderos/\n",
      "@danielsenderos\n",
      "  - Juan Luis Steegmann\n",
      "@jlsteeg_doc\n",
      "·\n",
      "Nov 9, 2021\n",
      "  - Mª Carmen Martínez\n",
      "@MCMartinezWine\n",
      "·\n",
      "Nov 23, 2021\n",
      "  - Pilar Marcos\n",
      "@pilarmarcosd\n",
      "  - Antón Gómez-Reino Varela\n",
      "@AntonGomezReino\n",
      "  - VíctorSánchezdelReal\n",
      "@sanchezdelreal\n",
      "·\n",
      "Jan 29, 2021\n",
      "  - María Muñoz\n",
      "@mariadelamiel\n",
      "·\n",
      "Jan 26, 2021\n",
      "  - Agustín Almodóbar Barceló\n",
      "@aalmodobar\n",
      "  - Albert Botran Pahissa\n",
      "@albertbotran\n",
      "  - Meritxell Batet\n",
      "@meritxell_batet\n",
      "  - Víctor González\n",
      "@vicpiedra\n",
      "  - Rafa Lomana\n",
      "@RafaLomana\n",
      "  - Luis Gestoso\n",
      "@LuisGestoso\n",
      "  - Eduardo Carazo\n",
      "@educarazo\n",
      "  - Error al extraer usuario de 1400488232580702208 tras 3 intentos.\n",
      "  - Error al extraer usuario de 1349462952915689473 tras 3 intentos.\n",
      "  - Íñigo Errejón\n",
      "@ierrejon\n",
      "·\n",
      "Jun 21, 2021\n",
      "  - Martina Velarde\n",
      "@MartinaVelardeG\n",
      "  - Martina Velarde\n",
      "@MartinaVelardeG\n",
      "  - Ricardo Chamorro Delmo\n",
      "@rchamode\n",
      "  - Pau Marí-Klose\n",
      "@pmklose\n",
      "·\n",
      "Sep 10, 2021\n",
      "  - Error al extraer usuario de 1375339582582104064 tras 3 intentos.\n",
      "  - Javier Sáenz del Castillo\n",
      "@javiersaenzdelc\n",
      "·\n",
      "Aug 7, 2021\n",
      "  - Alberto Herrero\n",
      "@herrerobono\n",
      "  - antonio hurtado\n",
      "@AntonioHurtado\n",
      "  - Daniel Senderos/\n",
      "@danielsenderos\n",
      "  - Pedro Navarro\n",
      "@pedronavarrol\n",
      "  - Fuensanta Lima\n",
      "@fuensantalima\n",
      "  - interino en abuso\n",
      "@Trabucoman1\n",
      "·\n",
      "Jan 10, 2021\n",
      "  - José Ramírez del Río ن\n",
      "@joseramirezdel2\n",
      "  - Error al extraer usuario de 1414323167863128064 tras 3 intentos.\n",
      "  - Pere Joan Pons Sampietro\n",
      "@perejoanpons\n",
      "  - VíctorSánchezdelReal\n",
      "@sanchezdelreal\n",
      "·\n",
      "Aug 25, 2021\n",
      "  - Teodoro García Egea\n",
      "@TeoGarciaEgea\n",
      "  - May Mariño\n",
      "@MAYANTOXO\n",
      "·\n",
      "May 7, 2021\n",
      "  - Víctor González\n",
      "@vicpiedra\n",
      "  - Fco. J. Contreras\n",
      "@fjconpe\n",
      "·\n",
      "Apr 30, 2021\n",
      "  - Laura Borràs\n",
      "@LauraBorras\n",
      "·\n",
      "Oct 19, 2021\n",
      "  - María Guijarro\n",
      "@Maritxu30\n",
      "  - Jaume Alonso-Cuevillas i Sayrol (JACS)\n",
      "@JACS_JaumeACS\n",
      "  - Ángeles Marra \\\n",
      "@AngelesMarra\n",
      "  - Macarena Olona\n",
      "@Macarena_Olona\n",
      "  - Teodoro García Egea\n",
      "@TeoGarciaEgea\n",
      "·\n",
      "Apr 14, 2021\n",
      "  - Carlos Rojas García\n",
      "@CarlosRojas_PPA\n",
      "  - Rocío De Meer ن\n",
      "@MeerRocio\n",
      "  - The Ugly\n",
      "@and_the_ugly\n",
      "·\n",
      "Feb 6, 2021\n",
      "  - Juan López de Uralde\n",
      "@juralde\n",
      "·\n",
      "Nov 1, 2021\n",
      "  - José Ramírez del Río ن\n",
      "@joseramirezdel2\n",
      "  - VíctorSánchezdelReal\n",
      "@sanchezdelreal\n",
      "·\n",
      "Aug 15, 2021\n",
      "  - Silvia\n",
      "@silfg92\n",
      "·\n",
      "Nov 11, 2021\n",
      "  - Teodoro García Egea\n",
      "@TeoGarciaEgea\n",
      "  - Joan Mena\n",
      "@joanmena\n",
      "  - Gloria Elizo\n",
      "@GloriaElizo\n",
      "  - José Alcaraz Martos\n",
      "@fjosealcaraz\n",
      "  - Pedro Casares\n",
      "@pedro_casares\n",
      "  - Rafa Mayoral\n",
      "@MayoralRafa\n",
      "  - Inés Sabanés\n",
      "@isabanes\n",
      "  - Victor Píriz Maya\n",
      "@vicpiriz1975\n",
      "  - VíctorSánchezdelReal\n",
      "@sanchezdelreal\n",
      "  - Mercè Perea Conillas\n",
      "@MercePerea\n",
      "  - carlos_dhe\n",
      "@carlos_dhe\n",
      "·\n",
      "Oct 2, 2021\n",
      "  - Andrés Lorite\n",
      "@AndresLorite\n",
      "  - Marta Pastor\n",
      "@MartaPastor\n",
      "·\n",
      "Feb 18, 2021\n",
      "  - Maria Dantas (@mariadantas.bsky.social)\n",
      "@_Maria_Dantas_\n",
      "  - jhonny\n",
      "@Jonytorrero\n",
      "·\n",
      "Nov 14, 2021\n",
      "  - VíctorSánchezdelReal\n",
      "@sanchezdelreal\n",
      "  - Inés Arrimadas\n",
      "@InesArrimadas\n",
      "  - Victor Píriz Maya\n",
      "@vicpiriz1975\n",
      "  - Ricardo Chamorro Delmo\n",
      "@rchamode\n",
      "  - Miguel Ángel Reinoso\n",
      "@mianrey\n",
      "·\n",
      "Dec 23, 2021\n",
      "  - Ana Zurita\n",
      "@AnaZurita7\n",
      "  - Andrés Lorite\n",
      "@AndresLorite\n",
      "  - Daniel Senderos/\n",
      "@danielsenderos\n",
      "  - Íñigo Errejón\n",
      "@ierrejon\n",
      "·\n",
      "Sep 29, 2021\n",
      "  - Odón Elorza Activista por la Democracia\n",
      "@odonelorza2011\n",
      "·\n",
      "Feb 18, 2021\n",
      "  - Macarena Olona\n",
      "@Macarena_Olona\n",
      "·\n",
      "Feb 7, 2021\n",
      "  - Juan Cuatrecasas Asúa/\n",
      "@CuatrecasasJuan\n",
      "  - Maria Dantas (@mariadantas.bsky.social)\n",
      "@_Maria_Dantas_\n",
      "  - Maria Dantas (@mariadantas.bsky.social)\n",
      "@_Maria_Dantas_\n",
      "·\n",
      "Mar 9, 2021\n",
      "  - VíctorSánchezdelReal\n",
      "@sanchezdelreal\n",
      "  - Odón Elorza Activista por la Democracia\n",
      "@odonelorza2011\n",
      "  - Maria Dantas (@mariadantas.bsky.social)\n",
      "@_Maria_Dantas_\n",
      "  - Daniel Senderos/\n",
      "@danielsenderos\n",
      "  - Rafael Simancas\n",
      "@SimancasRafael\n",
      "  - Meritxell Batet\n",
      "@meritxell_batet\n",
      "  - Pere Joan Pons Sampietro\n",
      "@perejoanpons\n",
      "  - Laura Berja Vega\n",
      "@lauraberja86\n",
      "·\n",
      "Dec 6, 2021\n",
      "  - Montse Bassa i Coll\n",
      "@BassaMontse\n",
      "  - Daniel Senderos/\n",
      "@danielsenderos\n",
      "  - José Ángel Alonso\n",
      "@JAngelVillalon\n",
      "  - Error al extraer usuario de 1451885387929038848 tras 3 intentos.\n",
      "  - Javi Merino\n",
      "@javier_merino\n",
      "  - Arnau Ramírez\n",
      "@arnauramirez\n",
      "·\n",
      "May 29, 2021\n",
      "  - José Alcaraz Martos\n",
      "@fjosealcaraz\n",
      "  - antonio hurtado\n",
      "@AntonioHurtado\n",
      "  - Marcel Vivet Regalón\n",
      "@MarcelVR1\n",
      "·\n",
      "Jul 14, 2021\n",
      "  - Error al extraer usuario de 1444961661555720194 tras 3 intentos.\n",
      "  - Fco. J. Contreras\n",
      "@fjconpe\n",
      "  - VíctorSánchezdelReal\n",
      "@sanchezdelreal\n",
      "·\n",
      "Feb 18, 2021\n",
      "  - Alberto Herrero\n",
      "@herrerobono\n",
      "  - Carmen Riolobos\n",
      "@CarmenRiolobos\n",
      "  - Pablo Iglesias {R}\n",
      "@PabloIglesias\n",
      "  - AnaOlmedo\n",
      "@DiQueN0\n",
      "·\n",
      "Feb 6, 2021\n",
      "  - Juan Cuatrecasas Asúa/\n",
      "@CuatrecasasJuan\n",
      "  - Emilio del Valle\n",
      "@edelvallerod\n",
      "  - Mercedes Iglesias\n",
      "@mercheiglesiasc\n",
      "·\n",
      "Jan 2, 2021\n",
      "  - Rubén Manso Olivar\n",
      "@rubenmansolivar\n",
      "·\n",
      "Sep 23, 2021\n",
      "  - Error al extraer usuario de 1412118353288826887 tras 3 intentos.\n",
      "  - Pablo Casado Blanco\n",
      "@pablocasado_\n",
      "  - Marisa Saavedra\n",
      "@MarisaSaavedraM\n",
      "  - Error al extraer usuario de 1383376710465294349 tras 3 intentos.\n",
      "  - Sofía Castañón\n",
      "@SofCastanon\n",
      "  - Cristina Esteban Calonje\n",
      "@CrisCalonje\n",
      "  - Mercè Perea Conillas\n",
      "@MercePerea\n",
      "  - VíctorSánchezdelReal\n",
      "@sanchezdelreal\n",
      "·\n",
      "Oct 7, 2021\n",
      "  - Omar Anguita Pérez\n",
      "@AnguitaOmar\n",
      "  - antonio hurtado\n",
      "@AntonioHurtado\n",
      "  - Marisa Saavedra\n",
      "@MarisaSaavedraM\n",
      "  - Juanjo Aizcorbe Torra\n",
      "@JuanjoAizcorbe\n",
      "  - Carlos Rojas García\n",
      "@CarlosRojas_PPA\n",
      "  - Pau Marí-Klose\n",
      "@pmklose\n",
      "  - Roberto Uriarte\n",
      "@RoberUriarte\n",
      "·\n",
      "Sep 26, 2021\n",
      "  - Daniel Senderos/\n",
      "@danielsenderos\n",
      "  - Error al extraer usuario de 1357451089872904192 tras 3 intentos.\n",
      "  - Error al extraer usuario de 1469761173105123338 tras 3 intentos.\n",
      "  - Macarena Olona\n",
      "@Macarena_Olona\n",
      "  - Daniel Senderos/\n",
      "@danielsenderos\n",
      "  - Emilio del Valle\n",
      "@edelvallerod\n",
      "  - Juan López de Uralde\n",
      "@juralde\n",
      "  - Joan Baldoví ;)\n",
      "@joanbaldovi\n",
      "  - Cesar Ramos\n",
      "@CesarJRamos\n",
      "  - Teresa Jiménez-Becerril\n",
      "@teresajbecerril\n",
      "  - Iván Espinosa de los Monteros\n",
      "@ivanedlm\n",
      "·\n",
      "Apr 19, 2021\n",
      "  - Pablo Lolaso\n",
      "@PabloLolaso\n",
      "·\n",
      "Apr 29, 2021\n",
      "  - DAO Makrer\n",
      "@daomakrer\n",
      "·\n",
      "Oct 6, 2021\n",
      "  - Santiago Abascal\n",
      "@Santi_ABASCAL\n",
      "·\n",
      "Apr 24, 2021\n",
      "  - Daniel Senderos/\n",
      "@danielsenderos\n",
      "  - Odón Elorza Activista por la Democracia\n",
      "@odonelorza2011\n",
      "·\n",
      "May 6, 2021\n",
      "  - Víctor González\n",
      "@vicpiedra\n",
      "  - Pablo Casado Blanco\n",
      "@pablocasado_\n",
      "  - Martina Velarde\n",
      "@MartinaVelardeG\n",
      "·\n",
      "Apr 29, 2021\n",
      "  - Juan Cuatrecasas Asúa/\n",
      "@CuatrecasasJuan\n",
      "·\n",
      "Dec 31, 2021\n",
      "  - Pablo Iglesias {R}\n",
      "@PabloIglesias\n",
      "  - Pilar Marcos\n",
      "@pilarmarcosd\n",
      "  - Pilar Marcos\n",
      "@pilarmarcosd\n",
      "  - Sofía Castañón\n",
      "@SofCastanon\n",
      "  - Error al extraer usuario de 1357977951053221889 tras 3 intentos.\n",
      "  - Nieves Ulayar.\n",
      "@nulayar\n",
      "·\n",
      "Mar 10, 2021\n",
      "  - Daniel Senderos/\n",
      "@danielsenderos\n",
      "  - Sara Giménez\n",
      "@SaraGimnez\n",
      "  - José Alcaraz Martos\n",
      "@fjosealcaraz\n",
      "  - ~Gret~\n",
      "@GRET79\n",
      "·\n",
      "Nov 28, 2021\n",
      "  - Pedro Navarro\n",
      "@pedronavarrol\n",
      "  - Rodrigo Jiménez Revuelta\n",
      "@rodrijr111\n",
      "  - Fco. J. Contreras\n",
      "@fjconpe\n",
      "  - Fuensanta Lima\n",
      "@fuensantalima\n",
      "  - Iván Espinosa de los Monteros\n",
      "@ivanedlm\n",
      "  - Íñigo Errejón\n",
      "@ierrejon\n",
      "·\n",
      "Nov 30, 2021\n",
      "  - Reyes Romero\n",
      "@rromerovilches\n",
      "  - Vicente Tirado\n",
      "@vicentetiradopp\n",
      "  - Fco. J. Contreras\n",
      "@fjconpe\n",
      "·\n",
      "Feb 20, 2021\n",
      "  - Arnau Ramírez\n",
      "@arnauramirez\n",
      "  - Ángeles Marra \\\n",
      "@AngelesMarra\n",
      "  - Xavier Eritja Ciuró\n",
      "@xavieritja\n",
      "  - Juan López de Uralde\n",
      "@juralde\n",
      "  - Pau Marí-Klose\n",
      "@pmklose\n",
      "  - PI\n",
      "@PInterinos\n",
      "·\n",
      "Sep 25, 2021\n",
      "  - Victor Píriz Maya\n",
      "@vicpiriz1975\n",
      "  - Error al extraer usuario de 1434445152324620292 tras 3 intentos.\n",
      "  - Marta Martín Llaguno\n",
      "@martamartirio\n",
      "  - Eulàlia Gili\n",
      "@eulaliagili\n",
      "·\n",
      "Sep 27, 2021\n",
      "  - Georgina Trias\n",
      "@georginatrias10\n",
      "  - Daniel Senderos/\n",
      "@danielsenderos\n",
      "  - Daniel Senderos/\n",
      "@danielsenderos\n",
      "  - Javier Ortega Smith\n",
      "@Ortega_Smith\n",
      "  - VíctorSánchezdelReal\n",
      "@sanchezdelreal\n",
      "·\n",
      "Feb 22, 2021\n",
      "  - Error al extraer usuario de 1425793148299714564 tras 3 intentos.\n",
      "  - Fco. J. Contreras\n",
      "@fjconpe\n",
      "  - Laura Borràs\n",
      "@LauraBorras\n",
      "·\n",
      "Feb 23, 2021\n",
      "  - Mariona Illamola Dausà\n",
      "@MarionaID\n",
      "  - Néstor Rego\n",
      "@NestorRego\n",
      "  - José Ramírez del Río ن\n",
      "@joseramirezdel2\n",
      "  - Eduardo Carazo\n",
      "@educarazo\n",
      "  - Marisa Saavedra\n",
      "@MarisaSaavedraM\n",
      "  - Error al extraer usuario de 1416734573644374018 tras 3 intentos.\n",
      "  - Beatriz Micaela Carrillo de los Reyes\n",
      "@BeaMCarrillo\n",
      "  - Sònia Guerra López/\n",
      "@SonyaGuerraLpz\n",
      "  - LuJo\n",
      "@LuJo548014lu\n",
      "·\n",
      "Sep 1, 2021\n",
      "  - Maria Dantas (@mariadantas.bsky.social)\n",
      "@_Maria_Dantas_\n",
      "  - Marta Martín Llaguno\n",
      "@martamartirio\n",
      "  - Laura Berja Vega\n",
      "@lauraberja86\n",
      "  - Pau Marí-Klose\n",
      "@pmklose\n",
      "·\n",
      "Nov 19, 2021\n",
      "  - Pau Marí-Klose\n",
      "@pmklose\n",
      "  - Carmen Riolobos\n",
      "@CarmenRiolobos\n",
      "  - Agustín Almodóbar Barceló\n",
      "@aalmodobar\n",
      "  - Javier Alfonso Cendón\n",
      "@alfonsocendon\n",
      "  - Fco. J. Contreras\n",
      "@fjconpe\n",
      "·\n",
      "Nov 21, 2021\n",
      "  - Mar García Puig\n",
      "@margpuig\n",
      "  - Mariona Illamola Dausà\n",
      "@MarionaID\n",
      "  - Lepetitpep\n",
      "@lepetitpep\n",
      "·\n",
      "Mar 10, 2021\n",
      "  - VíctorSánchezdelReal\n",
      "@sanchezdelreal\n",
      "·\n",
      "May 23, 2021\n",
      "  - Reyes Romero\n",
      "@rromerovilches\n",
      "·\n",
      "Jan 14, 2021\n",
      "  - Lucía Muñoz Dalda\n",
      "@luciadalda\n",
      "  - Patricia Rueda\n",
      "@_patricia_rueda\n",
      "  - Ignacio López Cano\n",
      "@nasholop\n",
      "·\n",
      "Mar 20, 2021\n",
      "  - Macarena Olona\n",
      "@Macarena_Olona\n",
      "  - Rodrigo Jiménez Revuelta\n",
      "@rodrijr111\n",
      "  - Mariona Illamola Dausà\n",
      "@MarionaID\n",
      "  - Daniel Senderos/\n",
      "@danielsenderos\n",
      "  - Eloy Suárez Lamata\n",
      "@eloysuarezl\n",
      "  - Reyes Romero\n",
      "@rromerovilches\n",
      "  - SVQCapital Económica\n",
      "@SVQCapEcon\n",
      "·\n",
      "Nov 2, 2021\n",
      "  - José Alcaraz Martos\n",
      "@fjosealcaraz\n",
      "·\n",
      "Apr 24, 2021\n",
      "  - Jordi Salvador Duch\n",
      "@jsalvadorduch\n",
      "·\n",
      "Mar 23, 2021\n",
      "  - Jaume Alonso-Cuevillas i Sayrol (JACS)\n",
      "@JACS_JaumeACS\n",
      "  - Pablo Montesinos\n",
      "@montesinospablo\n",
      "  - Sergio Gutierrez\n",
      "@Sergio_GP\n",
      "  - Error al extraer usuario de 1366350122574094337 tras 3 intentos.\n",
      "  - Error al extraer usuario de 1362528893517918209 tras 3 intentos.\n",
      "  - VíctorSánchezdelReal\n",
      "@sanchezdelreal\n",
      "  - Reza por un político\n",
      "@rezaporpolitico\n",
      "·\n",
      "Mar 21, 2021\n",
      "  - VíctorSánchezdelReal\n",
      "@sanchezdelreal\n",
      "·\n",
      "Aug 25, 2021\n",
      "  - Íñigo Errejón\n",
      "@ierrejon\n",
      "  - Pablo Casado Blanco\n",
      "@pablocasado_\n",
      "  - Miriam Nogueras\n",
      "@miriamnoguerasM\n",
      "·\n",
      "Apr 23, 2021\n",
      "  - José Alcaraz Martos\n",
      "@fjosealcaraz\n",
      "·\n",
      "Jun 17, 2021\n",
      "  - Fco. J. Contreras\n",
      "@fjconpe\n",
      "·\n",
      "May 3, 2021\n",
      "  - Jaume Alonso-Cuevillas i Sayrol (JACS)\n",
      "@JACS_JaumeACS\n",
      "  - Gerardo Pisarello\n",
      "@G_Pisarello\n",
      "  - Víctor González\n",
      "@vicpiedra\n",
      "  - Valentina Martinez\n",
      "@valentinam\n",
      "  - Kolontai\n",
      "@kolontai1959\n",
      "·\n",
      "Apr 3, 2021\n",
      "  - Arnau Ramírez\n",
      "@arnauramirez\n",
      "  - VíctorSánchezdelReal\n",
      "@sanchezdelreal\n",
      "  - *XPep Caín \"Facta Non Verba\"\n",
      "@ClonPepe\n",
      "·\n",
      "Jun 4, 2021\n",
      "  - Sònia Guerra López/\n",
      "@SonyaGuerraLpz\n",
      "  - Ángel Martínez\n",
      "@angelmartinezx2\n",
      "·\n",
      "Apr 10, 2021\n",
      "  - VíctorSánchezdelReal\n",
      "@sanchezdelreal\n",
      "·\n",
      "Feb 13, 2021\n",
      "  - María Muñoz\n",
      "@mariadelamiel\n",
      "·\n",
      "Feb 18, 2021\n",
      "  - Marta Martín Llaguno\n",
      "@martamartirio\n",
      "  - Ione Belarra\n",
      "@ionebelarra\n",
      "  - Daniel Senderos/\n",
      "@danielsenderos\n",
      "  - VíctorSánchezdelReal\n",
      "@sanchezdelreal\n",
      "  - Ana Pastor Julián\n",
      "@anapastorjulian\n",
      "  - Reza por un político\n",
      "@rezaporpolitico\n",
      "·\n",
      "Aug 16, 2021\n",
      "  - Ana Pastor Julián\n",
      "@anapastorjulian\n",
      "  - Daniel Senderos/\n",
      "@danielsenderos\n",
      "  - Jordi Salvador Duch\n",
      "@jsalvadorduch\n",
      "  - Rocío De Meer ن\n",
      "@MeerRocio\n",
      "  - Meritxell Batet\n",
      "@meritxell_batet\n",
      "  - Ricardo Chamorro Delmo\n",
      "@rchamode\n",
      "  - Pilar Cancela/\n",
      "@PiliCancela\n",
      "·\n",
      "Sep 6, 2021\n",
      "  - Diego Gago Bugarín\n",
      "@DiegoGagoB\n",
      "  - Maria Dantas (@mariadantas.bsky.social)\n",
      "@_Maria_Dantas_\n",
      "  - mjesus moro almaraz\n",
      "@MoroMjesus\n",
      "  - Mercè Perea Conillas\n",
      "@MercePerea\n",
      "  - Daniel Senderos/\n",
      "@danielsenderos\n",
      "  - Beatriz Micaela Carrillo de los Reyes\n",
      "@BeaMCarrillo\n",
      "  - Laura Borràs\n",
      "@LauraBorras\n",
      "·\n",
      "Feb 25, 2021\n",
      "  - VíctorSánchezdelReal\n",
      "@sanchezdelreal\n",
      "  - Mireia Vehí\n",
      "@Mireia_veca\n",
      "  - Antón Gómez-Reino Varela\n",
      "@AntonGomezReino\n",
      "  - Pablo Casado Blanco\n",
      "@pablocasado_\n",
      "  - Odón Elorza Activista por la Democracia\n",
      "@odonelorza2011\n",
      "·\n",
      "Aug 19, 2021\n",
      "  - Marian_Casares /\n",
      "@mariancasaresh\n",
      "·\n",
      "May 19, 2021\n",
      "  - Error al extraer usuario de 1411033490011869189 tras 3 intentos.\n",
      "  - Error al extraer usuario de 1422867705481371648 tras 3 intentos.\n",
      "  - Malena Nevado\n",
      "@malenanevado\n",
      "  - Juan Cuatrecasas Asúa/\n",
      "@CuatrecasasJuan\n",
      "  - Arseni\n",
      "@ArseniLaSeu\n",
      "·\n",
      "Apr 24, 2021\n",
      "  - Juan Luis Soto Buril\n",
      "@juanluissotoadd\n",
      "  - Jose Ramón Ortega\n",
      "@jr0rtega\n",
      "·\n",
      "Apr 10, 2021\n",
      "  - Laura Borràs\n",
      "@LauraBorras\n",
      "·\n",
      "May 8, 2021\n",
      "  - Sonia Sierra\n",
      "@SoniaSierra02\n",
      "·\n",
      "May 3, 2021\n",
      "  - Jaime de Olano\n",
      "@jaimedeolano\n",
      "  - Daniel Senderos/\n",
      "@danielsenderos\n",
      "  - Jaume Alonso-Cuevillas i Sayrol (JACS)\n",
      "@JACS_JaumeACS\n",
      "  - Rafa Lomana\n",
      "@RafaLomana\n",
      "  - Álex Dorado Nájera\n",
      "@DoradoAlex\n",
      "·\n",
      "Feb 23, 2021\n",
      "  - Error al extraer usuario de 1396437893531508737 tras 3 intentos.\n",
      "  - Mireia Vehí\n",
      "@Mireia_veca\n",
      "  - Teresa Jiménez-Becerril\n",
      "@teresajbecerril\n",
      "  - Carolina España\n",
      "@CarolinaEspanaR\n",
      "  - Pablo Hispan\n",
      "@HispanPablo\n",
      "  - Laura Borràs\n",
      "@LauraBorras\n",
      "·\n",
      "Jun 21, 2021\n",
      "  - Pablo Iglesias {R}\n",
      "@PabloIglesias\n",
      "  - Íñigo Errejón\n",
      "@ierrejon\n",
      "  - Bego Nasarre /\n",
      "@Begonasarre\n",
      "  - Roser Maestro\n",
      "@Roser_Maestro\n",
      "  - Laura Borràs\n",
      "@LauraBorras\n",
      "  - Fco. J. Contreras\n",
      "@fjconpe\n",
      "·\n",
      "Oct 20, 2021\n",
      "  - VíctorSánchezdelReal\n",
      "@sanchezdelreal\n",
      "  - Ángeles Marra \\\n",
      "@AngelesMarra\n",
      "  - María Ramallo\n",
      "@MariaRamallov\n",
      "  - Daniel Senderos/\n",
      "@danielsenderos\n",
      "  - Pilar Cancela/\n",
      "@PiliCancela\n",
      "·\n",
      "May 11, 2021\n",
      "  - Francisco Longo\n",
      "@francisco_longo\n",
      "·\n",
      "Feb 6, 2021\n",
      "  - Daniel Senderos/\n",
      "@danielsenderos\n",
      "  - Error al extraer usuario de 1404494869792448524 tras 3 intentos.\n",
      "  - Patricia Rueda\n",
      "@_patricia_rueda\n",
      "  - Yolanda Díaz\n",
      "@Yolanda_Diaz_\n",
      "  - Error al extraer usuario de 1387466653634547716 tras 3 intentos.\n",
      "  - Íñigo Errejón\n",
      "@ierrejon\n",
      "·\n",
      "Feb 15, 2021\n",
      "  - Malena Nevado\n",
      "@malenanevado\n",
      "  - Error al extraer usuario de 1413200007847628801 tras 3 intentos.\n",
      "  - Alicia García\n",
      "@AliciaGarcia_Av\n",
      "  - M Luz Martínez Seijo\n",
      "@luzseijo\n",
      "  - Emilio del Valle\n",
      "@edelvallerod\n",
      "  - Lucía Muñoz Dalda\n",
      "@luciadalda\n",
      "  - Pere Joan Pons Sampietro\n",
      "@perejoanpons\n",
      "·\n",
      "Nov 29, 2021\n",
      "  - Daniel Senderos/\n",
      "@danielsenderos\n",
      "  - Gloria Elizo\n",
      "@GloriaElizo\n",
      "  - Elvira Ramón\n",
      "@ElviraRamon\n",
      "  - Mario Garcés Sanagustín\n",
      "@MarioGarcesSan\n",
      "  - Omar Anguita Pérez\n",
      "@AnguitaOmar\n",
      "  - Helena Caballero\n",
      "@Caballerohelena\n",
      "  - Carol\n",
      "@ElislotedeCaro\n",
      "·\n",
      "Jun 15, 2021\n",
      "  - Despistaku\n",
      "@Despistaku\n",
      "·\n",
      "Nov 10, 2021\n",
      "  - Montse Mínguez\n",
      "@montseminguez\n",
      "  - Víctor González\n",
      "@vicpiedra\n",
      "  - Macarena Olona\n",
      "@Macarena_Olona\n",
      "  - Pau Marí-Klose\n",
      "@pmklose\n",
      "  - Beatriz Muñoz González\n",
      "@45Beatriz\n",
      "·\n",
      "May 26, 2021\n",
      "  - Antònia Jover\n",
      "@Antonia_Jover_\n",
      "  - Matea Fesa\n",
      "@Mateafesa\n",
      "·\n",
      "Apr 19, 2021\n",
      "  - Susana Sumelzo Jordán\n",
      "@SSumelzo\n",
      "  - Santos Cerdán León\n",
      "@santicl\n",
      "  - Ana Pastor Julián\n",
      "@anapastorjulian\n",
      "  - Jaume Alonso-Cuevillas i Sayrol (JACS)\n",
      "@JACS_JaumeACS\n",
      "  - Rodrigo Jiménez Revuelta\n",
      "@rodrijr111\n",
      "  - Bea Fanjul\n",
      "@bea_fanjul\n",
      "  - Omar Anguita Pérez\n",
      "@AnguitaOmar\n",
      "  - Daniel Senderos/\n",
      "@danielsenderos\n",
      "  - Javi Merino\n",
      "@javier_merino\n",
      "  - Íñigo Errejón\n",
      "@ierrejon\n",
      "·\n",
      "Aug 13, 2021\n",
      "  - Inés Sabanés\n",
      "@isabanes\n",
      "  - Maria Dantas (@mariadantas.bsky.social)\n",
      "@_Maria_Dantas_\n",
      "·\n",
      "Feb 17, 2021\n",
      "  - Error al extraer usuario de 1415370753474760705 tras 3 intentos.\n",
      "  - Luis Gestoso\n",
      "@LuisGestoso\n",
      "  - Error al extraer usuario de 1415625819444162563 tras 3 intentos.\n",
      "  - Fco. J. Contreras\n",
      "@fjconpe\n",
      "  - Maria Dantas (@mariadantas.bsky.social)\n",
      "@_Maria_Dantas_\n",
      "  - Txema Guijarro\n",
      "@TxemaGuijarro\n",
      "  - Néstor Rego\n",
      "@NestorRego\n",
      "  - Juan López de Uralde\n",
      "@juralde\n",
      "  - Genís Boadella\n",
      "@GenisBoadella\n",
      "  - Concep Cañadell\n",
      "@conceptermens\n",
      "  - Fco. J. Contreras\n",
      "@fjconpe\n",
      "  - Inés Sabanés\n",
      "@isabanes\n",
      "  - antonio hurtado\n",
      "@AntonioHurtado\n",
      "  - Inés Sabanés\n",
      "@isabanes\n",
      "·\n",
      "Jan 1, 2021\n",
      "  - Ines Granollers\n",
      "@InesGranollers\n",
      "  - Joan Capdevila ن\n",
      "@capdevilajoan\n",
      "  - Cristina Esteban Calonje\n",
      "@CrisCalonje\n",
      "  - Odón Elorza Activista por la Democracia\n",
      "@odonelorza2011\n",
      "·\n",
      "Nov 20, 2021\n",
      "  - Agustín Almodóbar Barceló\n",
      "@aalmodobar\n",
      "  - Mercè Perea Conillas\n",
      "@MercePerea\n",
      "  - Daniel Senderos/\n",
      "@danielsenderos\n",
      "  - Luis Gestoso\n",
      "@LuisGestoso\n",
      "  - Presidenta Laura Borràs\n",
      "@mhp_LauraBorras\n",
      "·\n",
      "Nov 2, 2021\n",
      "  - José Alcaraz Martos\n",
      "@fjosealcaraz\n",
      "  - Fco. J. Contreras\n",
      "@fjconpe\n",
      "  - Maria Dantas (@mariadantas.bsky.social)\n",
      "@_Maria_Dantas_\n",
      "·\n",
      "Dec 10, 2021\n",
      "  - Jaume Asens\n",
      "@Jaumeasens\n",
      "  - Marta Martín Llaguno\n",
      "@martamartirio\n",
      "  - Carla Toscano\n",
      "@eledhmel\n",
      "·\n",
      "Aug 16, 2021\n",
      "  - Alberto Rodríguez\n",
      "@Alber_Canarias\n",
      "·\n",
      "Apr 10, 2021\n",
      "  - Odón Elorza Activista por la Democracia\n",
      "@odonelorza2011\n",
      "  - VOX Sevilla\n",
      "@VOXSevilla_\n",
      "·\n",
      "Feb 24, 2021\n",
      "  - Ana Vázquez Blanco\n",
      "@anadebande\n",
      "  - Pilar Marcos\n",
      "@pilarmarcosd\n",
      "  - Maria Dantas (@mariadantas.bsky.social)\n",
      "@_Maria_Dantas_\n",
      "  - Mireia Vehí\n",
      "@Mireia_veca\n",
      "  - Marga Prohens\n",
      "@MargaProhens\n",
      "  - Ana Pastor Julián\n",
      "@anapastorjulian\n",
      "  - Error al extraer usuario de 1411059798062338049 tras 3 intentos.\n",
      "  - Pau Marí-Klose\n",
      "@pmklose\n",
      "·\n",
      "Mar 20, 2021\n",
      "  - Inés Arrimadas\n",
      "@InesArrimadas\n",
      "  - Carla Toscano\n",
      "@eledhmel\n",
      "  - \n",
      "  - Sònia Guerra López/\n",
      "@SonyaGuerraLpz\n",
      "  - X\n",
      "@brain__teaser\n",
      "·\n",
      "Jul 5, 2021\n",
      "  - Error al extraer usuario de 1445458943312994309 tras 3 intentos.\n",
      "  - aitor\n",
      "@aitoribar18\n",
      "·\n",
      "Nov 17, 2021\n",
      "  - Ana Vázquez Blanco\n",
      "@anadebande\n",
      "  - Daniel Senderos/\n",
      "@danielsenderos\n",
      "  - antonio hurtado\n",
      "@AntonioHurtado\n",
      "  - VíctorSánchezdelReal\n",
      "@sanchezdelreal\n",
      "·\n",
      "Jan 2, 2021\n",
      "  - Daniel Senderos/\n",
      "@danielsenderos\n",
      "  - Error al extraer usuario de 1440008163231739909 tras 3 intentos.\n",
      "  - Pedro Navarro\n",
      "@pedronavarrol\n",
      "  - Daniel Senderos/\n",
      "@danielsenderos\n",
      "  - Marcos de Quinto\n",
      "@MarcosdeQuinto\n",
      "·\n",
      "Mar 29, 2021\n",
      "  - Pablo Cambronero\n",
      "@PabloCamPiq\n",
      "·\n",
      "Feb 4, 2021\n",
      "  - Pedro Casares\n",
      "@pedro_casares\n",
      "  - Error al extraer usuario de 1434627749696638980 tras 3 intentos.\n",
      "  - Error al extraer usuario de 1433014611578691584 tras 3 intentos.\n",
      "  - Gloria Elizo\n",
      "@GloriaElizo\n",
      "  - Macarena Olona\n",
      "@Macarena_Olona\n",
      "  - Carla Toscano\n",
      "@eledhmel\n",
      "  - Marta Martín Llaguno\n",
      "@martamartirio\n",
      "  - LA GACETA\n",
      "@gaceta_es\n",
      "·\n",
      "Jan 31, 2021\n",
      "  - Pedro Casares\n",
      "@pedro_casares\n",
      "  - Reyes Romero\n",
      "@rromerovilches\n",
      "  - Cesar Ramos\n",
      "@CesarJRamos\n",
      "  - VíctorSánchezdelReal\n",
      "@sanchezdelreal\n",
      "·\n",
      "Aug 26, 2021\n",
      "  - Pablo Iglesias {R}\n",
      "@PabloIglesias\n",
      "  - Emilio del Valle\n",
      "@edelvallerod\n",
      "  - Mertxe Aizpurua\n",
      "@MertxeAizpurua\n",
      "  - Victor Píriz Maya\n",
      "@vicpiriz1975\n",
      "  - Barbijaputa\n",
      "@Barbijaputa\n",
      "·\n",
      "Mar 17, 2021\n",
      "  - Maria Dantas (@mariadantas.bsky.social)\n",
      "@_Maria_Dantas_\n",
      "  - Emilio del Valle\n",
      "@edelvallerod\n",
      "  - Daniel Senderos/\n",
      "@danielsenderos\n",
      "  - Meritxell Batet\n",
      "@meritxell_batet\n",
      "  - Pilar Marcos\n",
      "@pilarmarcosd\n",
      "·\n",
      "Jul 14, 2021\n",
      "  - Error al extraer usuario de 1430827446354522113 tras 3 intentos.\n",
      "  - VíctorSánchezdelReal\n",
      "@sanchezdelreal\n",
      "  - Jesús G. CONDE\n",
      "@JGCdelCastillo\n",
      "·\n",
      "Dec 3, 2021\n",
      "  - Joan Baldoví ;)\n",
      "@joanbaldovi\n",
      "  - Ana Vázquez Blanco\n",
      "@anadebande\n",
      "  - Jon Inarritu\n",
      "@JonInarritu\n",
      "  - Alberto Garzón\n",
      "@agarzon\n",
      "  - Jose Luis Aceves/\n",
      "@JLAceves\n",
      "  - Victor Píriz Maya\n",
      "@vicpiriz1975\n",
      "·\n",
      "Nov 7, 2021\n",
      "  - Laura Borràs\n",
      "@LauraBorras\n",
      "·\n",
      "Nov 6, 2021\n",
      "  - Pedro Sánchez\n",
      "@sanchezcastejon\n",
      "·\n",
      "Sep 9, 2021\n",
      "  - Sofía Castañón\n",
      "@SofCastanon\n",
      "  - Error al extraer usuario de 1388425145258332163 tras 3 intentos.\n",
      "  - Santos Cerdán León\n",
      "@santicl\n",
      "  - Juan López de Uralde\n",
      "@juralde\n",
      "  - Aitor Arranz Sanz\n",
      "@sanz_arranz\n",
      "·\n",
      "Sep 6, 2021\n",
      "  - Lucía Muñoz Dalda\n",
      "@luciadalda\n",
      "  - Laura Borràs\n",
      "@LauraBorras\n",
      "  - Alberto Garzón\n",
      "@agarzon\n",
      "  - Isabel Franco ۞\n",
      "@Isabel_Franco_\n",
      "  - NUET\n",
      "@NUET\n",
      "  - Pablo Casado Blanco\n",
      "@pablocasado_\n",
      "  - Ana Pastor Julián\n",
      "@anapastorjulian\n",
      "  - Alfonso R Gómez Celis\n",
      "@gomezdcelis\n",
      "  - Daniel Senderos/\n",
      "@danielsenderos\n",
      "  - Pau Marí-Klose\n",
      "@pmklose\n",
      "·\n",
      "Oct 22, 2021\n",
      "  - Tomàs Bordoy\n",
      "@tomasbordoy\n",
      "·\n",
      "Mar 14, 2021\n",
      "  - Daniel Senderos/\n",
      "@danielsenderos\n",
      "  - Marta Martín Llaguno\n",
      "@martamartirio\n",
      "  - sol cruz guzman\n",
      "@solcruzguzman\n",
      "  - Error al extraer usuario de 1453038792978411522 tras 3 intentos.\n",
      "  - Rubén Esteban Pérez\n",
      "@Ruben_ICOG\n",
      "·\n",
      "Jun 17, 2021\n",
      "  - Iván Espinosa de los Monteros\n",
      "@ivanedlm\n",
      "  - Irene Varela\n",
      "@irenevarela6\n",
      "·\n",
      "Apr 7, 2021\n",
      "  - Error al extraer usuario de 1430228603862650884 tras 3 intentos.\n",
      "  - El Cinéfago Gerardo MAGRO\n",
      "@ElCinefago\n",
      "·\n",
      "Jan 8, 2021\n",
      "  - Error al extraer usuario de 1430219593964994566 tras 3 intentos.\n",
      "  - PSOE Congreso\n",
      "@gpscongreso\n",
      "·\n",
      "Jun 13, 2021\n",
      "  - Mireia Borrás\n",
      "@_mireiaborras\n",
      "  - Inés Arrimadas\n",
      "@InesArrimadas\n",
      "  - Ignacio López Cano\n",
      "@nasholop\n",
      "  - Malena Nevado\n",
      "@malenanevado\n",
      "  - Amparo Rubiales\n",
      "@AmparoRubiales\n",
      "·\n",
      "Mar 1, 2021\n",
      "  - Tu abandono me puede MATAR\n",
      "@tu_abandono\n",
      "·\n",
      "Feb 7, 2021\n",
      "  - VíctorSánchezdelReal\n",
      "@sanchezdelreal\n",
      "·\n",
      "Aug 20, 2021\n",
      "  - Sofía Castañón\n",
      "@SofCastanon\n",
      "  - José Ramírez del Río ن\n",
      "@joseramirezdel2\n",
      "  - Javi Merino\n",
      "@javier_merino\n",
      "  - Emilio del Valle\n",
      "@edelvallerod\n",
      "·\n",
      "Nov 1, 2021\n",
      "  - sol cruz guzman\n",
      "@solcruzguzman\n",
      "  - Daniel Senderos/\n",
      "@danielsenderos\n",
      "  - Pablo Casado Blanco\n",
      "@pablocasado_\n",
      "  - Victor Píriz Maya\n",
      "@vicpiriz1975\n",
      "  - Error al extraer usuario de 1430571133372452867 tras 3 intentos.\n",
      "  - Pablo Casado Blanco\n",
      "@pablocasado_\n",
      "  - Martina Velarde\n",
      "@MartinaVelardeG\n",
      "  - Carlota Merchán\n",
      "@CarlotaMerchn\n",
      "·\n",
      "Nov 14, 2021\n",
      "  - Pablo Stefanoni\n",
      "@PabloAStefanoni\n",
      "·\n",
      "Apr 23, 2021\n",
      "  - José Alcaraz Martos\n",
      "@fjosealcaraz\n",
      "  - Mckenzie\n",
      "@manessacr\n",
      "·\n",
      "Feb 19, 2021\n",
      "  - Lídia Guinart Moreno/\n",
      "@lidiaguinart\n",
      "  - Gloria Elizo\n",
      "@GloriaElizo\n",
      "  - Teodoro García Egea\n",
      "@TeoGarciaEgea\n",
      "  - Odón Elorza Activista por la Democracia\n",
      "@odonelorza2011\n",
      "·\n",
      "Jul 13, 2021\n",
      "  - Daniel Senderos/\n",
      "@danielsenderos\n",
      "  - Mario Garcés Sanagustín\n",
      "@MarioGarcesSan\n",
      "  - Pepe Ortiz Vejer\n",
      "@vejer_ortiz\n",
      "  - Macarena Montesinos de Miguel\n",
      "@MackMontesinos\n",
      "  - Victor Píriz Maya\n",
      "@vicpiriz1975\n",
      "  - Cristina Esteban Calonje\n",
      "@CrisCalonje\n",
      "  - Cesar Ramos\n",
      "@CesarJRamos\n",
      "·\n",
      "Mar 10, 2021\n",
      "  - Ricardo Chamorro Delmo\n",
      "@rchamode\n",
      "·\n",
      "Mar 8, 2021\n",
      "  - Fco. J. Contreras\n",
      "@fjconpe\n",
      "·\n",
      "Jan 8, 2021\n",
      "  - Ricardo Chamorro Delmo\n",
      "@rchamode\n",
      "  - Malena Nevado\n",
      "@malenanevado\n",
      "·\n",
      "Nov 17, 2021\n",
      "  - Cristina Esteban Calonje\n",
      "@CrisCalonje\n",
      "·\n",
      "Jan 2, 2021\n",
      "  - Sergio Sayas\n",
      "@sergiosayas\n",
      "  - Daniel Senderos/\n",
      "@danielsenderos\n",
      "  - Santiago Abascal\n",
      "@Santi_ABASCAL\n",
      "  - María Muñoz\n",
      "@mariadelamiel\n",
      "  - Agustín Almodóbar Barceló\n",
      "@aalmodobar\n",
      "  - Daniel Senderos/\n",
      "@danielsenderos\n",
      "  - antonio hurtado\n",
      "@AntonioHurtado\n",
      "  - Laura Borràs\n",
      "@LauraBorras\n",
      "·\n",
      "Nov 14, 2021\n",
      "  - Fco. J. Contreras\n",
      "@fjconpe\n",
      "  - Pau Marí-Klose\n",
      "@pmklose\n",
      "  - VíctorSánchezdelReal\n",
      "@sanchezdelreal\n",
      "·\n",
      "Aug 29, 2021\n",
      "  - Cesar Ramos\n",
      "@CesarJRamos\n",
      "  - P. Juan Manuel Góngora\n",
      "@patergongora\n",
      "·\n",
      "Jan 22, 2021\n",
      "  - Marisol Sánchez Jódar\n",
      "@msolsj\n",
      "  - Mercè Perea Conillas\n",
      "@MercePerea\n",
      "  - Daniel Senderos/\n",
      "@danielsenderos\n",
      "  - Aina Vidal Sáez\n",
      "@AinaVS\n",
      "  - Teresa Jiménez-Becerril\n",
      "@teresajbecerril\n",
      "  - Juan López de Uralde\n",
      "@juralde\n",
      "  - José Ignacio Echániz\n",
      "@JIEchaniz\n",
      "  - Error al extraer usuario de 1348013526183522308 tras 3 intentos.\n",
      "  - Vicente Tirado\n",
      "@vicentetiradopp\n",
      "  - Inés Sabanés\n",
      "@isabanes\n",
      "  - Maria Dantas (@mariadantas.bsky.social)\n",
      "@_Maria_Dantas_\n",
      "·\n",
      "Mar 25, 2021\n",
      "  - VíctorSánchezdelReal\n",
      "@sanchezdelreal\n",
      "  - Iván Espinosa de los Monteros\n",
      "@ivanedlm\n",
      "  - Rosa Romero\n",
      "@rosaromerocr\n",
      "  - Reyes Romero\n",
      "@rromerovilches\n",
      "  - Fco. J. Contreras\n",
      "@fjconpe\n",
      "  - Daniel Senderos/\n",
      "@danielsenderos\n",
      "·\n",
      "Aug 19, 2021\n",
      "  - Javier Sánchez Serna\n",
      "@J_Sanchez_Serna\n",
      "  - Laura Borràs\n",
      "@LauraBorras\n",
      "  - Error al extraer usuario de 1371179416152379394 tras 3 intentos.\n",
      "  - Pablo Calvo Liste\n",
      "@pcalvoliste\n",
      "  - VíctorSánchezdelReal\n",
      "@sanchezdelreal\n",
      "  - Teodoro García Egea\n",
      "@TeoGarciaEgea\n",
      "  - Error al extraer usuario de 1465763703220019202 tras 3 intentos.\n",
      "  - Montserrat Caupena\n",
      "@Montcau\n",
      "·\n",
      "Dec 3, 2021\n",
      "  - Error al extraer usuario de 1363590627800330240 tras 3 intentos.\n",
      "  - VíctorSánchezdelReal\n",
      "@sanchezdelreal\n",
      "·\n",
      "Mar 27, 2021\n",
      "  - Toni Aira\n",
      "@toniaira\n",
      "·\n",
      "Feb 19, 2021\n",
      "  - Pedro Casares\n",
      "@pedro_casares\n",
      "  - Joan Mena\n",
      "@joanmena\n",
      "  - Gloria Elizo\n",
      "@GloriaElizo\n",
      "  - VíctorSánchezdelReal\n",
      "@sanchezdelreal\n",
      "·\n",
      "Sep 18, 2021\n",
      "  - Miriam Nogueras\n",
      "@miriamnoguerasM\n",
      "  - Daniel Senderos/\n",
      "@danielsenderos\n",
      "  - Mariona Illamola Dausà\n",
      "@MarionaID\n",
      "  - Juan López de Uralde\n",
      "@juralde\n",
      "  - Juan Cuatrecasas Asúa/\n",
      "@CuatrecasasJuan\n",
      "  - Ana Vázquez Blanco\n",
      "@anadebande\n",
      "  - Belén Fernández/\n",
      "@BelenFCasero\n",
      "  - Maria Dantas (@mariadantas.bsky.social)\n",
      "@_Maria_Dantas_\n",
      "  - VOX Cataluña\n",
      "@VOX_Cataluna\n",
      "·\n",
      "Mar 12, 2021\n",
      "  - Alberto Garzón\n",
      "@agarzon\n",
      "  - Rosa Romero\n",
      "@rosaromerocr\n",
      "  - Daniel Senderos/\n",
      "@danielsenderos\n",
      "  - Laura Borràs\n",
      "@LauraBorras\n",
      "·\n",
      "May 26, 2021\n",
      "  - Héctor Gómez\n",
      "@Hectorgomezh\n",
      "  - Omar Anguita Pérez\n",
      "@AnguitaOmar\n",
      "  - Pilar Rahola\n",
      "@RaholaOficial\n",
      "·\n",
      "Jun 10, 2021\n",
      "  - VilaWeb\n",
      "@VilaWeb\n",
      "·\n",
      "Mar 26, 2021\n",
      "  - Odón Elorza Activista por la Democracia\n",
      "@odonelorza2011\n",
      "  - Daniel Senderos/\n",
      "@danielsenderos\n",
      "  - Alfonso R Gómez Celis\n",
      "@gomezdcelis\n",
      "  - Gabriel Rufián\n",
      "@gabrielrufian\n",
      "  - Cuca Gamarra\n",
      "@cucagamarra\n",
      "  - Maria Dantas (@mariadantas.bsky.social)\n",
      "@_Maria_Dantas_\n",
      "  - Meritxell Batet\n",
      "@meritxell_batet\n",
      "·\n",
      "Nov 26, 2021\n",
      "  - Jose Luis Aceves/\n",
      "@JLAceves\n",
      "  - Juanjo Aizcorbe Torra\n",
      "@JuanjoAizcorbe\n",
      "  - Íñigo Errejón\n",
      "@ierrejon\n",
      "  - África Moreno\n",
      "@AfricaMoreno\n",
      "·\n",
      "Aug 28, 2021\n",
      "  - Daniel Senderos/\n",
      "@danielsenderos\n",
      "  - Andrea Fernández.\n",
      "@afernb\n",
      "·\n",
      "Mar 8, 2021\n",
      "  - M Luz Martínez Seijo\n",
      "@luzseijo\n",
      "  - Macarena Olona\n",
      "@Macarena_Olona\n",
      "  - Macarena Olona\n",
      "@Macarena_Olona\n",
      "  - Fco. J. Contreras\n",
      "@fjconpe\n",
      "  - Emilio del Valle\n",
      "@edelvallerod\n",
      "  - Gabriel Rufián\n",
      "@gabrielrufian\n",
      "  - Eneko Andueza\n",
      "@enekoandueza\n",
      "·\n",
      "Oct 31, 2021\n",
      "  - Error al extraer usuario de 1448923922351656962 tras 3 intentos.\n",
      "  - Odón Elorza Activista por la Democracia\n",
      "@odonelorza2011\n",
      "·\n",
      "Dec 22, 2021\n",
      "  - Daniel Senderos/\n",
      "@danielsenderos\n",
      "  - Daniel Senderos/\n",
      "@danielsenderos\n",
      "  - Malena Nevado\n",
      "@malenanevado\n",
      "  - Ines Granollers\n",
      "@InesGranollers\n",
      "  - Daniel Senderos/\n",
      "@danielsenderos\n",
      "  - Error al extraer usuario de 1423604369623326723 tras 3 intentos.\n",
      "  - Isidro M. Oblanca\n",
      "@imoblanca\n",
      "  - Fuensanta Lima\n",
      "@fuensantalima\n",
      "  - Leire Díez\n",
      "@leirediezpas\n",
      "·\n",
      "Mar 31, 2021\n",
      "  - Joan Margall Sastre\n",
      "@joanmargall\n",
      "  - Ana Zurita\n",
      "@AnaZurita7\n",
      "  - Error al extraer usuario de 1454109910241849350 tras 3 intentos.\n",
      "  - Laura Borràs\n",
      "@LauraBorras\n",
      "  - Jose Ramón Ortega\n",
      "@jr0rtega\n",
      "·\n",
      "Aug 21, 2021\n",
      "  - Eva Patricia Bueno/\n",
      "@evapatriciab\n",
      "  - VíctorSánchezdelReal\n",
      "@sanchezdelreal\n",
      "·\n",
      "May 4, 2021\n",
      "  - Luis Faci\n",
      "@lfaci\n",
      "·\n",
      "Dec 5, 2021\n",
      "  - Carmen Riolobos\n",
      "@CarmenRiolobos\n",
      "  - Aina Vidal Sáez\n",
      "@AinaVS\n",
      "·\n",
      "Feb 4, 2021\n",
      "  - Reyes Romero\n",
      "@rromerovilches\n",
      "  - Pilar Cancela/\n",
      "@PiliCancela\n",
      "  - JPB\n",
      "@PouBoada\n",
      "·\n",
      "May 13, 2021\n",
      "  - Íñigo Errejón\n",
      "@ierrejon\n",
      "·\n",
      "Dec 14, 2021\n",
      "  - Daniel Senderos/\n",
      "@danielsenderos\n",
      "  - Carlos Rojas García\n",
      "@CarlosRojas_PPA\n",
      "  - Lucía Muñoz Dalda\n",
      "@luciadalda\n",
      "  - Pilar Cancela/\n",
      "@PiliCancela\n",
      "·\n",
      "Apr 10, 2021\n",
      "  - Daniel Senderos/\n",
      "@danielsenderos\n",
      "  - Daniel Senderos/\n",
      "@danielsenderos\n",
      "  - Reyes Romero\n",
      "@rromerovilches\n",
      "  - Pablo Calvo Liste\n",
      "@pcalvoliste\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Ruta al archivo generado previamente\n",
    "INPUT_JSON = 'spain/Completado/tweets_españoles_evaluados_completo.json'\n",
    "\n",
    "with open(INPUT_JSON, encoding='utf-8') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "num_users = len(data)\n",
    "total_tweets = 0\n",
    "total_replies = 0\n",
    "users_sin_tweets = []\n",
    "\n",
    "for entry in data:\n",
    "    tweets = entry.get('tweets', [])\n",
    "    total_tweets += len(tweets)\n",
    "\n",
    "    if not tweets:\n",
    "        users_sin_tweets.append(entry['user'])\n",
    "\n",
    "    for tweet in tweets:\n",
    "        replies = tweet.get('replies', [])\n",
    "        total_replies += len(replies)\n",
    "\n",
    "# Cálculo de media de replies por tweet\n",
    "avg_replies = total_replies / total_tweets if total_tweets > 0 else 0\n",
    "\n",
    "# Resultados\n",
    "print(\"📊 Estadísticas generales\")\n",
    "print(f\"👤 Número de usuarios:       {num_users}\")\n",
    "print(f\"💬 Total de tweets:          {total_tweets}\")\n",
    "print(f\"💭 Total de respuestas:      {total_replies}\")\n",
    "print(f\"📈 Promedio respuestas/tweet:{avg_replies:.2f}\")\n",
    "\n",
    "# Usuarios sin tweets\n",
    "if users_sin_tweets:\n",
    "    print(\"\\n⚠️ Usuarios sin tweets:\")\n",
    "    for name in users_sin_tweets:\n",
    "        print(f\"  - {name}\")\n",
    "else:\n",
    "    print(\"\\n✅ Todos los usuarios tienen al menos un tweet.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "461d8295-951b-48fc-9aec-7dd9eecadd87",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'tweets_españoles_evaluados_completo.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[30]\u001b[39m\u001b[32m, line 19\u001b[39m\n\u001b[32m     16\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(POLITICOS_PATH, \u001b[33m\"\u001b[39m\u001b[33mr\u001b[39m\u001b[33m\"\u001b[39m, encoding=\u001b[33m\"\u001b[39m\u001b[33mutf-8\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[32m     17\u001b[39m     politicos = json.load(f)\n\u001b[32m---> \u001b[39m\u001b[32m19\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mTWEETS_PATH\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mr\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mutf-8\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[32m     20\u001b[39m     tweets_data = json.load(f)\n\u001b[32m     22\u001b[39m \u001b[38;5;66;03m# — Agrupar tweets por @usuario —\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/tljh/user/lib/python3.12/site-packages/IPython/core/interactiveshell.py:325\u001b[39m, in \u001b[36m_modified_open\u001b[39m\u001b[34m(file, *args, **kwargs)\u001b[39m\n\u001b[32m    318\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[32m0\u001b[39m, \u001b[32m1\u001b[39m, \u001b[32m2\u001b[39m}:\n\u001b[32m    319\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    320\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mIPython won\u001b[39m\u001b[33m'\u001b[39m\u001b[33mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m by default \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    321\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    322\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33myou can use builtins\u001b[39m\u001b[33m'\u001b[39m\u001b[33m open.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    323\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m325\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: 'tweets_españoles_evaluados_completo.json'"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import unicodedata\n",
    "\n",
    "# — Rutas de entrada y salida —\n",
    "POLITICOS_PATH = \"spain/politicos_españoles_con_edad.json\"\n",
    "TWEETS_PATH = \"tweets_españoles_evaluados_completo.json\"\n",
    "OUTPUT_PATH = \"politicos_con_tweets_completos.json\"\n",
    "\n",
    "# — Función de normalización —\n",
    "def normalize(text):\n",
    "    text = text.lower().strip()\n",
    "    text = unicodedata.normalize(\"NFKD\", text)\n",
    "    return ''.join(c for c in text if not unicodedata.combining(c))\n",
    "\n",
    "# — Cargar archivos —\n",
    "with open(POLITICOS_PATH, \"r\", encoding=\"utf-8\") as f:\n",
    "    politicos = json.load(f)\n",
    "\n",
    "with open(TWEETS_PATH, \"r\", encoding=\"utf-8\") as f:\n",
    "    tweets_data = json.load(f)\n",
    "\n",
    "# — Agrupar tweets por @usuario —\n",
    "def construir_tweet(tweet):\n",
    "    return {\n",
    "        \"id\": tweet.get(\"id\"),\n",
    "        \"text\": tweet.get(\"tweet\"),\n",
    "        \"valoration\": tweet.get(\"analysis\", {}),\n",
    "        \"replies\": tweet.get(\"replies\", [])\n",
    "    }\n",
    "\n",
    "tweets_por_user = {}\n",
    "for tw in tweets_data:\n",
    "    raw_user = tw.get(\"user\", \"\")\n",
    "    if not raw_user or raw_user.startswith(\"Error\"):\n",
    "        continue\n",
    "\n",
    "    # Extraer el @handle\n",
    "    tokens = raw_user.split()\n",
    "    handle = next((t for t in reversed(tokens) if t.startswith(\"@\")), None)\n",
    "    if not handle:\n",
    "        continue\n",
    "\n",
    "    if handle not in tweets_por_user:\n",
    "        tweets_por_user[handle] = []\n",
    "\n",
    "    tweets_por_user[handle].append(construir_tweet(tw))\n",
    "\n",
    "# — Fusionar políticos con tweets —\n",
    "with open(\"users_españoles.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    user_map = json.load(f)\n",
    "\n",
    "# Mapeo rápido: @usuario → nombre normalizado\n",
    "handle_to_normname = {u['user']: normalize(u['name']) for u in user_map}\n",
    "\n",
    "# Generar resultado\n",
    "final = []\n",
    "for p in politicos:\n",
    "    normname = normalize(p['name'])\n",
    "    handle = next((h for h, n in handle_to_normname.items() if n == normname), None)\n",
    "\n",
    "    tweets = tweets_por_user.get(handle, []) if handle else []\n",
    "\n",
    "    final.append({\n",
    "        \"name\": p[\"name\"],\n",
    "        \"user\": handle,\n",
    "        \"party\": p.get(\"party\"),\n",
    "        \"age\": p.get(\"age\"),\n",
    "        \"gender\": p.get(\"gender\"),\n",
    "        \"tweets\": tweets\n",
    "    })\n",
    "\n",
    "# — Guardar JSON final —\n",
    "with open(OUTPUT_PATH, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(final, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "print(f\"✅ JSON final generado en: {OUTPUT_PATH}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "417d019b-bc98-4228-a705-5b65b8faee32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archivo guardado como: grecia_anotados/politicos_griegos.json\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Ruta del archivo Excel de entrada\n",
    "input_excel = \"grecia_anotados/politicos_griegos.xlsx\"  # Cambia por tu archivo\n",
    "\n",
    "# Leer la hoja (puedes especificar sheet_name si hay varias hojas)\n",
    "df = pd.read_excel(input_excel)\n",
    "\n",
    "# Convertir a JSON y guardar\n",
    "output_json = \"grecia_anotados/politicos_griegos.json\"\n",
    "df.to_json(output_json, orient=\"records\", force_ascii=False, indent=2)\n",
    "\n",
    "print(f\"Archivo guardado como: {output_json}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e1e2c703-cfa6-4972-b4b7-a59a9f9945e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c7055c04fec43c5b478dc595637ba2c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.10.0.json:   0%|  …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-29 21:23:56 INFO: Downloaded file to /home/jupyter-lquijano/stanza_resources/resources.json\n",
      "2025-04-29 21:23:56 INFO: Downloading default packages for language: es (Spanish) ...\n",
      "2025-04-29 21:23:57 INFO: File exists: /home/jupyter-lquijano/stanza_resources/es/default.zip\n",
      "2025-04-29 21:24:01 INFO: Finished downloading models and saved to /home/jupyter-lquijano/stanza_resources\n",
      "2025-04-29 21:24:01 INFO: Checking for updates to resources.json in case models have been updated.  Note: this behavior can be turned off with download_method=None or download_method=DownloadMethod.REUSE_RESOURCES\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12b9b5aac5c3474780bf0d4c1af1ab2d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.10.0.json:   0%|  …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-29 21:24:01 INFO: Downloaded file to /home/jupyter-lquijano/stanza_resources/resources.json\n",
      "2025-04-29 21:24:01 WARNING: Language es package default expects mwt, which has been added\n",
      "2025-04-29 21:24:01 INFO: Loading these models for language: es (Spanish):\n",
      "===============================\n",
      "| Processor | Package         |\n",
      "-------------------------------\n",
      "| tokenize  | combined        |\n",
      "| mwt       | combined        |\n",
      "| pos       | combined_charlm |\n",
      "===============================\n",
      "\n",
      "2025-04-29 21:24:01 INFO: Using device: cpu\n",
      "2025-04-29 21:24:01 INFO: Loading: tokenize\n",
      "2025-04-29 21:24:01 INFO: Loading: mwt\n",
      "2025-04-29 21:24:01 INFO: Loading: pos\n",
      "2025-04-29 21:24:03 INFO: Done loading processors!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Archivo enriquecido guardado como: tweets_features_stanza.json\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import stanza\n",
    "\n",
    "# Paso 1: Descargar modelos si es necesario\n",
    "stanza.download(\"es\")\n",
    "\n",
    "# Paso 2: Inicializar el pipeline de Stanza para español\n",
    "nlp = stanza.Pipeline(\"es\", processors=\"tokenize,pos\", use_gpu=False)\n",
    "\n",
    "# Paso 3: Cargar archivo Excel\n",
    "archivo_excel = \"spain/Tweets_etiquetados.xlsx\"\n",
    "df = pd.read_excel(archivo_excel)\n",
    "\n",
    "# Paso 4: Procesar cada tweet\n",
    "resultados = []\n",
    "\n",
    "for _, row in df.iterrows():\n",
    "    tweet_text = str(row[\"text\"])\n",
    "    user = str(row[\"id\"]) if \"id\" in row else \"desconocido\"\n",
    "\n",
    "    # POS tagging con Stanza\n",
    "    doc = nlp(tweet_text)\n",
    "    pos_tags = []\n",
    "    counts = {\"DET\": 0, \"NOUN\": 0, \"VERB\": 0, \"ADJ\": 0, \"PROPN\": 0, \"PRON\": 0}\n",
    "\n",
    "    first_word_pos = None\n",
    "\n",
    "    for sentence in doc.sentences:\n",
    "        for idx, word in enumerate(sentence.words):\n",
    "            pos_tags.append({\n",
    "                \"text\": word.text,\n",
    "                \"pos\": word.upos\n",
    "            })\n",
    "            if word.upos in counts:\n",
    "                counts[word.upos] += 1\n",
    "            if first_word_pos is None and idx == 0:\n",
    "                first_word_pos = word.upos\n",
    "\n",
    "    # Paso 5: Construir el diccionario de salida SIN buscar partidos\n",
    "    resultados.append({\n",
    "        \"id\": user,\n",
    "        \"tweet\": tweet_text,\n",
    "        \"num_determinantes\": counts[\"DET\"],\n",
    "        \"num_nouns\": counts[\"NOUN\"],\n",
    "        \"num_verbs\": counts[\"VERB\"],\n",
    "        \"num_adjectives\": counts[\"ADJ\"],\n",
    "        \"num_proper_nouns\": counts[\"PROPN\"],\n",
    "        \"starts_with_pronoun\": first_word_pos == \"PRON\",\n",
    "        \"ratio_noun_to_verb\": round(counts[\"NOUN\"] / counts[\"VERB\"], 2) if counts[\"VERB\"] > 0 else None\n",
    "    })\n",
    "\n",
    "# Paso 6: Guardar el resultado en JSON\n",
    "output_file = \"tweets_features_stanza.json\"\n",
    "with open(output_file, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(resultados, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "print(f\"✅ Archivo enriquecido guardado como: {output_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4206332a-0cb2-44bf-a3d4-53bc13fc051f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c16e9addbde242c488b8dac86146605d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.10.0.json:   0%|  …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-29 21:48:42 INFO: Downloaded file to /home/jupyter-lquijano/stanza_resources/resources.json\n",
      "2025-04-29 21:48:42 INFO: Downloading default packages for language: el (Greek) ...\n",
      "2025-04-29 21:48:43 INFO: File exists: /home/jupyter-lquijano/stanza_resources/el/default.zip\n",
      "2025-04-29 21:48:44 INFO: Finished downloading models and saved to /home/jupyter-lquijano/stanza_resources\n",
      "2025-04-29 21:48:44 INFO: Checking for updates to resources.json in case models have been updated.  Note: this behavior can be turned off with download_method=None or download_method=DownloadMethod.REUSE_RESOURCES\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b819ae693a2340659f075897cb947f15",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.10.0.json:   0%|  …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-29 21:48:44 INFO: Downloaded file to /home/jupyter-lquijano/stanza_resources/resources.json\n",
      "2025-04-29 21:48:44 WARNING: Language el package default expects mwt, which has been added\n",
      "2025-04-29 21:48:44 INFO: Loading these models for language: el (Greek):\n",
      "============================\n",
      "| Processor | Package      |\n",
      "----------------------------\n",
      "| tokenize  | gdt          |\n",
      "| mwt       | gdt          |\n",
      "| pos       | gdt_nocharlm |\n",
      "============================\n",
      "\n",
      "2025-04-29 21:48:44 WARNING: GPU requested, but is not available!\n",
      "2025-04-29 21:48:44 INFO: Using device: cpu\n",
      "2025-04-29 21:48:44 INFO: Loading: tokenize\n",
      "2025-04-29 21:48:44 INFO: Loading: mwt\n",
      "2025-04-29 21:48:44 INFO: Loading: pos\n",
      "2025-04-29 21:48:45 INFO: Done loading processors!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Archivo enriquecido guardado como: tweets_griegos_features_stanza.json\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import stanza\n",
    "\n",
    "# Paso 1: Descargar modelo de griego si es necesario\n",
    "stanza.download(\"el\")\n",
    "\n",
    "# Paso 2: Inicializar el pipeline de Stanza para griego\n",
    "nlp = stanza.Pipeline(\"el\", processors=\"tokenize,pos\", use_gpu=True)\n",
    "\n",
    "# Paso 3: Cargar archivo JSON\n",
    "archivo_json = \"grecia_anotados/Preprado/Tweets_griegos.json\"\n",
    "with open(archivo_json, \"r\", encoding=\"utf-8\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# Paso 4: Procesar cada tweet\n",
    "resultados = []\n",
    "\n",
    "for item in data:\n",
    "    tweet_text = str(item.get(\"tweet\", \"\"))\n",
    "    tweet_id = str(item.get(\"id\", \"desconocido\"))\n",
    "\n",
    "    # POS tagging con Stanza\n",
    "    doc = nlp(tweet_text)\n",
    "    pos_tags = []\n",
    "    counts = {\"DET\": 0, \"NOUN\": 0, \"VERB\": 0, \"ADJ\": 0, \"PROPN\": 0, \"PRON\": 0}\n",
    "    first_word_pos = None\n",
    "\n",
    "    for sentence in doc.sentences:\n",
    "        for idx, word in enumerate(sentence.words):\n",
    "            pos_tags.append({\n",
    "                \"text\": word.text,\n",
    "                \"pos\": word.upos\n",
    "            })\n",
    "            if word.upos in counts:\n",
    "                counts[word.upos] += 1\n",
    "            if first_word_pos is None and idx == 0:\n",
    "                first_word_pos = word.upos\n",
    "\n",
    "    # Paso 5: Añadir los features directamente al objeto original\n",
    "    item[\"pos_features\"] = {\n",
    "        \"num_determinantes\": counts[\"DET\"],\n",
    "        \"num_nouns\": counts[\"NOUN\"],\n",
    "        \"num_verbs\": counts[\"VERB\"],\n",
    "        \"num_adjectives\": counts[\"ADJ\"],\n",
    "        \"num_proper_nouns\": counts[\"PROPN\"],\n",
    "        \"starts_with_pronoun\": first_word_pos == \"PRON\",\n",
    "        \"ratio_noun_to_verb\": round(counts[\"NOUN\"] / counts[\"VERB\"], 2) if counts[\"VERB\"] > 0 else None\n",
    "    }\n",
    "\n",
    "# Paso 6: Guardar el resultado en un nuevo JSON\n",
    "output_file = \"tweets_griegos_features_stanza.json\"\n",
    "with open(output_file, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(data, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "print(f\"✅ Archivo enriquecido guardado como: {output_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5bf10a5a-95d9-4a16-8c50-d0a97ddb3454",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Se añadieron los POS features al analysis de cada tweet correctamente.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# 1. Cargar el JSON principal (con análisis de sentimiento, emociones, etc.)\n",
    "with open(\"grecia_anotados/Preprado/Tweets_griegos.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    tweets_analizados = json.load(f)\n",
    "\n",
    "# 2. Cargar el JSON con los features POS (stanza)\n",
    "with open(\"tweets_griegos_features_stanza.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    tweets_features = json.load(f)\n",
    "\n",
    "# 3. Crear un mapa rápido: texto del tweet -> pos_features\n",
    "mapa_features = {\n",
    "    item[\"tweet\"].strip(): item.get(\"pos_features\", {})\n",
    "    for item in tweets_features\n",
    "}\n",
    "\n",
    "# 4. Insertar los pos_features en el analysis de cada tweet\n",
    "for tweet in tweets_analizados:\n",
    "    texto = tweet[\"tweet\"].strip()\n",
    "    features = mapa_features.get(texto, None)\n",
    "    if features:\n",
    "        tweet.setdefault(\"analysis\", {})[\"pos_features\"] = features  # Añadir pos_features dentro de analysis\n",
    "\n",
    "# 5. Guardar el nuevo JSON enriquecido\n",
    "with open(\"tweets_completos_con_analysis_y_pos.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(tweets_analizados, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "print(\"✅ Se añadieron los POS features al analysis de cada tweet correctamente.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "15b80490-4c27-4023-9bc2-0961fffddf66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Archivo actualizado con la polaridad ideológica.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# 1. Cargar JSON con los análisis y partidos\n",
    "with open(\"grecia_anotados/Preprado/Griegos.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# 2. Crear diccionario de partidos → polaridad\n",
    "partido_a_ideologia = {\n",
    "    \"Νέα Δημοκρατία\": \"derecha\",\n",
    "    \"Ελληνική Λύση\": \"derecha\",\n",
    "    \"Ανεξάρτητοι Έλληνες\": \"derecha\",\n",
    "    \"Εθνική Δημιουργία\": \"derecha\",\n",
    "    \"Συνασπισμός Ριζοσπαστικής Αριστεράς – Προοδευτική Συμμαχία\": \"izquierda\",\n",
    "    \"ΠΑΣΟΚ – Κίνημα Αλλαγής\": \"izquierda\",\n",
    "    \"ΜέΡΑ25\": \"izquierda\",\n",
    "    \"Κίνημα Αλλαγής\": \"izquierda\",\n",
    "    \"Κομμουνιστικό Κόμμα Ελλάδας\": \"izquierda\",\n",
    "    \"Κίνημα Δημοκρατών Σοσιαλιστών\": \"izquierda\"\n",
    "}\n",
    "\n",
    "# 3. Suponemos que en cada tweet tienes la clave 'party' ya puesta\n",
    "for tweet in data:\n",
    "    partido = tweet.get(\"party\", \"\").strip()\n",
    "    polaridad = partido_a_ideologia.get(partido)\n",
    "    tweet[\"polaridad_ideologica\"] = polaridad  # Puede ser None si el partido no está en el mapeo\n",
    "\n",
    "# 4. Guardar resultado\n",
    "with open(\"grecia_anotados/Preprado/Griegos_f.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(data, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "print(\"✅ Archivo actualizado con la polaridad ideológica.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "3f8a1e48-09cf-4a49-9de5-864a5a2002b9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'user': 'Giannis Plakiotakis\\n@G_Plakiotakis',\n",
       "  'tweet': 'Την Τετάρτη το πρωί, στις 9:15 στον ΣΚΑΪ και την εκπομπή \"Σήμερα\" #Πλακιωτάκης #ΣΚΑΪ https://t.co/PynuyD0upJ',\n",
       "  'replies': [],\n",
       "  'analysis': {'sentiment': {'label': 'neutral', 'score': 0.8632032871246338},\n",
       "   'emotions': [{'label': 'optimism', 'score': 0.593174934387207},\n",
       "    {'label': 'joy', 'score': 0.19987452030181885},\n",
       "    {'label': 'anger', 'score': 0.12021705508232117}],\n",
       "   'hate': {'label': 'not hate', 'score': 0.7837180495262146},\n",
       "   'translation': 'Wednesday morning, at 9:15 p.m. and today\\'s \"Today\" issue #Scaoits https://t.co/PynuyD0upJ',\n",
       "   'summary': ' Wednesday morning, at 9:15 p.m. and today\\'s \"Today\" issue #Scaoits .',\n",
       "   'pos_features': {'num_determinantes': 5,\n",
       "    'num_nouns': 6,\n",
       "    'num_verbs': 0,\n",
       "    'num_adjectives': 0,\n",
       "    'num_proper_nouns': 0,\n",
       "    'starts_with_pronoun': False,\n",
       "    'ratio_noun_to_verb': None}},\n",
       "  'id': '1349005840745984007',\n",
       "  'label': '0',\n",
       "  'annotator': 'tiebreak_rule',\n",
       "  'name': 'Giannis Plakiotakis',\n",
       "  'age': None,\n",
       "  'gender': None,\n",
       "  'party': None},\n",
       " {'user': 'Κατερίνα Νοτοπούλου\\n@katenotopoulou',\n",
       "  'tweet': 'Προχειρογράφημα ο νέος Οργανισμός Εσωτερικής Υπηρεσίας του Δήμου Θεσσαλονίκης. Δεν λαμβάνει υπόψη και δεν ανταποκρίνεται στις απαιτήσεις σύγχρονης διακυβέρνησης των δήμων. Δεν εκσυγχρονίζει τη λειτουργία του Δήμου Θεσσαλονίκης. https://t.co/qbZZ5XsbpC',\n",
       "  'replies': [],\n",
       "  'analysis': {'sentiment': {'label': 'neutral', 'score': 0.7721729874610901},\n",
       "   'emotions': [{'label': 'optimism', 'score': 0.5586957931518555},\n",
       "    {'label': 'joy', 'score': 0.2313828319311142},\n",
       "    {'label': 'anger', 'score': 0.13311350345611572}],\n",
       "   'hate': {'label': 'not hate', 'score': 0.8688682317733765},\n",
       "   'translation': 'The new Internal Service Agency of the Thessaloniki City of Thessaloniki. It does not take into account and does not meet the modern government requirements of the municipalities. It does not modernize the operation of the Thessaloniki City. https://t.co/qbZ5XsbpC',\n",
       "   'summary': \" The new Internal Service Agency of the Thessaloniki City does not meet the modern government requirements of the municipalities . It does not modernize the operation of the city, according to the city's mayor . The new agency does not take into account and does not .\",\n",
       "   'pos_features': {'num_determinantes': 6,\n",
       "    'num_nouns': 9,\n",
       "    'num_verbs': 4,\n",
       "    'num_adjectives': 2,\n",
       "    'num_proper_nouns': 2,\n",
       "    'starts_with_pronoun': False,\n",
       "    'ratio_noun_to_verb': 2.25}},\n",
       "  'id': '1352200868943245313',\n",
       "  'label': '-1',\n",
       "  'annotator': 'tiebreak_rule',\n",
       "  'name': 'Κατερίνα Νοτοπούλου',\n",
       "  'age': 36,\n",
       "  'gender': 'femenino',\n",
       "  'party': 'Συνασπισμός Ριζοσπαστικής Αριστεράς – Προοδευτική Συμμαχία'}]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Carga tus datos (aquí se asume que ya los has cargado como listas de diccionarios)\n",
    "# json1 es la lista con tweets, json2 la lista con información personal\n",
    "\n",
    "with open('grecia_anotados/Preprado/tweets_completos_con_analysis_y_pos.json', 'r', encoding='utf-8') as f:\n",
    "    tweets_data = json.load(f)\n",
    "\n",
    "with open('grecia_anotados/politicos_griegos.json', 'r', encoding='utf-8') as f:\n",
    "    info_data = json.load(f)\n",
    "\n",
    "# Crear un diccionario para búsqueda rápida por nombre\n",
    "info_dict = {entry['name']: entry for entry in info_data}\n",
    "\n",
    "# Función para extraer el nombre del campo \"user\"\n",
    "def extract_name(user_str):\n",
    "    return user_str.split('\\n')[0].strip()\n",
    "\n",
    "# Lista final combinada\n",
    "combined = []\n",
    "\n",
    "for tweet_entry in tweets_data:\n",
    "    name = extract_name(tweet_entry[\"user\"])\n",
    "    persona_info = info_dict.get(name, {})  # Si no se encuentra, será un dict vacío\n",
    "    \n",
    "    tweet_copy = tweet_entry.copy()\n",
    "    tweet_copy[\"name\"] = name  # Añadir campo separado\n",
    "    tweet_copy[\"age\"] = persona_info.get(\"age\")\n",
    "    tweet_copy[\"gender\"] = persona_info.get(\"gender\")\n",
    "    tweet_copy[\"party\"] = persona_info.get(\"party\")\n",
    "    \n",
    "    combined.append(tweet_copy)\n",
    "\n",
    "# Guardar resultado\n",
    "with open('combined.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(combined, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "# Mostrar una muestra\n",
    "combined[:2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "62c6d318-df4e-46eb-a495-c7015c5327b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "142\n",
      "No se encontró información para 73 personas.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import unicodedata\n",
    "\n",
    "# Función para normalizar nombres (quita acentos, pone minúsculas)\n",
    "def normalizar(texto):\n",
    "    if not texto:\n",
    "        return \"\"\n",
    "    texto = unicodedata.normalize('NFKD', texto)\n",
    "    texto = ''.join([c for c in texto if not unicodedata.combining(c)])\n",
    "    return texto.lower().strip()\n",
    "\n",
    "# Cargar el mapeo nombre–usuario\n",
    "with open('grecia_anotados/users_griegos.json', 'r', encoding='utf-8') as f:\n",
    "    name_user_map = json.load(f)\n",
    "\n",
    "# Cargar la información personal original\n",
    "with open('grecia_anotados/politicos_griegos.json', 'r', encoding='utf-8') as f:\n",
    "    info_data = json.load(f)\n",
    "\n",
    "# Crear diccionario con nombres normalizados para búsqueda flexible\n",
    "info_dict_normalizado = {\n",
    "    normalizar(entry[\"name\"]): entry\n",
    "    for entry in info_data\n",
    "}\n",
    "\n",
    "# Construir el nuevo JSON unificado\n",
    "resultado = []\n",
    "no_encontrados = []\n",
    "\n",
    "for entry in name_user_map:\n",
    "    name_original = entry[\"name\"]\n",
    "    user = entry[\"user\"]\n",
    "    name_normalizado = normalizar(name_original)\n",
    "\n",
    "    info = info_dict_normalizado.get(name_normalizado)\n",
    "\n",
    "    if info:\n",
    "        resultado.append({\n",
    "            \"name\": name_original,\n",
    "            \"user\": user,\n",
    "            \"age\": info.get(\"age\"),\n",
    "            \"gender\": info.get(\"gender\"),\n",
    "            \"party\": info.get(\"party\")\n",
    "        })\n",
    "    else:\n",
    "        no_encontrados.append(name_original)\n",
    "        resultado.append({\n",
    "            \"name\": name_original,\n",
    "            \"user\": user,\n",
    "            \"age\": None,\n",
    "            \"gender\": None,\n",
    "            \"party\": None\n",
    "        })\n",
    "\n",
    "# Guardar resultado\n",
    "with open('user_info_completo.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(resultado, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "# Guardar lista de no encontrados (opcional)\n",
    "with open('no_encontrados.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(no_encontrados, f, ensure_ascii=False, indent=2)\n",
    "print(len(resultado))\n",
    "# Mostrar cuántos no se encontraron\n",
    "print(f\"No se encontró información para {len(no_encontrados)} personas.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3e9a7c6-e6ff-458a-a82d-a28ca96fc105",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "09992d8b-9aa7-4661-825a-9069aa7aa673",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Fusión completada. Archivo guardado como 'tweets_fusionados.json'.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from collections import defaultdict\n",
    "\n",
    "# Cargar archivos\n",
    "with open('spain/Completado/tweets_españoles_evaluados_completo.json', 'r', encoding='utf-8') as f:\n",
    "    original_data = json.load(f)\n",
    "\n",
    "with open('spain/Tweets_etiquetados.json', 'r', encoding='utf-8') as f:\n",
    "    manual_annotations = json.load(f)\n",
    "\n",
    "with open('tweets_españoles_evaluados_completo.json', 'r', encoding='utf-8') as f:\n",
    "    stanza_sentiment = json.load(f)\n",
    "\n",
    "with open('spain/usuarios_con_tweets_y_detalles.json', 'r', encoding='utf-8') as f:\n",
    "    user_info = json.load(f)\n",
    "\n",
    "# Convertir anotaciones y sentimientos en diccionarios para acceso rápido\n",
    "annotation_dict = {str(item['id']): item for item in manual_annotations}\n",
    "stanza_dict = {str(item['id']): item['analysis']['sentiment'] for item in stanza_sentiment}\n",
    "stanza_reply_dict = {str(item['id']): item for item in stanza_sentiment}\n",
    "\n",
    "# Crear índice de usuario por tweet_id\n",
    "user_by_tweet = {}\n",
    "for user in user_info:\n",
    "    for tid in user['tweet_ids']:\n",
    "        user_by_tweet[str(tid)] = {\n",
    "            \"name\": user['name'],\n",
    "            \"age\": user['age'],\n",
    "            \"gender\": user['gender'],\n",
    "            \"party\": user['party']\n",
    "        }\n",
    "\n",
    "# Organizar resultado final por usuario\n",
    "final_result = defaultdict(lambda: {\n",
    "    \"name\": \"\",\n",
    "    \"age\": None,\n",
    "    \"gender\": \"\",\n",
    "    \"party\": \"\",\n",
    "    \"tweets\": []\n",
    "})\n",
    "\n",
    "for tweet in original_data:\n",
    "    tweet_id = str(tweet['id'])\n",
    "\n",
    "    # Filtrar si no está en las anotaciones\n",
    "    if tweet_id not in annotation_dict:\n",
    "        continue\n",
    "\n",
    "    # Verificar si hay datos del usuario\n",
    "    if tweet_id not in user_by_tweet:\n",
    "        continue\n",
    "\n",
    "    user_info_obj = user_by_tweet[tweet_id]\n",
    "    user_key = user_info_obj['name'] + ' ' + user_info_obj['party']\n",
    "\n",
    "    # Agregar información del usuario\n",
    "    final_result[user_key]['name'] = user_info_obj['name']\n",
    "    final_result[user_key]['age'] = user_info_obj['age']\n",
    "    final_result[user_key]['gender'] = user_info_obj['gender']\n",
    "    final_result[user_key]['party'] = user_info_obj['party']\n",
    "\n",
    "    # Agregar anotaciones manuales\n",
    "    annotations = {\n",
    "        \"User1\": annotation_dict[tweet_id][\"User1\"],\n",
    "        \"User2\": annotation_dict[tweet_id][\"User2\"],\n",
    "        \"Total\": annotation_dict[tweet_id][\"Total\"]\n",
    "    }\n",
    "\n",
    "    # Añadir sentimiento stanza si existe\n",
    "    if tweet_id in stanza_dict:\n",
    "        tweet['analysis']['sentiment_stanza'] = stanza_dict[tweet_id]\n",
    "\n",
    "    # Procesar replies por orden\n",
    "    replies = tweet.get('replies', [])\n",
    "    stanza_replies = stanza_reply_dict.get(tweet_id, {}).get('replies', [])\n",
    "\n",
    "    for idx, reply in enumerate(replies):\n",
    "        if idx < len(stanza_replies):\n",
    "            sentiment_stanza = stanza_replies[idx].get('analysis', {}).get('sentiment')\n",
    "            if sentiment_stanza is not None:\n",
    "                reply['analysis']['sentiment_stanza'] = sentiment_stanza\n",
    "\n",
    "    # Crear estructura final del tweet\n",
    "    tweet_struct = {\n",
    "        \"id\": tweet_id,\n",
    "        \"tweet\": tweet['tweet'],\n",
    "        \"analysis\": tweet['analysis'],\n",
    "        \"annotations\": annotations,\n",
    "        \"replies\": replies\n",
    "    }\n",
    "\n",
    "    final_result[user_key]['tweets'].append(tweet_struct)\n",
    "\n",
    "# Guardar resultado final\n",
    "final_json = list(final_result.values())\n",
    "\n",
    "with open('tweets_fusionados.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(final_json, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "print(\"✅ Fusión completada. Archivo guardado como 'tweets_fusionados.json'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b15cf3ab-154a-408a-b8fe-8c8a4132a0b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Partidos políticos encontrados:\n",
      "- BNG\n",
      "- CCa-PNC-NC\n",
      "- CUP-PR\n",
      "- Cs\n",
      "- ECP\n",
      "- EH Bildu\n",
      "- ERC-Sob\n",
      "- JxCat\n",
      "- MP\n",
      "- NA+\n",
      "- PP\n",
      "- PSOE\n",
      "- UP\n",
      "- VOX\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Cargar el archivo fusionado\n",
    "with open('tweets_fusionados_ideologia.json', 'r', encoding='utf-8') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# Extraer todos los partidos\n",
    "partidos = set()\n",
    "for usuario in data:\n",
    "    partido = usuario.get('party')\n",
    "    if partido:\n",
    "        partidos.add(partido)\n",
    "\n",
    "# Mostrar la lista ordenada\n",
    "partidos_ordenados = sorted(partidos)\n",
    "print(\"Partidos políticos encontrados:\")\n",
    "for partido in partidos_ordenados:\n",
    "    print(\"-\", partido)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "74da29f3-3843-4560-a325-23cd3158f178",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Partidos normalizados y clasificados. Guardado como 'tweets_fusionados_ideologia.json'.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Cargar el archivo fusionado\n",
    "with open('tweets_fusionados.json', 'r', encoding='utf-8') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# Normalizar nombres de partidos (guiones inconsistentes)\n",
    "def normalizar_partido(partido):\n",
    "    partido = partido.replace('–', '-')  # guion largo a guion corto\n",
    "    if partido in ['ERC-Sob', 'ERC–Sob']:\n",
    "        return 'ERC-Sob'\n",
    "    return partido\n",
    "\n",
    "# Definir agrupación ideológica\n",
    "izquierda = {'BNG', 'CUP-PR', 'ECP', 'EH Bildu', 'ERC-Sob', 'MP', 'PSOE', 'UP'}\n",
    "derecha = {'CCa-PNC-NC', 'Cs', 'JxCat', 'NA+', 'PP', 'VOX'}\n",
    "\n",
    "# Procesar cada usuario\n",
    "for usuario in data:\n",
    "    partido = normalizar_partido(usuario['party'])\n",
    "    usuario['party'] = partido  # actualizar nombre normalizado\n",
    "\n",
    "    if partido in izquierda:\n",
    "        usuario['ideologia'] = 'izquierda'\n",
    "    elif partido in derecha:\n",
    "        usuario['ideologia'] = 'derecha'\n",
    "    else:\n",
    "        usuario['ideologia'] = 'otros'\n",
    "\n",
    "# Guardar el archivo modificado\n",
    "with open('tweets_fusionados_ideologia.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(data, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "print(\"✅ Partidos normalizados y clasificados. Guardado como 'tweets_fusionados_ideologia.json'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "70c46d20-a2eb-4fba-a75e-0f141d79015b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Resultados guardados en 'comparaciones_sesgo.csv'\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import ttest_ind\n",
    "\n",
    "# === 1. Cargar archivo fusionado con ideología incluida ===\n",
    "with open('tweets_fusionados_ideologia.json', 'r', encoding='utf-8') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# === 2. Extraer replies con análisis y atributos del autor original ===\n",
    "rows = []\n",
    "for usuario in data:\n",
    "    gender = usuario['gender']\n",
    "    age = usuario['age']\n",
    "    party = usuario['party']\n",
    "    ideologia = usuario['ideologia']\n",
    "\n",
    "    for tweet in usuario['tweets']:\n",
    "        for reply in tweet.get('replies', []):\n",
    "            if not isinstance(reply, dict):\n",
    "                continue\n",
    "            analysis = reply.get('analysis')\n",
    "            if not isinstance(analysis, dict):\n",
    "                continue\n",
    "\n",
    "            hate = analysis.get('hate')\n",
    "            hate_score = hate.get('score') if isinstance(hate, dict) else None\n",
    "\n",
    "            sentiment = analysis.get('sentiment')\n",
    "            sentiment_score = sentiment.get('score') if isinstance(sentiment, dict) else None\n",
    "\n",
    "            emotions_raw = analysis.get('emotions', [])\n",
    "            emotions = {}\n",
    "            if isinstance(emotions_raw, list):\n",
    "                emotions = {\n",
    "                    e['label']: e['score']\n",
    "                    for e in emotions_raw\n",
    "                    if isinstance(e, dict) and 'label' in e and 'score' in e\n",
    "                }\n",
    "\n",
    "            row = {\n",
    "                'gender': gender,\n",
    "                'age': age,\n",
    "                'party': party,\n",
    "                'ideologia': ideologia,\n",
    "                'hate_score': hate_score,\n",
    "                'sentiment_score': sentiment_score,\n",
    "            }\n",
    "            row.update(emotions)\n",
    "            rows.append(row)\n",
    "\n",
    "# === 3. Crear DataFrame ===\n",
    "df = pd.DataFrame(rows)\n",
    "\n",
    "# === 4. Limpiar y categorizar edad ===\n",
    "df = df.dropna(subset=['age'])  # eliminar edad nula\n",
    "df['age_group'] = pd.cut(df['age'], bins=[0, 40, 100], labels=['joven', 'mayor'])\n",
    "\n",
    "# === 5. Función para calcular d de Cohen ===\n",
    "def cohens_d(x1, x2):\n",
    "    n1, n2 = len(x1), len(x2)\n",
    "    s1, s2 = np.var(x1, ddof=1), np.var(x2, ddof=1)\n",
    "    s_pooled = np.sqrt(((n1 - 1)*s1 + (n2 - 1)*s2) / (n1 + n2 - 2))\n",
    "    return (np.mean(x1) - np.mean(x2)) / s_pooled\n",
    "\n",
    "# === 6. Comparar todas las métricas contra todos los grupos ===\n",
    "metricas = ['hate_score', 'sentiment_score', 'anger', 'joy', 'sadness', 'optimism']\n",
    "grupos = ['gender', 'ideologia', 'age_group']\n",
    "\n",
    "resultados = []\n",
    "\n",
    "for variable_grupo in grupos:\n",
    "    for metrica in metricas:\n",
    "        grupos_unicos = df[variable_grupo].dropna().unique()\n",
    "        if len(grupos_unicos) != 2:\n",
    "            continue\n",
    "\n",
    "        grupo1, grupo2 = grupos_unicos\n",
    "        datos1 = df[df[variable_grupo] == grupo1][metrica].dropna()\n",
    "        datos2 = df[df[variable_grupo] == grupo2][metrica].dropna()\n",
    "\n",
    "        if len(datos1) < 10 or len(datos2) < 10:\n",
    "            continue\n",
    "\n",
    "        d = cohens_d(datos1, datos2)\n",
    "        t_stat, p_value = ttest_ind(datos1, datos2, equal_var=False)\n",
    "\n",
    "        resultados.append({\n",
    "            \"grupo\": variable_grupo,\n",
    "            \"valor\": metrica,\n",
    "            \"grupo_1\": grupo1,\n",
    "            \"grupo_2\": grupo2,\n",
    "            \"d_cohen\": d,\n",
    "            \"t_stat\": t_stat,\n",
    "            \"p_value\": p_value,\n",
    "            \"n1\": len(datos1),\n",
    "            \"n2\": len(datos2)\n",
    "        })\n",
    "\n",
    "# === 7. Mostrar resultados ordenados ===\n",
    "df_resultados = pd.DataFrame(resultados)\n",
    "df_resultados = df_resultados.sort_values(by='d_cohen', key=lambda x: abs(x), ascending=False)\n",
    "\n",
    "# === 8. Mostrar como tabla interactiva en Jupyter ===\n",
    "df_resultados.to_csv(\"comparaciones_sesgo.csv\", index=False, encoding='utf-8')\n",
    "print(\"✅ Resultados guardados en 'comparaciones_sesgo.csv'\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d7f88336-3fce-42a9-bf63-2be1a5db9106",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Resultados guardados en 'sesgo_modelo_sentimiento.csv'\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import ttest_ind\n",
    "# === Función para calcular el tamaño del efecto (Cohen's d) ===\n",
    "def cohens_d(x1, x2):\n",
    "    n1, n2 = len(x1), len(x2)\n",
    "    s1, s2 = np.var(x1, ddof=1), np.var(x2, ddof=1)\n",
    "    s_pooled = np.sqrt(((n1 - 1)*s1 + (n2 - 1)*s2) / (n1 + n2 - 2))\n",
    "    return (np.mean(x1) - np.mean(x2)) / s_pooled if s_pooled > 0 else 0.0\n",
    "\n",
    "# === 1. Cargar archivo JSON ===\n",
    "with open('grecia_anotados/Preprado/Griegos_f.json', 'r', encoding='utf-8') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# === 2. Extraer predicciones y etiquetas humanas ===\n",
    "rows = []\n",
    "for usuario in data:\n",
    "    gender = usuario.get('gender')\n",
    "    age = usuario.get('age')\n",
    "    party = usuario.get('party')\n",
    "    ideologia = usuario.get('polaridad_ideologica')\n",
    "\n",
    "    for tweet in usuario.get('tweets', []):\n",
    "        for reply in [tweet] + tweet.get('replies', []):\n",
    "            if not isinstance(reply, dict):\n",
    "                continue\n",
    "\n",
    "            label_humana = reply.get('label')\n",
    "            if label_humana not in ['-1', '0', '1']:\n",
    "                continue\n",
    "\n",
    "            analysis = reply.get('analysis')\n",
    "            if not isinstance(analysis, dict):\n",
    "                continue\n",
    "\n",
    "            pred_sentiment = analysis.get('sentiment', {}).get('label')\n",
    "            if pred_sentiment not in ['positive', 'neutral', 'negative']:\n",
    "                continue\n",
    "\n",
    "            # Convertimos para comparar: humano (str) -> modelo (str)\n",
    "            mapping_humano = {'-1': 'negative', '0': 'neutral', '1': 'positive'}\n",
    "            label_humana_str = mapping_humano.get(label_humana)\n",
    "\n",
    "            acierto = int(pred_sentiment == label_humana_str)\n",
    "\n",
    "            rows.append({\n",
    "                'gender': gender,\n",
    "                'age': age,\n",
    "                'party': party,\n",
    "                'ideologia': ideologia,\n",
    "                'acierto': acierto\n",
    "            })\n",
    "\n",
    "# === 3. Crear DataFrame ===\n",
    "df = pd.DataFrame(rows)\n",
    "\n",
    "# === 4. Categorizar edad ===\n",
    "df = df.dropna(subset=['age'])\n",
    "df['age_group'] = pd.cut(df['age'], bins=[0, 40, 100], labels=['joven', 'mayor'])\n",
    "\n",
    "# === 5. Comparar tasa de acierto por grupo ===\n",
    "grupos = ['gender', 'ideologia', 'age_group', 'party']\n",
    "resultados = []\n",
    "\n",
    "for variable in grupos:\n",
    "    grupos_unicos = df[variable].dropna().unique()\n",
    "    if len(grupos_unicos) != 2:\n",
    "        continue\n",
    "\n",
    "    g1, g2 = grupos_unicos\n",
    "    acc1 = df[df[variable] == g1]['acierto']\n",
    "    acc2 = df[df[variable] == g2]['acierto']\n",
    "\n",
    "    if len(acc1) < 10 or len(acc2) < 10:\n",
    "        continue\n",
    "\n",
    "    # Diferencia en tasa de acierto\n",
    "    mean1, mean2 = acc1.mean(), acc2.mean()\n",
    "    d = cohens_d(acc1, acc2)\n",
    "    t_stat, p_value = ttest_ind(acc1, acc2, equal_var=False)\n",
    "\n",
    "    resultados.append({\n",
    "        'grupo': variable,\n",
    "        'grupo_1': g1,\n",
    "        'grupo_2': g2,\n",
    "        'acierto_1': mean1,\n",
    "        'acierto_2': mean2,\n",
    "        'diff': mean1 - mean2,\n",
    "        'd_cohen': d,\n",
    "        't_stat': t_stat,\n",
    "        'p_value': p_value,\n",
    "        'n1': len(acc1),\n",
    "        'n2': len(acc2)\n",
    "    })\n",
    "\n",
    "# === 6. Resultados ordenados por magnitud de efecto ===\n",
    "df_resultados = pd.DataFrame(resultados)\n",
    "df_resultados = df_resultados.sort_values(by='d_cohen', key=lambda x: abs(x), ascending=False)\n",
    "\n",
    "# === 7. Guardar como CSV ===\n",
    "df_resultados.to_csv(\"sesgo_modelo_sentimiento.csv\", index=False, encoding='utf-8')\n",
    "print(\"✅ Resultados guardados en 'sesgo_modelo_sentimiento.csv'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1f763f06-c568-477d-87c9-a3f3b0364789",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ideologia\n",
      "None    925\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df['ideologia'].value_counts(dropna=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ffd6f99a-5f2e-4400-a218-b82c337cace4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Resultados guardados en 'comparaciones_completas.csv'\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import ttest_ind\n",
    "\n",
    "# === 1. Cargar archivo con estructura nueva ===\n",
    "with open('grecia_anotados/Preprado/Griegos.json', 'r', encoding='utf-8') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# === 2. Extraer tweets originales y replies con análisis + atributos del autor ===\n",
    "rows = []\n",
    "for persona in data:\n",
    "    gender = persona.get('gender')\n",
    "    age = persona.get('age')\n",
    "    party = persona.get('party')\n",
    "    ideologia = persona.get('ideologia')\n",
    "\n",
    "    for tweet in persona.get('tweets', []):\n",
    "        for fuente in ['analysis'] + [r.get('analysis') for r in tweet.get('replies', []) if isinstance(r, dict) and 'analysis' in r]:\n",
    "            if not isinstance(fuente, dict):\n",
    "                continue\n",
    "\n",
    "            hate = fuente.get('hate')\n",
    "            hate_score = hate.get('score') if isinstance(hate, dict) else None\n",
    "\n",
    "            sentiment = fuente.get('sentiment')\n",
    "            sentiment_score = sentiment.get('score') if isinstance(sentiment, dict) else None\n",
    "\n",
    "            emotions_raw = fuente.get('emotions', [])\n",
    "            emotions = {}\n",
    "            if isinstance(emotions_raw, list):\n",
    "                emotions = {\n",
    "                    e['label']: e['score']\n",
    "                    for e in emotions_raw\n",
    "                    if isinstance(e, dict) and 'label' in e and 'score' in e\n",
    "                }\n",
    "\n",
    "            row = {\n",
    "                'gender': gender,\n",
    "                'age': age,\n",
    "                'party': party,\n",
    "                'ideologia': ideologia,\n",
    "                'hate_score': hate_score,\n",
    "                'sentiment_score': sentiment_score,\n",
    "            }\n",
    "            row.update(emotions)\n",
    "            rows.append(row)\n",
    "\n",
    "# === 3. Crear DataFrame ===\n",
    "df = pd.DataFrame(rows)\n",
    "\n",
    "# === 4. Limpiar y categorizar edad ===\n",
    "df = df.dropna(subset=['age'])\n",
    "df['age_group'] = pd.cut(df['age'], bins=[0, 40, 100], labels=['joven', 'mayor'])\n",
    "\n",
    "# === 5. Función para calcular d de Cohen ===\n",
    "def cohens_d(x1, x2):\n",
    "    n1, n2 = len(x1), len(x2)\n",
    "    s1, s2 = np.var(x1, ddof=1), np.var(x2, ddof=1)\n",
    "    s_pooled = np.sqrt(((n1 - 1)*s1 + (n2 - 1)*s2) / (n1 + n2 - 2))\n",
    "    return (np.mean(x1) - np.mean(x2)) / s_pooled\n",
    "\n",
    "# === 6. Comparar métricas entre grupos ===\n",
    "metricas = ['hate_score', 'sentiment_score', 'anger', 'joy', 'sadness', 'optimism']\n",
    "grupos = ['gender', 'ideologia', 'age_group']\n",
    "\n",
    "resultados = []\n",
    "\n",
    "for variable_grupo in grupos:\n",
    "    for metrica in metricas:\n",
    "        grupos_unicos = df[variable_grupo].dropna().unique()\n",
    "        if len(grupos_unicos) != 2:\n",
    "            continue\n",
    "\n",
    "        grupo1, grupo2 = grupos_unicos\n",
    "        datos1 = df[df[variable_grupo] == grupo1][metrica].dropna()\n",
    "        datos2 = df[df[variable_grupo] == grupo2][metrica].dropna()\n",
    "\n",
    "        if len(datos1) < 10 or len(datos2) < 10:\n",
    "            continue\n",
    "\n",
    "        d = cohens_d(datos1, datos2)\n",
    "        t_stat, p_value = ttest_ind(datos1, datos2, equal_var=False)\n",
    "\n",
    "        resultados.append({\n",
    "            \"grupo\": variable_grupo,\n",
    "            \"valor\": metrica,\n",
    "            \"grupo_1\": grupo1,\n",
    "            \"grupo_2\": grupo2,\n",
    "            \"d_cohen\": d,\n",
    "            \"t_stat\": t_stat,\n",
    "            \"p_value\": p_value,\n",
    "            \"n1\": len(datos1),\n",
    "            \"n2\": len(datos2)\n",
    "        })\n",
    "\n",
    "# === 7. Guardar resultados ===\n",
    "df_resultados = pd.DataFrame(resultados)\n",
    "df_resultados = df_resultados.sort_values(by='d_cohen', key=lambda x: abs(x), ascending=False)\n",
    "df_resultados.to_csv(\"comparaciones_completas.csv\", index=False, encoding='utf-8')\n",
    "print(\"✅ Resultados guardados en 'comparaciones_completas.csv'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0434d065-5415-40f2-a77f-54d1411b3a2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Resultados guardados en 'comparaciones_metricas_espanoles.csv'\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import ttest_ind\n",
    "\n",
    "# === 1. Cargar archivo JSON ===\n",
    "with open('spain/Completado/Spain_Completo.json', 'r', encoding='utf-8') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# === 2. Extraer datos de análisis y atributos del autor ===\n",
    "rows = []\n",
    "for persona in data:\n",
    "    gender = persona.get('gender')\n",
    "    age = persona.get('age')\n",
    "    party = persona.get('party')\n",
    "    ideologia = persona.get('ideologia')\n",
    "\n",
    "    for tweet in persona.get('tweets', []):\n",
    "        # Procesar tweet original\n",
    "        fuentes = [tweet.get('analysis')]\n",
    "        # Añadir replies\n",
    "        fuentes += [r.get('analysis') for r in tweet.get('replies', []) if isinstance(r, dict) and 'analysis' in r]\n",
    "\n",
    "        for fuente in fuentes:\n",
    "            if not isinstance(fuente, dict):\n",
    "                continue\n",
    "\n",
    "            hate = fuente.get('hate')\n",
    "            hate_score = hate.get('score') if isinstance(hate, dict) else None\n",
    "\n",
    "            sentiment = fuente.get('sentiment')\n",
    "            sentiment_score = sentiment.get('score') if isinstance(sentiment, dict) else None\n",
    "\n",
    "            emotions_raw = fuente.get('emotions', [])\n",
    "            emotions = {}\n",
    "            if isinstance(emotions_raw, list):\n",
    "                emotions = {\n",
    "                    e['label']: e['score']\n",
    "                    for e in emotions_raw\n",
    "                    if isinstance(e, dict) and 'label' in e and 'score' in e\n",
    "                }\n",
    "\n",
    "            row = {\n",
    "                'gender': gender,\n",
    "                'age': age,\n",
    "                'party': party,\n",
    "                'ideologia': ideologia,\n",
    "                'hate_score': hate_score,\n",
    "                'sentiment_score': sentiment_score,\n",
    "            }\n",
    "            row.update(emotions)\n",
    "            rows.append(row)\n",
    "\n",
    "# === 3. Crear DataFrame ===\n",
    "df = pd.DataFrame(rows)\n",
    "\n",
    "# === 4. Limpiar y categorizar edad ===\n",
    "df = df.dropna(subset=['age'])\n",
    "df['age_group'] = pd.cut(df['age'], bins=[0, 40, 100], labels=['joven', 'mayor'])\n",
    "\n",
    "# === 5. Función para calcular d de Cohen ===\n",
    "def cohens_d(x1, x2):\n",
    "    n1, n2 = len(x1), len(x2)\n",
    "    s1, s2 = np.var(x1, ddof=1), np.var(x2, ddof=1)\n",
    "    s_pooled = np.sqrt(((n1 - 1)*s1 + (n2 - 1)*s2) / (n1 + n2 - 2))\n",
    "    return (np.mean(x1) - np.mean(x2)) / s_pooled if s_pooled > 0 else 0.0\n",
    "\n",
    "# === 6. Comparar métricas entre grupos ===\n",
    "metricas = ['hate_score', 'sentiment_score', 'anger', 'joy', 'sadness', 'optimism']\n",
    "grupos = ['gender', 'ideologia', 'age_group']\n",
    "\n",
    "resultados = []\n",
    "\n",
    "for variable_grupo in grupos:\n",
    "    for metrica in metricas:\n",
    "        grupos_unicos = df[variable_grupo].dropna().unique()\n",
    "        if len(grupos_unicos) != 2:\n",
    "            continue\n",
    "\n",
    "        grupo1, grupo2 = grupos_unicos\n",
    "        datos1 = df[df[variable_grupo] == grupo1][metrica].dropna()\n",
    "        datos2 = df[df[variable_grupo] == grupo2][metrica].dropna()\n",
    "\n",
    "        if len(datos1) < 10 or len(datos2) < 10:\n",
    "            continue\n",
    "\n",
    "        d = cohens_d(datos1, datos2)\n",
    "        t_stat, p_value = ttest_ind(datos1, datos2, equal_var=False)\n",
    "\n",
    "        resultados.append({\n",
    "            \"grupo\": variable_grupo,\n",
    "            \"valor\": metrica,\n",
    "            \"grupo_1\": grupo1,\n",
    "            \"grupo_2\": grupo2,\n",
    "            \"d_cohen\": d,\n",
    "            \"t_stat\": t_stat,\n",
    "            \"p_value\": p_value,\n",
    "            \"n1\": len(datos1),\n",
    "            \"n2\": len(datos2)\n",
    "        })\n",
    "\n",
    "# === 7. Guardar resultados ===\n",
    "df_resultados = pd.DataFrame(resultados)\n",
    "df_resultados = df_resultados.sort_values(by='d_cohen', key=lambda x: abs(x), ascending=False)\n",
    "df_resultados.to_csv(\"comparaciones_metricas_espanoles.csv\", index=False, encoding='utf-8')\n",
    "\n",
    "print(\"✅ Resultados guardados en 'comparaciones_metricas_espanoles.csv'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f23edda9-37b7-4ce0-b52a-70895ae2e663",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import ttest_ind\n",
    "# === Función para calcular el tamaño del efecto (Cohen's d) ===\n",
    "def cohens_d(x1, x2):\n",
    "    n1, n2 = len(x1), len(x2)\n",
    "    s1, s2 = np.var(x1, ddof=1), np.var(x2, ddof=1)\n",
    "    s_pooled = np.sqrt(((n1 - 1)*s1 + (n2 - 1)*s2) / (n1 + n2 - 2))\n",
    "    return (np.mean(x1) - np.mean(x2)) / s_pooled if s_pooled > 0 else 0.0\n",
    "\n",
    "# === 1. Cargar archivo JSON ===\n",
    "with open('grecia_anotados/Preprado/Griegos_f.json', 'r', encoding='utf-8') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# === 2. Extraer predicciones y etiquetas humanas ===\n",
    "rows = []\n",
    "for usuario in data:\n",
    "    gender = usuario.get('gender')\n",
    "    age = usuario.get('age')\n",
    "    party = usuario.get('party')\n",
    "    ideologia = usuario.get('polaridad_ideologica')\n",
    "\n",
    "    for tweet in usuario.get('tweets', []):\n",
    "        for reply in [tweet] + tweet.get('replies', []):\n",
    "            if not isinstance(reply, dict):\n",
    "                continue\n",
    "\n",
    "            label_humana = reply.get('label')\n",
    "            if label_humana not in ['-1', '0', '1']:\n",
    "                continue\n",
    "\n",
    "            analysis = reply.get('analysis')\n",
    "            if not isinstance(analysis, dict):\n",
    "                continue\n",
    "\n",
    "            pred_sentiment = analysis.get('sentiment', {}).get('label')\n",
    "            if pred_sentiment not in ['positive', 'neutral', 'negative']:\n",
    "                continue\n",
    "\n",
    "            # Convertimos para comparar: humano (str) -> modelo (str)\n",
    "            mapping_humano = {'-1': 'negative', '0': 'neutral', '1': 'positive'}\n",
    "            label_humana_str = mapping_humano.get(label_humana)\n",
    "\n",
    "            acierto = int(pred_sentiment == label_humana_str)\n",
    "\n",
    "            rows.append({\n",
    "                'gender': gender,\n",
    "                'age': age,\n",
    "                'party': party,\n",
    "                'ideologia': ideologia,\n",
    "                'acierto': acierto\n",
    "            })\n",
    "\n",
    "# === 3. Crear DataFrame ===\n",
    "df = pd.DataFrame(rows)\n",
    "\n",
    "# === 4. Categorizar edad ===\n",
    "df = df.dropna(subset=['age'])\n",
    "df['age_group'] = pd.cut(df['age'], bins=[0, 40, 100], labels=['joven', 'mayor'])\n",
    "\n",
    "# === 5. Comparar tasa de acierto por grupo ===\n",
    "grupos = ['gender', 'ideologia', 'age_group', 'party']\n",
    "resultados = []\n",
    "\n",
    "for variable in grupos:\n",
    "    grupos_unicos = df[variable].dropna().unique()\n",
    "    if len(grupos_unicos) != 2:\n",
    "        continue\n",
    "\n",
    "    g1, g2 = grupos_unicos\n",
    "    acc1 = df[df[variable] == g1]['acierto']\n",
    "    acc2 = df[df[variable] == g2]['acierto']\n",
    "\n",
    "    if len(acc1) < 10 or len(acc2) < 10:\n",
    "        continue\n",
    "\n",
    "    # Diferencia en tasa de acierto\n",
    "    mean1, mean2 = acc1.mean(), acc2.mean()\n",
    "    d = cohens_d(acc1, acc2)\n",
    "    t_stat, p_value = ttest_ind(acc1, acc2, equal_var=False)\n",
    "\n",
    "    resultados.append({\n",
    "        'grupo': variable,\n",
    "        'grupo_1': g1,\n",
    "        'grupo_2': g2,\n",
    "        'acierto_1': mean1,\n",
    "        'acierto_2': mean2,\n",
    "        'diff': mean1 - mean2,\n",
    "        'd_cohen': d,\n",
    "        't_stat': t_stat,\n",
    "        'p_value': p_value,\n",
    "        'n1': len(acc1),\n",
    "        'n2': len(acc2)\n",
    "    })\n",
    "\n",
    "# === 6. Resultados ordenados por magnitud de efecto ===\n",
    "df_resultados = pd.DataFrame(resultados)\n",
    "df_resultados = df_resultados.sort_values(by='d_cohen', key=lambda x: abs(x), ascending=False)\n",
    "\n",
    "# === 7. Guardar como CSV ===\n",
    "df_resultados.to_csv(\"sesgo_modelo_sentimiento.csv\", index=False, encoding='utf-8')\n",
    "print(\"✅ Resultados guardados en 'sesgo_modelo_sentimiento.csv'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "64ada2fa-f042-4101-95f9-2d2a7a6b19d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Resultados guardados en 'comparaciones_britanicos.csv'\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import ttest_ind\n",
    "\n",
    "# === 1. Cargar archivo JSON con estructura por nombre de político ===\n",
    "with open('ingleses/fusion_final_con_odio_y_stanza.json', 'r', encoding='utf-8') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# === 2. Extraer datos de tweets y replies con métricas y atributos del autor ===\n",
    "rows = []\n",
    "for nombre, info in data.items():\n",
    "    gender = info.get('Genero')\n",
    "    age = info.get('Edad')\n",
    "    party = info.get('mp_party')\n",
    "    ideologia = info.get('Izquierda/Derecha')\n",
    "    etnia = info.get('Etnia')\n",
    "\n",
    "    for tweet in info.get('tweets', []):\n",
    "        fuentes = [tweet] + tweet.get('replies', [])\n",
    "\n",
    "        for fuente in fuentes:\n",
    "            if not isinstance(fuente, dict):\n",
    "                continue\n",
    "\n",
    "            row = {\n",
    "                'gender': gender,\n",
    "                'age': age,\n",
    "                'party': party,\n",
    "                'ideologia': ideologia,\n",
    "                'etnia': etnia,\n",
    "                'hate_score': fuente.get('hate_score'),\n",
    "                'sentiment_score': fuente.get('sentiment_score'),\n",
    "            }\n",
    "\n",
    "            # Añadir emociones específicas si están presentes\n",
    "            emotion_label = fuente.get('emotion_label')\n",
    "            emotion_score = fuente.get('emotion_score')\n",
    "\n",
    "            if emotion_label in ['joy', 'anger', 'sadness', 'optimism']:\n",
    "                row[emotion_label] = emotion_score\n",
    "\n",
    "            rows.append(row)\n",
    "\n",
    "# === 3. Crear DataFrame ===\n",
    "df = pd.DataFrame(rows)\n",
    "\n",
    "# === 4. Categorizar edad ===\n",
    "df = df.dropna(subset=['age'])\n",
    "df['age_group'] = pd.cut(df['age'], bins=[0, 40, 100], labels=['joven', 'mayor'])\n",
    "\n",
    "# === 5. Función para calcular d de Cohen ===\n",
    "def cohens_d(x1, x2):\n",
    "    n1, n2 = len(x1), len(x2)\n",
    "    s1, s2 = np.var(x1, ddof=1), np.var(x2, ddof=1)\n",
    "    s_pooled = np.sqrt(((n1 - 1)*s1 + (n2 - 1)*s2) / (n1 + n2 - 2))\n",
    "    return (np.mean(x1) - np.mean(x2)) / s_pooled\n",
    "\n",
    "# === 6. Comparar métricas entre grupos ===\n",
    "metricas = ['hate_score', 'sentiment_score', 'anger', 'joy', 'sadness', 'optimism']\n",
    "grupos = ['gender', 'ideologia', 'age_group']\n",
    "\n",
    "resultados = []\n",
    "\n",
    "for variable_grupo in grupos:\n",
    "    for metrica in metricas:\n",
    "        grupos_unicos = df[variable_grupo].dropna().unique()\n",
    "        if len(grupos_unicos) != 2:\n",
    "            continue\n",
    "\n",
    "        grupo1, grupo2 = grupos_unicos\n",
    "        datos1 = df[df[variable_grupo] == grupo1][metrica].dropna()\n",
    "        datos2 = df[df[variable_grupo] == grupo2][metrica].dropna()\n",
    "\n",
    "        if len(datos1) < 10 or len(datos2) < 10:\n",
    "            continue\n",
    "\n",
    "        d = cohens_d(datos1, datos2)\n",
    "        t_stat, p_value = ttest_ind(datos1, datos2, equal_var=False)\n",
    "\n",
    "        resultados.append({\n",
    "            \"grupo\": variable_grupo,\n",
    "            \"valor\": metrica,\n",
    "            \"grupo_1\": grupo1,\n",
    "            \"grupo_2\": grupo2,\n",
    "            \"d_cohen\": d,\n",
    "            \"t_stat\": t_stat,\n",
    "            \"p_value\": p_value,\n",
    "            \"n1\": len(datos1),\n",
    "            \"n2\": len(datos2)\n",
    "        })\n",
    "\n",
    "# === 7. Guardar resultados ===\n",
    "df_resultados = pd.DataFrame(resultados)\n",
    "df_resultados = df_resultados.sort_values(by='d_cohen', key=lambda x: abs(x), ascending=False)\n",
    "df_resultados.to_csv(\"comparaciones_britanicos.csv\", index=False, encoding='utf-8')\n",
    "print(\"✅ Resultados guardados en 'comparaciones_britanicos.csv'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "81327c7f-a7d3-4ff7-884a-b9e5e4a39ee6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Resultados guardados en 'sesgo_modelo_sentimiento_espanoles.csv'\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import ttest_ind\n",
    "\n",
    "# === Función para calcular el tamaño del efecto (Cohen's d) ===\n",
    "def cohens_d(x1, x2):\n",
    "    n1, n2 = len(x1), len(x2)\n",
    "    s1, s2 = np.var(x1, ddof=1), np.var(x2, ddof=1)\n",
    "    s_pooled = np.sqrt(((n1 - 1)*s1 + (n2 - 1)*s2) / (n1 + n2 - 2))\n",
    "    return (np.mean(x1) - np.mean(x2)) / s_pooled if s_pooled > 0 else 0.0\n",
    "\n",
    "# === 1. Cargar archivo JSON ===\n",
    "with open('spain/Completado/Spain_Completo.json', 'r', encoding='utf-8') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# === 2. Extraer predicciones y etiquetas humanas ===\n",
    "rows = []\n",
    "for usuario in data:\n",
    "    gender = usuario.get('gender')\n",
    "    age = usuario.get('age')\n",
    "    party = usuario.get('party')\n",
    "    ideologia = usuario.get('ideologia')  # si está disponible\n",
    "\n",
    "    for tweet in usuario.get('tweets', []):\n",
    "        # Elegimos tweet original + replies\n",
    "        for fuente in [tweet] + tweet.get('replies', []):\n",
    "            if not isinstance(fuente, dict):\n",
    "                continue\n",
    "\n",
    "            # Etiqueta humana de sentimiento\n",
    "            label_humana = fuente.get('annotations', {}).get('Total')\n",
    "            if label_humana not in [-1, 0, 1, -1.0, 0.0, 1.0]:\n",
    "                continue\n",
    "\n",
    "            # Etiqueta del modelo\n",
    "            analysis = fuente.get('analysis')\n",
    "            if not isinstance(analysis, dict):\n",
    "                continue\n",
    "\n",
    "            pred_sentiment = analysis.get('sentiment', {}).get('label')\n",
    "            if pred_sentiment not in ['positive', 'neutral', 'negative']:\n",
    "                continue\n",
    "\n",
    "            # Convertimos la etiqueta humana a texto para comparar\n",
    "            mapping = {-1: 'negative', 0: 'neutral', 1: 'positive'}\n",
    "            label_humana_str = mapping.get(int(label_humana))\n",
    "\n",
    "            acierto = int(pred_sentiment == label_humana_str)\n",
    "\n",
    "            rows.append({\n",
    "                'gender': gender,\n",
    "                'age': age,\n",
    "                'party': party,\n",
    "                'ideologia': ideologia,\n",
    "                'acierto': acierto\n",
    "            })\n",
    "\n",
    "# === 3. Crear DataFrame ===\n",
    "df = pd.DataFrame(rows)\n",
    "\n",
    "# === 4. Categorizar edad ===\n",
    "df = df.dropna(subset=['age'])\n",
    "df['age_group'] = pd.cut(df['age'], bins=[0, 40, 100], labels=['joven', 'mayor'])\n",
    "\n",
    "# === 5. Comparar tasa de acierto por grupo ===\n",
    "grupos = ['gender', 'ideologia', 'age_group', 'party']\n",
    "resultados = []\n",
    "\n",
    "for variable in grupos:\n",
    "    grupos_unicos = df[variable].dropna().unique()\n",
    "    if len(grupos_unicos) != 2:\n",
    "        continue\n",
    "\n",
    "    g1, g2 = grupos_unicos\n",
    "    acc1 = df[df[variable] == g1]['acierto']\n",
    "    acc2 = df[df[variable] == g2]['acierto']\n",
    "\n",
    "    if len(acc1) < 10 or len(acc2) < 10:\n",
    "        continue\n",
    "\n",
    "    mean1, mean2 = acc1.mean(), acc2.mean()\n",
    "    d = cohens_d(acc1, acc2)\n",
    "    t_stat, p_value = ttest_ind(acc1, acc2, equal_var=False)\n",
    "\n",
    "    resultados.append({\n",
    "        'grupo': variable,\n",
    "        'grupo_1': g1,\n",
    "        'grupo_2': g2,\n",
    "        'acierto_1': mean1,\n",
    "        'acierto_2': mean2,\n",
    "        'diff': mean1 - mean2,\n",
    "        'd_cohen': d,\n",
    "        't_stat': t_stat,\n",
    "        'p_value': p_value,\n",
    "        'n1': len(acc1),\n",
    "        'n2': len(acc2)\n",
    "    })\n",
    "\n",
    "# === 6. Resultados ordenados ===\n",
    "df_resultados = pd.DataFrame(resultados)\n",
    "df_resultados = df_resultados.sort_values(by='d_cohen', key=lambda x: abs(x), ascending=False)\n",
    "\n",
    "# === 7. Guardar resultados ===\n",
    "df_resultados.to_csv(\"sesgo_modelo_sentimiento_espanoles.csv\", index=False, encoding='utf-8')\n",
    "print(\"✅ Resultados guardados en 'sesgo_modelo_sentimiento_espanoles.csv'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c417c617-8ae3-47c5-9300-dbafe9c72096",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Excel generado como 'resumen_politicos_espanoles.xlsx'\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "# === 1. Cargar archivo JSON ===\n",
    "with open(\"spain/Completado/Spain_Completo.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# === 2. Extraer datos de cada político ===\n",
    "rows = []\n",
    "for politico in data:\n",
    "    gender = politico.get(\"gender\")\n",
    "    age = politico.get(\"age\")\n",
    "    party = politico.get(\"party\")\n",
    "    ideologia = politico.get(\"ideologia\")\n",
    "    rows.append({\n",
    "        \"gender\": gender,\n",
    "        \"age\": age,\n",
    "        \"party\": party,\n",
    "        \"ideologia\": ideologia\n",
    "    })\n",
    "\n",
    "df = pd.DataFrame(rows)\n",
    "\n",
    "# === 3. Crear resumen ===\n",
    "resumen = {\n",
    "    \"Total de políticos\": [len(df)],\n",
    "    \"Número de hombres\": [df['gender'].str.lower().eq(\"masculino\").sum()],\n",
    "    \"Número de mujeres\": [df['gender'].str.lower().eq(\"femenino\").sum()]\n",
    "}\n",
    "df_resumen = pd.DataFrame(resumen)\n",
    "\n",
    "# === 4. Distribución por partido e ideología ===\n",
    "dist_partido = df['party'].value_counts().rename_axis('partido').reset_index(name='n_politicos')\n",
    "dist_ideologia = df['ideologia'].value_counts().rename_axis('ideologia').reset_index(name='n_politicos')\n",
    "\n",
    "# === 5. Guardar todo en un archivo Excel con varias hojas ===\n",
    "with pd.ExcelWriter(\"resumen_politicos_espanoles.xlsx\") as writer:\n",
    "    df_resumen.to_excel(writer, sheet_name=\"Resumen General\", index=False)\n",
    "    dist_partido.to_excel(writer, sheet_name=\"Por Partido\", index=False)\n",
    "    dist_ideologia.to_excel(writer, sheet_name=\"Por Ideología\", index=False)\n",
    "\n",
    "print(\"✅ Excel generado como 'resumen_politicos_espanoles.xlsx'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1d10b231-6bc3-439f-b7bb-91bbbfd0755e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Resultados guardados en 'sesgo_modelo_sentimiento_estructura_nueva.csv'\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import ttest_ind\n",
    "\n",
    "# === Función para calcular el tamaño del efecto (Cohen's d) ===\n",
    "def cohens_d(x1, x2):\n",
    "    n1, n2 = len(x1), len(x2)\n",
    "    s1, s2 = np.var(x1, ddof=1), np.var(x2, ddof=1)\n",
    "    s_pooled = np.sqrt(((n1 - 1)*s1 + (n2 - 1)*s2) / (n1 + n2 - 2))\n",
    "    return (np.mean(x1) - np.mean(x2)) / s_pooled if s_pooled > 0 else 0.0\n",
    "\n",
    "# === 1. Cargar archivo JSON ===\n",
    "with open('ingleses/Ingleses_Completo.json', 'r', encoding='utf-8') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# === 2. Extraer predicciones comparadas con etiqueta humana ===\n",
    "rows = []\n",
    "for tweet in data:\n",
    "    mp = tweet.get(\"mp\", {})\n",
    "    gender = mp.get(\"genero\")\n",
    "    age = mp.get(\"edad\")\n",
    "    party = mp.get(\"party\")\n",
    "    ideologia = mp.get(\"ideologia\")\n",
    "    pais = mp.get(\"pais\")\n",
    "    etnia = mp.get(\"etnia\")\n",
    "\n",
    "    acierto = tweet.get(\"match_sentiment_label\")\n",
    "    if isinstance(acierto, bool):\n",
    "        rows.append({\n",
    "            'gender': gender,\n",
    "            'age': age,\n",
    "            'party': party,\n",
    "            'ideologia': ideologia,\n",
    "            'pais': pais,\n",
    "            'etnia': etnia,\n",
    "            'acierto': int(acierto)  # convertir a 1 (True) o 0 (False)\n",
    "        })\n",
    "\n",
    "# === 3. Crear DataFrame ===\n",
    "df = pd.DataFrame(rows)\n",
    "\n",
    "# === 4. Categorizar edad ===\n",
    "df = df.dropna(subset=['age'])\n",
    "df['age_group'] = pd.cut(df['age'], bins=[0, 40, 100], labels=['joven', 'mayor'])\n",
    "\n",
    "# === 5. Comparar tasa de acierto por grupo ===\n",
    "grupos = ['gender', 'ideologia', 'age_group', 'party', 'etnia']\n",
    "resultados = []\n",
    "\n",
    "for variable in grupos:\n",
    "    grupos_unicos = df[variable].dropna().unique()\n",
    "    if len(grupos_unicos) != 2:\n",
    "        continue  # solo comparar si hay dos grupos\n",
    "\n",
    "    g1, g2 = grupos_unicos\n",
    "    acc1 = df[df[variable] == g1]['acierto']\n",
    "    acc2 = df[df[variable] == g2]['acierto']\n",
    "\n",
    "    if len(acc1) < 10 or len(acc2) < 10:\n",
    "        continue\n",
    "\n",
    "    mean1, mean2 = acc1.mean(), acc2.mean()\n",
    "    d = cohens_d(acc1, acc2)\n",
    "    t_stat, p_value = ttest_ind(acc1, acc2, equal_var=False)\n",
    "\n",
    "    resultados.append({\n",
    "        'grupo': variable,\n",
    "        'grupo_1': g1,\n",
    "        'grupo_2': g2,\n",
    "        'acierto_1': mean1,\n",
    "        'acierto_2': mean2,\n",
    "        'diff': mean1 - mean2,\n",
    "        'd_cohen': d,\n",
    "        't_stat': t_stat,\n",
    "        'p_value': p_value,\n",
    "        'n1': len(acc1),\n",
    "        'n2': len(acc2)\n",
    "    })\n",
    "\n",
    "# === 6. Resultados ordenados ===\n",
    "df_resultados = pd.DataFrame(resultados)\n",
    "df_resultados = df_resultados.sort_values(by='d_cohen', key=lambda x: abs(x), ascending=False)\n",
    "\n",
    "# === 7. Guardar resultados ===\n",
    "df_resultados.to_csv(\"sesgo_modelo_sentimiento_estructura_nueva.csv\", index=False, encoding='utf-8')\n",
    "print(\"✅ Resultados guardados en 'sesgo_modelo_sentimiento_estructura_nueva.csv'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "550a8e87-61ca-487d-9377-9017e60c4d6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting ace_tools\n",
      "  Downloading ace_tools-0.0-py3-none-any.whl.metadata (300 bytes)\n",
      "Downloading ace_tools-0.0-py3-none-any.whl (1.1 kB)\n",
      "Installing collected packages: ace_tools\n",
      "Successfully installed ace_tools-0.0\n"
     ]
    }
   ],
   "source": [
    "!pip install ace_tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "be76ab94-dbd0-446b-888e-60dda42fe526",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Resultados guardados como:\n",
      "- tasas_acierto_genero.csv\n",
      "- tasas_acierto_ideologia.csv\n",
      "- tasas_acierto_edad.csv\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "# Cargar datos\n",
    "with open('tweets_fusionados_ideologia.json', 'r', encoding='utf-8') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# Recolectar datos de tweets originales con anotación\n",
    "rows = []\n",
    "for usuario in data:\n",
    "    gender = usuario['gender']\n",
    "    age = usuario['age']\n",
    "    party = usuario['party']\n",
    "    ideologia = usuario['ideologia']\n",
    "    age_group = 'joven' if age is not None and age <= 40 else 'mayor' if age is not None else None\n",
    "\n",
    "    for tweet in usuario['tweets']:\n",
    "        annotations = tweet.get('annotations', {})\n",
    "        total = annotations.get('Total')\n",
    "        if total is None:\n",
    "            continue\n",
    "\n",
    "        # IA 1: Cardiff (sentiment.label)\n",
    "        sentiment_label = tweet['analysis'].get('sentiment', {}).get('label')\n",
    "\n",
    "        # IA 2: Stanza (int: -1, 0, 1)\n",
    "        sentiment_stanza = tweet['analysis'].get('sentiment_stanza')\n",
    "\n",
    "        # Convertir label de texto a número\n",
    "        label_map = {'negative': -1, 'neutral': 0, 'positive': 1}\n",
    "        sentiment_cardiff = label_map.get(sentiment_label)\n",
    "\n",
    "        row = {\n",
    "            \"gender\": gender,\n",
    "            \"age_group\": age_group,\n",
    "            \"ideologia\": ideologia,\n",
    "            \"Total\": total,\n",
    "            \"Cardiff\": sentiment_cardiff,\n",
    "            \"Stanza\": sentiment_stanza\n",
    "        }\n",
    "        rows.append(row)\n",
    "\n",
    "# Crear DataFrame\n",
    "df = pd.DataFrame(rows)\n",
    "\n",
    "# Comparar predicciones con etiqueta humana\n",
    "df['acierto_cardiff'] = df['Cardiff'] == df['Total']\n",
    "df['acierto_stanza'] = df['Stanza'] == df['Total']\n",
    "\n",
    "# Agrupar por atributo y calcular tasa de acierto\n",
    "def tasas_acierto_por(variable):\n",
    "    resumen = df.groupby(variable)[['acierto_cardiff', 'acierto_stanza']].mean() * 100\n",
    "    resumen = resumen.rename(columns={\n",
    "        'acierto_cardiff': 'Cardiff (%)',\n",
    "        'acierto_stanza': 'Stanza (%)'\n",
    "    })\n",
    "    return resumen.round(2)\n",
    "\n",
    "# Calcular tasas\n",
    "tasas_por_genero = tasas_acierto_por('gender')\n",
    "tasas_por_ideologia = tasas_acierto_por('ideologia')\n",
    "tasas_por_edad = tasas_acierto_por('age_group')\n",
    "\n",
    "# Guardar a CSV\n",
    "tasas_por_genero.to_csv('tasas_acierto_genero.csv')\n",
    "tasas_por_ideologia.to_csv('tasas_acierto_ideologia.csv')\n",
    "tasas_por_edad.to_csv('tasas_acierto_edad.csv')\n",
    "\n",
    "print(\"✅ Resultados guardados como:\")\n",
    "print(\"- tasas_acierto_genero.csv\")\n",
    "print(\"- tasas_acierto_ideologia.csv\")\n",
    "print(\"- tasas_acierto_edad.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "27ac9ae1-74bd-4117-97e3-0cdd4bc2d5d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Tweets agrupados y completados con datos auxiliares. Guardado como 'tweets_agrupados_completos.json'\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from collections import defaultdict\n",
    "\n",
    "# === 1. Cargar los archivos ===\n",
    "with open(\"tweets_1_giregos.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    tweets_data = json.load(f)\n",
    "\n",
    "with open(\"bloque_1_20_politicos.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    usuarios_extra = json.load(f)\n",
    "\n",
    "# === 2. Crear índice auxiliar con búsqueda flexible ===\n",
    "def buscar_info_extra(nombre):\n",
    "    for entry in usuarios_extra:\n",
    "        if nombre in entry['name']:\n",
    "            return entry\n",
    "    return {}\n",
    "\n",
    "# === 3. Agrupar tweets por usuario ===\n",
    "agrupados = defaultdict(lambda: {\n",
    "    \"name\": None,\n",
    "    \"age\": None,\n",
    "    \"gender\": None,\n",
    "    \"party\": None,\n",
    "    \"tweets\": []\n",
    "})\n",
    "\n",
    "for tweet in tweets_data:\n",
    "    nombre = tweet.get('name')\n",
    "    partido = tweet.get('party')\n",
    "    clave = (nombre, partido)\n",
    "\n",
    "    # Buscar datos extra si faltan\n",
    "    extra_info = buscar_info_extra(nombre)\n",
    "\n",
    "    age = tweet.get(\"age\") or extra_info.get(\"age\")\n",
    "    gender = tweet.get(\"gender\") or extra_info.get(\"gender\")\n",
    "    party = tweet.get(\"party\") or extra_info.get(\"party\")\n",
    "\n",
    "    # Asignar datos del usuario\n",
    "    usuario = agrupados[clave]\n",
    "    usuario[\"name\"] = nombre\n",
    "    usuario[\"age\"] = age if age is not None else None\n",
    "    usuario[\"gender\"] = gender if gender is not None else None\n",
    "    usuario[\"party\"] = party if party is not None else None\n",
    "\n",
    "    # Agregar tweet con toda su estructura\n",
    "    tweet_info = {\n",
    "        \"id\": tweet.get(\"id\"),\n",
    "        \"user\": tweet.get(\"user\"),\n",
    "        \"tweet\": tweet.get(\"tweet\"),\n",
    "        \"label\": tweet.get(\"label\"),\n",
    "        \"annotator\": tweet.get(\"annotator\"),\n",
    "        \"analysis\": tweet.get(\"analysis\"),\n",
    "        \"replies\": tweet.get(\"replies\")\n",
    "    }\n",
    "\n",
    "    usuario[\"tweets\"].append(tweet_info)\n",
    "\n",
    "# === 4. Convertir a lista final y guardar ===\n",
    "resultado = list(agrupados.values())\n",
    "\n",
    "with open(\"tweets_agrupados_completos.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(resultado, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "print(\"✅ Tweets agrupados y completados con datos auxiliares. Guardado como 'tweets_agrupados_completos.json'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "59671d29-16b0-45c1-9b90-d86ad1abbc12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 TOTALES GENERALES:\n",
      "- Total de usuarios: 168\n",
      "- Total de tweets: 959\n",
      "- Total de replies: 2328\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Cargar archivo\n",
    "with open(\"grecia_anotados/Preprado/tweets_agrupados_completos_final.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    usuarios = json.load(f)\n",
    "\n",
    "# Contar totales\n",
    "total_usuarios = len(usuarios)\n",
    "total_tweets = sum(len(u.get(\"tweets\", [])) for u in usuarios)\n",
    "total_replies = sum(len(t.get(\"replies\", [])) for u in usuarios for t in u.get(\"tweets\", []))\n",
    "\n",
    "# Mostrar resultados\n",
    "print(\"📊 TOTALES GENERALES:\")\n",
    "print(f\"- Total de usuarios: {total_usuarios}\")\n",
    "print(f\"- Total de tweets: {total_tweets}\")\n",
    "print(f\"- Total de replies: {total_replies}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e16f7e2d-ac16-4dd8-9e24-0b498ea97949",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Eliminados 41 usuarios con nombre erróneo.\n",
      "📁 Archivo limpio guardado como 'tweets_agrupados_sin_errores.json'\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Cargar archivo original\n",
    "with open(\"tweets_agrupados_completos.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    usuarios = json.load(f)\n",
    "\n",
    "# Filtrar usuarios válidos\n",
    "usuarios_limpios = [\n",
    "    u for u in usuarios\n",
    "    if not (isinstance(u.get(\"name\"), str) and u[\"name\"].startswith(\"Error al extraer usuario\"))\n",
    "]\n",
    "\n",
    "# Guardar archivo limpio\n",
    "with open(\"tweets_agrupados_sin_errores.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(usuarios_limpios, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "print(f\"✅ Eliminados {len(usuarios) - len(usuarios_limpios)} usuarios con nombre erróneo.\")\n",
    "print(\"📁 Archivo limpio guardado como 'tweets_agrupados_sin_errores.json'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "76825364-5cf2-431f-8d36-2201742c97ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Archivo actualizado guardado como 'tweets_agrupados_completos_final.json'\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "# === 1. Cargar usuarios con metadatos corregidos desde Excel ===\n",
    "df_corr = pd.read_excel(\"usuarios_incompletos_completados_updated.xlsx\")\n",
    "\n",
    "# Normalizar los nombres para buscar por inclusión parcial\n",
    "usuarios_corr = []\n",
    "for _, row in df_corr.iterrows():\n",
    "    usuarios_corr.append({\n",
    "        \"name\": str(row[\"name\"]).strip().lower(),\n",
    "        \"age\": row.get(\"age\"),\n",
    "        \"gender\": row.get(\"gender\"),\n",
    "        \"party\": row.get(\"party\")\n",
    "    })\n",
    "\n",
    "# === 2. Cargar el archivo JSON original de tweets agrupados ===\n",
    "with open(\"tweets_agrupados_sin_errores.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    datos = json.load(f)\n",
    "\n",
    "# === 3. Función para buscar en lista de usuarios corregidos ===\n",
    "def buscar_metadata(nombre):\n",
    "    nombre = nombre.strip().lower()\n",
    "    for u in usuarios_corr:\n",
    "        if nombre in u[\"name\"] or u[\"name\"] in nombre:\n",
    "            return u\n",
    "    return {}\n",
    "\n",
    "# === 4. Completar los campos que estén a None ===\n",
    "for usuario in datos:\n",
    "    if usuario.get(\"age\") is None or usuario.get(\"gender\") is None or usuario.get(\"party\") is None:\n",
    "        info = buscar_metadata(usuario[\"name\"])\n",
    "        if usuario.get(\"age\") is None:\n",
    "            usuario[\"age\"] = info.get(\"age\")\n",
    "        if usuario.get(\"gender\") is None:\n",
    "            usuario[\"gender\"] = info.get(\"gender\")\n",
    "        if usuario.get(\"party\") is None:\n",
    "            usuario[\"party\"] = info.get(\"party\")\n",
    "\n",
    "# === 5. Guardar el nuevo JSON completo ===\n",
    "with open(\"tweets_agrupados_completos_final.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(datos, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "print(\"✅ Archivo actualizado guardado como 'tweets_agrupados_completos_final.json'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1830ffbc-9d45-4fda-a5f6-8fec1c938123",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "# Cargar el archivo limpio y agrupado\n",
    "with open('tweets_agrupados_sin_errores.json', 'r', encoding='utf-8') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# Recolectar datos de tweets originales con anotación\n",
    "rows = []\n",
    "for usuario in data:\n",
    "    gender = usuario.get('gender')\n",
    "    age = usuario.get('age')\n",
    "    party = usuario.get('party')\n",
    "    age_group = 'joven' if age is not None and age <= 40 else 'mayor' if age is not None else None\n",
    "\n",
    "    for tweet in usuario.get('tweets', []):\n",
    "        annotations = tweet.get('annotations', {})\n",
    "        total = annotations.get('Total')\n",
    "        if total is None:\n",
    "            continue\n",
    "\n",
    "        # IA 1: Cardiff (sentiment.label)\n",
    "        sentiment_label = tweet['analysis'].get('sentiment', {}).get('label')\n",
    "\n",
    "        # IA 2: Stanza (int: -1, 0, 1)\n",
    "\n",
    "        # Convertir label de texto a número\n",
    "        label_map = {'negative': -1, 'neutral': 0, 'positive': 1}\n",
    "        sentiment_cardiff = label_map.get(sentiment_label)\n",
    "\n",
    "        row = {\n",
    "            \"gender\": gender,\n",
    "            \"age_group\": age_group,\n",
    "            \"party\": party,\n",
    "            \"Total\": total,\n",
    "            \"Cardiff\": sentiment_cardiff,\n",
    "        }\n",
    "        rows.append(row)\n",
    "\n",
    "# Crear DataFrame\n",
    "df = pd.DataFrame(rows)\n",
    "\n",
    "# Comparar predicciones con etiqueta humana\n",
    "df['acierto_cardiff'] = df['Cardiff'] == df['Total']\n",
    "\n",
    "# Agrupar por atributo y calcular tasa de acierto\n",
    "def tasas_acierto_por(variable):\n",
    "    resumen = df.groupby(variable)[['acierto_cardiff', 'acierto_stanza']].mean() * 100\n",
    "    resumen = resumen.rename(columns={\n",
    "        'acierto_cardiff': 'Cardiff (%)',\n",
    "        'acierto_stanza': 'Stanza (%)'\n",
    "    })\n",
    "    return resumen.round(2)\n",
    "\n",
    "# Calcular tasas\n",
    "tasas_por_genero = tasas_acierto_por('gender')\n",
    "tasas_por_partido = tasas_acierto_por('party')\n",
    "tasas_por_edad = tasas_acierto_por('age_group')\n",
    "\n",
    "# Guardar a CSV\n",
    "tasas_por_genero.to_csv('tasas_acierto_genero.csv')\n",
    "tasas_por_partido.to_csv('tasas_acierto_partido.csv')\n",
    "tasas_por_edad.to_csv('tasas_acierto_edad.csv')\n",
    "\n",
    "print(\"✅ Resultados guardados como:\")\n",
    "print(\"- tasas_acierto_genero.csv\")\n",
    "print(\"- tasas_acierto_partido.csv\")\n",
    "print(\"- tasas_acierto_edad.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c393fe41-4840-4184-84c8-a762e4c11643",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-06 10:47:18 INFO: Checking for updates to resources.json in case models have been updated.  Note: this behavior can be turned off with download_method=None or download_method=DownloadMethod.REUSE_RESOURCES\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7cf92ba3921e4280b4984bd890d513d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.10.0.json:   0%|  …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-06 10:47:18 INFO: Downloaded file to /home/jupyter-lquijano/stanza_resources/resources.json\n",
      "2025-05-06 10:47:18 WARNING: Language es package default expects mwt, which has been added\n",
      "2025-05-06 10:47:19 INFO: Loading these models for language: es (Spanish):\n",
      "===============================\n",
      "| Processor | Package         |\n",
      "-------------------------------\n",
      "| tokenize  | combined        |\n",
      "| mwt       | combined        |\n",
      "| pos       | combined_charlm |\n",
      "===============================\n",
      "\n",
      "2025-05-06 10:47:19 INFO: Using device: cuda\n",
      "2025-05-06 10:47:19 INFO: Loading: tokenize\n",
      "2025-05-06 10:47:19 INFO: Loading: mwt\n",
      "2025-05-06 10:47:19 INFO: Loading: pos\n",
      "2025-05-06 10:47:20 INFO: Done loading processors!\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import stanza\n",
    "\n",
    "# Carga el pipeline en español\n",
    "nlp = stanza.Pipeline(lang='es', processors='tokenize,pos', tokenize_pretokenized=False)\n",
    "\n",
    "# Lista de etiquetas POS irrelevantes que queremos eliminar\n",
    "irrelevant_pos = {\"DET\", \"ADP\", \"PUNCT\", \"CCONJ\", \"SCONJ\", \"PART\"}\n",
    "\n",
    "def get_filtered_pos(text):\n",
    "    doc = nlp(text)\n",
    "    pos_tags = []\n",
    "    for sentence in doc.sentences:\n",
    "        for word in sentence.words:\n",
    "            if word.upos not in irrelevant_pos:\n",
    "                pos_tags.append(word.upos)\n",
    "    return pos_tags\n",
    "\n",
    "# Carga tus datos (por ejemplo desde un archivo JSON)\n",
    "with open(\"spain/Completado/Spain_Completo.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# Procesa cada tweet y sus replies\n",
    "for person in data:\n",
    "    for tweet in person[\"tweets\"]:\n",
    "        tweet[\"filtered_pos_tags\"] = get_filtered_pos(tweet[\"tweet\"])\n",
    "        for reply in tweet.get(\"replies\", []):\n",
    "            reply[\"filtered_pos_tags\"] = get_filtered_pos(reply[\"reply\"])\n",
    "\n",
    "# Guarda el archivo con las nuevas etiquetas POS filtradas\n",
    "with open(\"datos_filtrados.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(data, f, ensure_ascii=False, indent=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b083ad60-67b8-4e48-8978-4fee3b0dcb5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a24f59f7de4c4a65b4c4c36471c9dda4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.10.0.json:   0%|  …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-06 11:09:00 INFO: Downloaded file to /home/jupyter-lquijano/stanza_resources/resources.json\n",
      "2025-05-06 11:09:00 INFO: Downloading default packages for language: en (English) ...\n",
      "2025-05-06 11:09:01 INFO: File exists: /home/jupyter-lquijano/stanza_resources/en/default.zip\n",
      "2025-05-06 11:09:04 INFO: Finished downloading models and saved to /home/jupyter-lquijano/stanza_resources\n",
      "2025-05-06 11:09:04 INFO: Checking for updates to resources.json in case models have been updated.  Note: this behavior can be turned off with download_method=None or download_method=DownloadMethod.REUSE_RESOURCES\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c37aa06c365343dda3246b948f997ffc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.10.0.json:   0%|  …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-06 11:09:04 INFO: Downloaded file to /home/jupyter-lquijano/stanza_resources/resources.json\n",
      "2025-05-06 11:09:04 WARNING: Language en package default expects mwt, which has been added\n",
      "2025-05-06 11:09:05 INFO: Loading these models for language: en (English):\n",
      "===============================\n",
      "| Processor | Package         |\n",
      "-------------------------------\n",
      "| tokenize  | combined        |\n",
      "| mwt       | combined        |\n",
      "| pos       | combined_charlm |\n",
      "===============================\n",
      "\n",
      "2025-05-06 11:09:05 INFO: Using device: cuda\n",
      "2025-05-06 11:09:05 INFO: Loading: tokenize\n",
      "2025-05-06 11:09:05 INFO: Loading: mwt\n",
      "2025-05-06 11:09:05 INFO: Loading: pos\n",
      "2025-05-06 11:09:06 INFO: Done loading processors!\n"
     ]
    }
   ],
   "source": [
    "import stanza\n",
    "import json\n",
    "\n",
    "# Configura el pipeline de inglés\n",
    "stanza.download(\"en\")\n",
    "nlp = stanza.Pipeline(lang='en', processors='tokenize,pos', tokenize_pretokenized=False)\n",
    "\n",
    "# Etiquetas POS que vamos a filtrar (irrelevantes para análisis semántico)\n",
    "irrelevant_pos = {\"DET\", \"ADP\", \"PUNCT\", \"CCONJ\", \"SCONJ\", \"PART\", \"SYM\", \"X\"}\n",
    "\n",
    "def get_filtered_pos(text):\n",
    "    doc = nlp(text)\n",
    "    pos_tags = []\n",
    "    for sentence in doc.sentences:\n",
    "        for word in sentence.words:\n",
    "            if word.upos not in irrelevant_pos:\n",
    "                pos_tags.append(word.upos)\n",
    "    return pos_tags\n",
    "\n",
    "# Cargar los datos\n",
    "with open(\"ingleses/Ingleses_Completo.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# Procesar cada entrada del JSON\n",
    "for tweet in data:\n",
    "    tweet[\"filtered_pos_tags\"] = get_filtered_pos(tweet[\"text\"])\n",
    "\n",
    "# Guardar los resultados en un nuevo archivo\n",
    "with open(\"tweets_filtrados_ingleses.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(data, f, indent=2, ensure_ascii=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "52fbc246-2f7d-4e99-9e50-9ee7d5b56dc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Resultados guardados en 'cohens_d_analisis.csv'\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import ttest_ind\n",
    "from collections import defaultdict\n",
    "\n",
    "# Cargar datos\n",
    "with open(\"tweets_filtrados_ingleses.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# Clasificación de edad\n",
    "def categorizar_edad(edad):\n",
    "    if edad < 40:\n",
    "        return \"joven\"\n",
    "    elif edad <= 60:\n",
    "        return \"adulto\"\n",
    "    else:\n",
    "        return \"mayor\"\n",
    "\n",
    "# Extraer filas con métricas útiles\n",
    "rows = []\n",
    "for entry in data:\n",
    "    mp = entry[\"mp\"]\n",
    "    pos_tags = entry.get(\"filtered_pos_tags\", [])\n",
    "    total = len(pos_tags)\n",
    "    if total == 0:\n",
    "        continue\n",
    "\n",
    "    row = {\n",
    "        \"pais\": mp.get(\"pais\", \"Unknown\"),\n",
    "        \"genero\": mp.get(\"genero\", \"Unknown\"),\n",
    "        \"etnia\": mp.get(\"etnia\", \"Unknown\"),\n",
    "        \"ideologia\": mp.get(\"ideologia\", \"Unknown\"),\n",
    "        \"party\": mp.get(\"party\", \"Unknown\"),\n",
    "        \"edad_grupo\": categorizar_edad(mp.get(\"edad\", 0)),\n",
    "    }\n",
    "\n",
    "    # POS tags\n",
    "    tag_counts = defaultdict(int)\n",
    "    for tag in pos_tags:\n",
    "        tag_counts[tag] += 1\n",
    "    for tag, count in tag_counts.items():\n",
    "        row[f\"POS_{tag}\"] = count / total  # proporción\n",
    "\n",
    "    # Emociones y scores\n",
    "    nlp = entry.get(\"nlp\", {})\n",
    "    for key in [\"sentiment_score\", \"hate_score\", \"emotion_score\"]:\n",
    "        val = nlp.get(key)\n",
    "        if val is not None:\n",
    "            row[key] = val\n",
    "    for key in [\"joy\", \"anger\", \"sadness\", \"optimism\"]:\n",
    "        if f\"{key}_score\" in nlp:\n",
    "            row[key] = nlp[f\"{key}_score\"]\n",
    "\n",
    "    rows.append(row)\n",
    "\n",
    "# Crear DataFrame\n",
    "df = pd.DataFrame(rows).fillna(0)\n",
    "\n",
    "# Comparaciones a hacer\n",
    "comparisons = {\n",
    "    \"genero\": [\"Male\", \"Female\"],\n",
    "    \"ideologia\": [\"derecha\", \"izquierda\"],\n",
    "    \"edad_grupo\": [\"joven\", \"mayor\"]\n",
    "}\n",
    "\n",
    "# Variables a comparar\n",
    "metricas = [col for col in df.columns if col.startswith(\"POS_\")] + [\n",
    "    \"joy\", \"anger\", \"sadness\", \"optimism\", \"sentiment_score\", \"hate_score\"\n",
    "]\n",
    "\n",
    "# Función de Cohen's d\n",
    "def cohens_d(x1, x2):\n",
    "    n1, n2 = len(x1), len(x2)\n",
    "    s1, s2 = np.var(x1, ddof=1), np.var(x2, ddof=1)\n",
    "    s_pooled = np.sqrt(((n1 - 1)*s1 + (n2 - 1)*s2) / (n1 + n2 - 2))\n",
    "    if s_pooled == 0:\n",
    "        return 0.0\n",
    "    return (np.mean(x1) - np.mean(x2)) / s_pooled\n",
    "\n",
    "# Analizar y guardar resultados\n",
    "resultados = []\n",
    "\n",
    "for grupo, (g1, g2) in comparisons.items():\n",
    "    df1 = df[df[grupo] == g1]\n",
    "    df2 = df[df[grupo] == g2]\n",
    "\n",
    "    for metrica in metricas:\n",
    "        if metrica not in df.columns:\n",
    "            continue\n",
    "\n",
    "        x1 = df1[metrica]\n",
    "        x2 = df2[metrica]\n",
    "\n",
    "        if len(x1) < 10 or len(x2) < 10:\n",
    "            continue\n",
    "\n",
    "        d = cohens_d(x1, x2)\n",
    "        t_stat, p_value = ttest_ind(x1, x2, equal_var=False)\n",
    "\n",
    "        resultados.append({\n",
    "            \"grupo\": grupo,\n",
    "            \"valor\": metrica,\n",
    "            \"grupo_1\": g1,\n",
    "            \"grupo_2\": g2,\n",
    "            \"d_cohen\": d,\n",
    "            \"t_stat\": t_stat,\n",
    "            \"p_value\": p_value,\n",
    "            \"n1\": len(x1),\n",
    "            \"n2\": len(x2)\n",
    "        })\n",
    "\n",
    "# Convertir a DataFrame y guardar\n",
    "df_resultados = pd.DataFrame(resultados)\n",
    "df_resultados.to_csv(\"cohens_d_analisis.csv\", index=False)\n",
    "\n",
    "print(\"✅ Resultados guardados en 'cohens_d_analisis.csv'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "99f191c9-5d3e-43d1-9cea-3fea8c3a092f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Análisis completo. Resultados guardados en 'cohens_d_espanol.csv'\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import ttest_ind\n",
    "from collections import defaultdict\n",
    "\n",
    "# Cargar datos\n",
    "with open(\"datos_filtrados.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# Clasificación de edad\n",
    "def categorizar_edad(edad):\n",
    "    if edad < 40:\n",
    "        return \"joven\"\n",
    "    elif edad <= 60:\n",
    "        return \"adulto\"\n",
    "    else:\n",
    "        return \"mayor\"\n",
    "\n",
    "# Extraer datos tweet y replies\n",
    "rows = []\n",
    "\n",
    "for persona in data:\n",
    "    genero = persona.get(\"gender\", \"Unknown\")\n",
    "    edad = persona.get(\"age\", None)\n",
    "    edad_grupo = categorizar_edad(edad) if edad is not None else \"Unknown\"\n",
    "    party = persona.get(\"party\", \"Unknown\")\n",
    "    nombre = persona.get(\"name\", \"Unknown\")\n",
    "    pais = \"esp\"\n",
    "\n",
    "    for tweet in persona.get(\"tweets\", []):\n",
    "        # Añadir tweet principal\n",
    "        for fuente, pos_tags in [(\"tweet\", tweet.get(\"filtered_pos_tags\", []))] + \\\n",
    "                                 [(\"reply\", reply.get(\"filtered_pos_tags\", [])) for reply in tweet.get(\"replies\", [])]:\n",
    "            total = len(pos_tags)\n",
    "            if total == 0:\n",
    "                continue\n",
    "\n",
    "            tag_counts = defaultdict(int)\n",
    "            for tag in pos_tags:\n",
    "                tag_counts[tag] += 1\n",
    "\n",
    "            row = {\n",
    "                \"pais\": pais,\n",
    "                \"genero\": genero,\n",
    "                \"edad_grupo\": edad_grupo,\n",
    "                \"party\": party,\n",
    "                \"origen\": fuente,\n",
    "                \"nombre\": nombre\n",
    "            }\n",
    "\n",
    "            for tag, count in tag_counts.items():\n",
    "                row[f\"POS_{tag}\"] = count / total\n",
    "\n",
    "            rows.append(row)\n",
    "\n",
    "# Crear DataFrame\n",
    "df = pd.DataFrame(rows).fillna(0)\n",
    "\n",
    "# Definir comparaciones posibles\n",
    "comparisons = {}\n",
    "\n",
    "# Género (si hay suficientes ejemplos)\n",
    "generos = df[\"genero\"].value_counts()\n",
    "if len(generos) >= 2 and all(generos >= 10):\n",
    "    comparisons[\"genero\"] = list(generos.index[:2])\n",
    "\n",
    "# Edad (joven vs mayor)\n",
    "comparisons[\"edad_grupo\"] = [\"joven\", \"mayor\"]\n",
    "\n",
    "# Partido (si hay al menos 2 grupos grandes)\n",
    "partidos = df[\"party\"].value_counts()\n",
    "if len(partidos) >= 2 and all(partidos[:2] >= 10):\n",
    "    comparisons[\"party\"] = list(partidos.index[:2])\n",
    "\n",
    "# Variables a comparar (solo POS)\n",
    "metricas = [col for col in df.columns if col.startswith(\"POS_\")]\n",
    "\n",
    "# Función de Cohen's d\n",
    "def cohens_d(x1, x2):\n",
    "    n1, n2 = len(x1), len(x2)\n",
    "    s1, s2 = np.var(x1, ddof=1), np.var(x2, ddof=1)\n",
    "    s_pooled = np.sqrt(((n1 - 1)*s1 + (n2 - 1)*s2) / (n1 + n2 - 2))\n",
    "    if s_pooled == 0:\n",
    "        return 0.0\n",
    "    return (np.mean(x1) - np.mean(x2)) / s_pooled\n",
    "\n",
    "# Ejecutar comparaciones\n",
    "resultados = []\n",
    "\n",
    "for grupo, (g1, g2) in comparisons.items():\n",
    "    df1 = df[df[grupo] == g1]\n",
    "    df2 = df[df[grupo] == g2]\n",
    "\n",
    "    for metrica in metricas:\n",
    "        x1 = df1[metrica]\n",
    "        x2 = df2[metrica]\n",
    "\n",
    "        if len(x1) < 10 or len(x2) < 10:\n",
    "            continue\n",
    "\n",
    "        d = cohens_d(x1, x2)\n",
    "        t_stat, p_value = ttest_ind(x1, x2, equal_var=False)\n",
    "\n",
    "        resultados.append({\n",
    "            \"grupo\": grupo,\n",
    "            \"valor\": metrica,\n",
    "            \"grupo_1\": g1,\n",
    "            \"grupo_2\": g2,\n",
    "            \"d_cohen\": round(d, 5),\n",
    "            \"t_stat\": round(t_stat, 5),\n",
    "            \"p_value\": p_value,\n",
    "            \"n1\": len(x1),\n",
    "            \"n2\": len(x2)\n",
    "        })\n",
    "\n",
    "# Exportar resultados\n",
    "df_resultados = pd.DataFrame(resultados)\n",
    "df_resultados.to_csv(\"cohens_d_espanol.csv\", index=False)\n",
    "\n",
    "print(\"✅ Análisis completo. Resultados guardados en 'cohens_d_espanol.csv'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c016fb87-85f8-4eaa-8e46-7a18fac896e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Resultados guardados en 'cohens_d_griegos.csv'\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import ttest_ind\n",
    "\n",
    "# Cargar datos griegos\n",
    "with open(\"grecia_anotados/Preprado/Griegos_f.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# Clasificar edad\n",
    "def categorizar_edad(edad):\n",
    "    if edad < 40:\n",
    "        return \"joven\"\n",
    "    elif edad <= 60:\n",
    "        return \"adulto\"\n",
    "    else:\n",
    "        return \"mayor\"\n",
    "\n",
    "# Extraer tweets y replies con métricas POS\n",
    "rows = []\n",
    "\n",
    "for persona in data:\n",
    "    genero = persona.get(\"gender\", \"Unknown\")\n",
    "    edad = persona.get(\"age\", None)\n",
    "    edad_grupo = categorizar_edad(edad) if edad is not None else \"Unknown\"\n",
    "    partido = persona.get(\"party\", \"Unknown\")\n",
    "    ideologia = persona.get(\"polaridad_ideologica\", \"Unknown\")\n",
    "    nombre = persona.get(\"name\", \"Unknown\")\n",
    "    pais = \"gre\"\n",
    "\n",
    "    for tweet in persona.get(\"tweets\", []):\n",
    "        analysis = tweet.get(\"analysis\", {})\n",
    "        pos = analysis.get(\"pos_features\", {})\n",
    "        if not pos:\n",
    "            continue\n",
    "\n",
    "        row = {\n",
    "            \"pais\": pais,\n",
    "            \"nombre\": nombre,\n",
    "            \"gender\": genero,\n",
    "            \"edad_grupo\": edad_grupo,\n",
    "            \"party\": partido,\n",
    "            \"ideologia\": ideologia,\n",
    "        }\n",
    "\n",
    "        for k, v in pos.items():\n",
    "            # convertir a número si es posible\n",
    "            if isinstance(v, (int, float)) or (isinstance(v, str) and v.replace('.', '', 1).isdigit()):\n",
    "                row[k] = float(v)\n",
    "\n",
    "        rows.append(row)\n",
    "\n",
    "# Crear DataFrame\n",
    "df = pd.DataFrame(rows).fillna(0)\n",
    "\n",
    "# Comparaciones posibles\n",
    "comparisons = {}\n",
    "\n",
    "if df[\"gender\"].nunique() >= 2:\n",
    "    top2 = df[\"gender\"].value_counts().index[:2]\n",
    "    comparisons[\"gender\"] = list(top2)\n",
    "\n",
    "if df[\"edad_grupo\"].nunique() >= 2:\n",
    "    comparisons[\"edad_grupo\"] = [\"joven\", \"mayor\"]\n",
    "\n",
    "if df[\"party\"].nunique() >= 2:\n",
    "    top2 = df[\"party\"].value_counts().index[:2]\n",
    "    comparisons[\"party\"] = list(top2)\n",
    "\n",
    "if df[\"ideologia\"].nunique() >= 2:\n",
    "    top2 = df[\"ideologia\"].value_counts().index[:2]\n",
    "    comparisons[\"ideologia\"] = list(top2)\n",
    "\n",
    "# Métricas POS\n",
    "metricas = [col for col in df.columns if col.startswith(\"num_\") or col.startswith(\"ratio_\")]\n",
    "\n",
    "# Función para Cohen's d\n",
    "def cohens_d(x1, x2):\n",
    "    n1, n2 = len(x1), len(x2)\n",
    "    s1, s2 = np.var(x1, ddof=1), np.var(x2, ddof=1)\n",
    "    s_pooled = np.sqrt(((n1 - 1)*s1 + (n2 - 1)*s2) / (n1 + n2 - 2))\n",
    "    return (np.mean(x1) - np.mean(x2)) / s_pooled if s_pooled > 0 else 0\n",
    "\n",
    "# Comparar y guardar resultados\n",
    "resultados = []\n",
    "\n",
    "for grupo, (g1, g2) in comparisons.items():\n",
    "    df1 = df[df[grupo] == g1]\n",
    "    df2 = df[df[grupo] == g2]\n",
    "\n",
    "    for metrica in metricas:\n",
    "        if metrica not in df.columns:\n",
    "            continue\n",
    "\n",
    "        x1 = df1[metrica]\n",
    "        x2 = df2[metrica]\n",
    "\n",
    "        if len(x1) < 10 or len(x2) < 10:\n",
    "            continue\n",
    "\n",
    "        d = cohens_d(x1, x2)\n",
    "        t_stat, p_value = ttest_ind(x1, x2, equal_var=False)\n",
    "\n",
    "        resultados.append({\n",
    "            \"grupo\": grupo,\n",
    "            \"valor\": metrica,\n",
    "            \"grupo_1\": g1,\n",
    "            \"grupo_2\": g2,\n",
    "            \"d_cohen\": round(d, 5),\n",
    "            \"t_stat\": round(t_stat, 5),\n",
    "            \"p_value\": p_value,\n",
    "            \"n1\": len(x1),\n",
    "            \"n2\": len(x2)\n",
    "        })\n",
    "\n",
    "# Guardar resultados\n",
    "df_resultados = pd.DataFrame(resultados)\n",
    "df_resultados.to_csv(\"cohens_d_griegos.csv\", index=False)\n",
    "\n",
    "print(\"✅ Resultados guardados en 'cohens_d_griegos.csv'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a8b445d-9446-4f8a-8c40-93b89e0d00fd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
