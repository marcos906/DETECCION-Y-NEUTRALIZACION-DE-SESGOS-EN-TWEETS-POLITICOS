{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4379f134-6c43-4425-b5c6-3bbbe6230a90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cargados 500 tweets de tweets_griegos_stanza_1_500.json\n",
      "Cargados 500 tweets de tweets_griegos_stanza_501_1000.json\n",
      "Total combinado: 1000 tweets\n",
      "‚úÖ Todos los tweets guardados en tweets_espa√±oles_evaluados_completo.json\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Archivos de entrada\n",
    "input_files = [\n",
    "    \"tweets_griegos_stanza_1_500.json\",\n",
    "    \"tweets_griegos_stanza_501_1000.json\"\n",
    "]\n",
    "output_file = \"tweets_espa√±oles_evaluados_completo.json\"\n",
    "\n",
    "all_tweets = []\n",
    "\n",
    "for path in input_files:\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        data = json.load(f)\n",
    "        print(f\"Cargados {len(data)} tweets de {path}\")\n",
    "        # Asegurarse de que 'data' es una lista\n",
    "        if isinstance(data, list):\n",
    "            all_tweets.extend(data)\n",
    "        else:\n",
    "            raise ValueError(f\"El archivo {path} no contiene una lista de tweets.\")\n",
    "\n",
    "print(f\"Total combinado: {len(all_tweets)} tweets\")\n",
    "\n",
    "# Guardar resultado\n",
    "with open(output_file, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(all_tweets, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "print(f\"‚úÖ Todos los tweets guardados en {output_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f95bf344-ea12-47d0-8540-55f8cfefc285",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Metadatos a√±adidos a 1000 tweets. Archivo guardado en 'tweets_griegos_con_meta.json'.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import csv\n",
    "\n",
    "# 1) Rutas de entrada y salida\n",
    "json_input  = \"tweets_griegos_evaluados_completo.json\"\n",
    "csv_input   = \"grecia_anotados/gr_combined.csv\"                # CSV con columnas: id, label, annotator\n",
    "json_output = \"tweets_griegos_con_meta.json\"\n",
    "\n",
    "# 2) Leer registros del CSV\n",
    "records = []\n",
    "with open(csv_input, newline='', encoding='utf-8') as f:\n",
    "    reader = csv.DictReader(f)\n",
    "    for row in reader:\n",
    "        records.append(row)\n",
    "\n",
    "# 3) Cargar el JSON combinado\n",
    "with open(json_input, \"r\", encoding=\"utf-8\") as f:\n",
    "    tweets = json.load(f)\n",
    "\n",
    "# 4) Verificar que coincidan en longitud\n",
    "if len(records) != len(tweets):\n",
    "    raise ValueError(f\"El CSV tiene {len(records)} filas, pero el JSON tiene {len(tweets)} tweets.\")\n",
    "\n",
    "# 5) Asignar id, label y annotator\n",
    "for rec, tweet in zip(records, tweets):\n",
    "    tweet[\"id\"]        = rec[\"id\"]\n",
    "    tweet[\"label\"]     = rec.get(\"label\")\n",
    "    tweet[\"annotator\"] = rec.get(\"annotator\")\n",
    "\n",
    "# 6) Guardar el JSON resultante\n",
    "with open(json_output, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(tweets, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "print(f\"‚úÖ Metadatos a√±adidos a {len(tweets)} tweets. Archivo guardado en '{json_output}'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e13d15fe-cd88-4c17-8045-005a78500ec8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N√∫mero de tweets: 1000\n",
      "N√∫mero total de replies: 3082\n",
      "Media de replies por tweet: 3.08\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "INPUT_JSON = 'spain/Completado/tweets_espa√±oles_evaluados_completo.json'\n",
    "\n",
    "# Cargar archivo JSON\n",
    "with open(INPUT_JSON, 'r', encoding='utf-8') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# N√∫mero de tweets\n",
    "num_tweets = len(data)\n",
    "\n",
    "# N√∫mero total de replies\n",
    "total_replies = sum(len(item.get('replies', [])) for item in data)\n",
    "\n",
    "# Media de replies por tweet\n",
    "avg_replies = total_replies / num_tweets if num_tweets > 0 else 0\n",
    "\n",
    "print(f\"N√∫mero de tweets: {num_tweets}\")\n",
    "print(f\"N√∫mero total de replies: {total_replies}\")\n",
    "print(f\"Media de replies por tweet: {avg_replies:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "36e31b26-ed9a-4117-b897-e1159be37b30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Guardados 172 usuarios √∫nicos con tweets en 'users_espa√±oles.json'.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import unicodedata\n",
    "from collections import defaultdict\n",
    "\n",
    "# Rutas de entrada y salida\n",
    "input_path = \"spain/Completado/tweets_espa√±oles_evaluados_completo.json\"\n",
    "output_path = \"users_espa√±oles.json\"\n",
    "\n",
    "# Funci√≥n para normalizar nombres\n",
    "def normalize_name(name):\n",
    "    name = name.lower().strip()\n",
    "    name = unicodedata.normalize('NFKD', name)\n",
    "    name = ''.join(c for c in name if not unicodedata.combining(c))\n",
    "    name = name.replace(\"(\", \"\").replace(\")\", \"\")\n",
    "    return \" \".join(name.split())\n",
    "\n",
    "# Carga de tweets\n",
    "with open(input_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# Para evitar duplicados y asociar tweet IDs\n",
    "users_dict = {}\n",
    "seen_usernames = set()\n",
    "\n",
    "# Para agrupar los tweet IDs por usuario original (raw_user)\n",
    "user_to_ids = defaultdict(list)\n",
    "\n",
    "for item in data:\n",
    "    raw_user = item.get(\"user\", \"\").strip()\n",
    "    tweet_id = item.get(\"id\")\n",
    "    party = item.get(\"mp_party\")\n",
    "\n",
    "    if not raw_user or raw_user.startswith(\"Error al extraer usuario\"):\n",
    "        continue\n",
    "\n",
    "    # Extraer nombre y @usuario\n",
    "    if \"\\n\" in raw_user:\n",
    "        lines = [line.strip() for line in raw_user.splitlines() if line.strip()]\n",
    "        if len(lines) >= 2 and lines[-1].startswith(\"@\"):\n",
    "            name = \" \".join(lines[:-1])\n",
    "            username = lines[-1]\n",
    "        else:\n",
    "            continue\n",
    "    else:\n",
    "        tokens = raw_user.split()\n",
    "        username = None\n",
    "        for t in reversed(tokens):\n",
    "            if t.startswith(\"@\"):\n",
    "                username = t\n",
    "                break\n",
    "        if username:\n",
    "            name = raw_user[: raw_user.rfind(username)].strip()\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "    # Agregar tweet ID\n",
    "    if tweet_id:\n",
    "        user_to_ids[username].append(tweet_id)\n",
    "\n",
    "    # Si ya se proces√≥ este username, solo agregamos el tweet\n",
    "    if username in seen_usernames:\n",
    "        continue\n",
    "\n",
    "    seen_usernames.add(username)\n",
    "    users_dict[username] = {\n",
    "        \"name\": name,\n",
    "        \"user\": username,\n",
    "        \"party\": party,\n",
    "        \"normalized_name\": normalize_name(name),\n",
    "        \"tweet_ids\": []  # se a√±adir√° m√°s abajo\n",
    "    }\n",
    "\n",
    "# A√±adir los IDs recolectados\n",
    "for username, tweet_ids in user_to_ids.items():\n",
    "    if username in users_dict:\n",
    "        users_dict[username][\"tweet_ids\"] = tweet_ids\n",
    "\n",
    "# Exportar a JSON\n",
    "users = list(users_dict.values())\n",
    "with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(users, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "print(f\"‚úÖ Guardados {len(users)} usuarios √∫nicos con tweets en '{output_path}'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8e9149f2-7351-4e43-94e5-3b1f7e578e4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Asignados 1000 IDs. Salvo en 'Tweets_espa√±oles_id.json'.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import re\n",
    "\n",
    "# 1) Rutas de tus archivos\n",
    "json_input  = \"tweets_espa√±oles_anotados_finales.json\"     # tu JSON sin IDs\n",
    "txt_input   = \"tweets_id.txt\"          # el archivo de log con \"Procesando tweet ID: <id>\"\n",
    "json_output = \"Tweets_espa√±oles_id.json\"     # salida con IDs asignados\n",
    "\n",
    "# 2) Extraer la lista de IDs del txt en el orden en que aparecen\n",
    "ids = []\n",
    "with open(txt_input, \"r\", encoding=\"utf-8\") as f:\n",
    "    for line in f:\n",
    "        m = re.search(r\"Procesando tweet ID:\\s*(\\d+)\", line)\n",
    "        if m:\n",
    "            ids.append(m.group(1))\n",
    "\n",
    "# 3) Cargar tu JSON original\n",
    "with open(json_input, \"r\", encoding=\"utf-8\") as f:\n",
    "    tweets = json.load(f)\n",
    "\n",
    "# 4) Verificar que concuerden\n",
    "if len(ids) != len(tweets):\n",
    "    raise ValueError(f\"Tengo {len(ids)} IDs en el txt pero {len(tweets)} tweets en el JSON.\")\n",
    "\n",
    "# 5) Asignar cada ID a su tweet correspondiente\n",
    "for idx, tweet in enumerate(tweets):\n",
    "    tweet[\"id\"] = ids[idx]\n",
    "\n",
    "# 6) Guardar el JSON resultante\n",
    "with open(json_output, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(tweets, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "print(f\"‚úÖ Asignados {len(ids)} IDs. Salvo en '{json_output}'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "78c78c57-b2b9-473b-a433-0820a7466a52",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ö†Ô∏è No se encontr√≥ usuario para: Daniel Senderos\n",
      "‚ö†Ô∏è No se encontr√≥ usuario para: Mar√≠a Jesus moro almaraz\n",
      "‚ö†Ô∏è No se encontr√≥ usuario para: V√≠ctor S√°nchezdel Real\n",
      "‚ö†Ô∏è No se encontr√≥ usuario para: Od√≥n Elorza\n",
      "‚ö†Ô∏è No se encontr√≥ usuario para: Joan Capdevila\n",
      "‚ö†Ô∏è No se encontr√≥ usuario para: Juan Cuatrecasas As√∫a\n",
      "‚ö†Ô∏è No se encontr√≥ usuario para: Federico. J. Contreras\n",
      "‚ö†Ô∏è No se encontr√≥ usuario para: Roc√≠o De Meer\n",
      "‚ö†Ô∏è No se encontr√≥ usuario para: Jose Luis Aceves\n",
      "‚ö†Ô∏è No se encontr√≥ usuario para: Mar√≠a Luz Mart√≠nez Seijo\n",
      "‚ö†Ô∏è No se encontr√≥ usuario para: Jos√© Ram√≠rez del R√≠o\n",
      "‚ö†Ô∏è No se encontr√≥ usuario para: Jaume Alonso-Cuevillas\n",
      "‚ö†Ô∏è No se encontr√≥ usuario para: Maria Dantas\n",
      "‚ö†Ô∏è No se encontr√≥ usuario para: Concepci√≥n Ca√±adell\n",
      "‚ö†Ô∏è No se encontr√≥ usuario para: L√≠dia Guinart Moreno\n",
      "‚ö†Ô∏è No se encontr√≥ usuario para: Bel√©n Fern√°ndez\n",
      "‚ö†Ô∏è No se encontr√≥ usuario para: Joan Baldov√≠\n",
      "‚ö†Ô∏è No se encontr√≥ usuario para: Pablo Iglesias\n",
      "‚ö†Ô∏è No se encontr√≥ usuario para: S√≤nia Guerra L√≥pez\n",
      "‚ö†Ô∏è No se encontr√≥ usuario para: Bego Nasarre\n",
      "‚ö†Ô∏è No se encontr√≥ usuario para: Isabel Franco\n",
      "‚ö†Ô∏è No se encontr√≥ usuario para: Eva Patricia Bueno\n",
      "\n",
      "‚úÖ JSON final guardado en: tweets_espa√±oles_completos2.json\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "import json\n",
    "import unicodedata\n",
    "\n",
    "# ‚Äî Rutas de entrada/salida ‚Äî\n",
    "TWEETS_JSON    = 'spain/Completado/tweets_espa√±oles_evaluados_completo.json'\n",
    "DETAILS_JSON   = 'spain/politicos_espa√±oles_con_edad.json'\n",
    "USERS_JSON     = 'spain/users_espa√±oles.json'\n",
    "OUTPUT_JSON    = 'tweets_espa√±oles_completos2.json'\n",
    "\n",
    "# ‚Äî Funci√≥n para normalizar texto ‚Äî\n",
    "def normalize(text):\n",
    "    text = text.lower().strip()\n",
    "    text = unicodedata.normalize('NFKD', text)\n",
    "    return ''.join(c for c in text if not unicodedata.combining(c))\n",
    "\n",
    "# ‚Äî Carga de datos ‚Äî\n",
    "with open(TWEETS_JSON, encoding='utf-8') as f:\n",
    "    all_tweets = json.load(f)\n",
    "\n",
    "with open(DETAILS_JSON, encoding='utf-8') as f:\n",
    "    politicos = json.load(f)\n",
    "\n",
    "with open(USERS_JSON, encoding='utf-8') as f:\n",
    "    user_info = json.load(f)\n",
    "\n",
    "# ‚Äî Mapeo r√°pido de ID ‚Üí tweet ‚Äî\n",
    "id_to_tweet = {str(tw['id']): tw for tw in all_tweets}\n",
    "\n",
    "# ‚Äî Mapeo de nombre normalizado ‚Üí @usuario ‚Äî\n",
    "name_to_user = {normalize(u['name']): u for u in user_info}\n",
    "\n",
    "# ‚Äî Construir resultado final ‚Äî\n",
    "final = {}\n",
    "for pol in politicos:\n",
    "    normname = normalize(pol['name'])\n",
    "    user_entry = name_to_user.get(normname)\n",
    "\n",
    "    if not user_entry:\n",
    "        print(f\"‚ö†Ô∏è No se encontr√≥ usuario para: {pol['name']}\")\n",
    "        continue\n",
    "\n",
    "    tweet_ids = user_entry.get(\"tweet_ids\", [])\n",
    "    tweet_objs = []\n",
    "    for tid in tweet_ids:\n",
    "        t = id_to_tweet.get(str(tid))\n",
    "        if t:\n",
    "            tweet_objs.append({\n",
    "                'id':         t.get('id'),\n",
    "                'text':       t.get('text'),\n",
    "                'valoration': t.get('valoration'),\n",
    "                'replies':    t.get('replies', [])\n",
    "            })\n",
    "        else:\n",
    "            print(f\"‚ùå Tweet ID {tid} no encontrado en dataset.\")\n",
    "\n",
    "    final[normname] = {\n",
    "        'name':   pol['name'],\n",
    "        'user':   user_entry.get('user'),\n",
    "        'age':    pol.get('age'),\n",
    "        'party':  pol.get('party'),\n",
    "        'gender': pol.get('gender'),\n",
    "        'tweets': tweet_objs\n",
    "    }\n",
    "\n",
    "# ‚Äî Guardar resultado ‚Äî\n",
    "output = list(final.values())\n",
    "with open(OUTPUT_JSON, 'w', encoding='utf-8') as f:\n",
    "    json.dump(output, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "print(f\"\\n‚úÖ JSON final guardado en: {OUTPUT_JSON}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1932d16d-30af-412e-bf0f-163118993e7c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Estad√≠sticas generales\n",
      "üë§ N√∫mero de usuarios:       1000\n",
      "üí¨ Total de tweets:          0\n",
      "üí≠ Total de respuestas:      0\n",
      "üìà Promedio respuestas/tweet:0.00\n",
      "\n",
      "‚ö†Ô∏è Usuarios sin tweets:\n",
      "  - Juan L√≥pez de Uralde\n",
      "@juralde\n",
      "¬∑\n",
      "Nov 7, 2021\n",
      "  - Gloria Elizo\n",
      "@GloriaElizo\n",
      "  - Guillermo Prudencio\n",
      "@guilleprudencio\n",
      "¬∑\n",
      "Feb 19, 2021\n",
      "  - Andr√©s Lorite\n",
      "@AndresLorite\n",
      "  - In√©s Saban√©s\n",
      "@isabanes\n",
      "  - Jos√© Alcaraz Martos\n",
      "@fjosealcaraz\n",
      "  - Marisa Saavedra\n",
      "@MarisaSaavedraM\n",
      "  - Daniel Senderos/\n",
      "@danielsenderos\n",
      "  - Jaume Asens\n",
      "@Jaumeasens\n",
      "  - Pilar Marcos\n",
      "@pilarmarcosd\n",
      "¬∑\n",
      "Sep 9, 2021\n",
      "  - Marta Mart√≠n Llaguno\n",
      "@martamartirio\n",
      "  - Marisa Saavedra\n",
      "@MarisaSaavedraM\n",
      "  - Marisa Saavedra\n",
      "@MarisaSaavedraM\n",
      "  - Error al extraer usuario de 1356204051105460227 tras 3 intentos.\n",
      "  - In√®s Gum√† Mitj√†\n",
      "@inheis\n",
      "¬∑\n",
      "Aug 28, 2021\n",
      "  - Diego Gago Bugar√≠n\n",
      "@DiegoGagoB\n",
      "  - Error al extraer usuario de 1444931213400199170 tras 3 intentos.\n",
      "  - Miriam Nogueras\n",
      "@miriamnoguerasM\n",
      "¬∑\n",
      "Sep 23, 2021\n",
      "  - Miguel Guti√©rrez\n",
      "@MGutierrezCs\n",
      "  - Rosa Romero\n",
      "@rosaromerocr\n",
      "  - Carla Toscano\n",
      "@eledhmel\n",
      "¬∑\n",
      "Feb 5, 2021\n",
      "  - Fco. J. Contreras\n",
      "@fjconpe\n",
      "¬∑\n",
      "Aug 28, 2021\n",
      "  - Castiel\n",
      "@Castiel_Perez\n",
      "¬∑\n",
      "Jun 18, 2021\n",
      "  - Rosa Romero\n",
      "@rosaromerocr\n",
      "  - Od√≥n Elorza Activista por la Democracia\n",
      "@odonelorza2011\n",
      "¬∑\n",
      "Nov 26, 2021\n",
      "  - Juan Luis Soto Buril\n",
      "@juanluissotoadd\n",
      "  - Pilar Cancela/\n",
      "@PiliCancela\n",
      "  - N√©stor Rego\n",
      "@NestorRego\n",
      "  - Pedro S√°nchez\n",
      "@sanchezcastejon\n",
      "  - Od√≥n Elorza Activista por la Democracia\n",
      "@odonelorza2011\n",
      "¬∑\n",
      "Jul 22, 2021\n",
      "  - Daniel Senderos/\n",
      "@danielsenderos\n",
      "  - Daniel Senderos/\n",
      "@danielsenderos\n",
      "  - Laura Borr√†s\n",
      "@LauraBorras\n",
      "  - Antonio Saor√≠n.#YoApoyoAlGobierno\n",
      "@marxiniano\n",
      "¬∑\n",
      "Dec 14, 2021\n",
      "  - H√©ctor G√≥mez\n",
      "@Hectorgomezh\n",
      "  - mjesus moro almaraz\n",
      "@MoroMjesus\n",
      "  - Junts per Catalunya\n",
      "@JuntsXCat\n",
      "¬∑\n",
      "Jan 26, 2021\n",
      "  - Ines Granollers\n",
      "@InesGranollers\n",
      "  - Ricardo Chamorro Delmo\n",
      "@rchamode\n",
      "  - Alberto Garz√≥n\n",
      "@agarzon\n",
      "  - Mario Garc√©s Sanagust√≠n\n",
      "@MarioGarcesSan\n",
      "  - Jose Antonio Rodr√≠guez Salas Ó®Ä\n",
      "@JoseantonioJun\n",
      "  - Carla Toscano\n",
      "@eledhmel\n",
      "¬∑\n",
      "Nov 14, 2021\n",
      "  - Juan L√≥pez de Uralde\n",
      "@juralde\n",
      "  - Macarena Olona\n",
      "@Macarena_Olona\n",
      "  - Patricia Rueda\n",
      "@_patricia_rueda\n",
      "  - Nieves Ulayar.\n",
      "@nulayar\n",
      "¬∑\n",
      "Mar 27, 2021\n",
      "  - Macarena Olona\n",
      "@Macarena_Olona\n",
      "  - Error al extraer usuario de 1353983962507575296 tras 3 intentos.\n",
      "  - Carmen Riolobos\n",
      "@CarmenRiolobos\n",
      "  - V√≠ctorS√°nchezdelReal\n",
      "@sanchezdelreal\n",
      "  - Daniel Senderos/\n",
      "@danielsenderos\n",
      "  - Eloy Su√°rez Lamata\n",
      "@eloysuarezl\n",
      "  - Od√≥n Elorza Activista por la Democracia\n",
      "@odonelorza2011\n",
      "  - Isabel\n",
      "@Belisa82754991\n",
      "¬∑\n",
      "Oct 24, 2021\n",
      "  - Rodrigo Jim√©nez Revuelta\n",
      "@rodrijr111\n",
      "  - Ana V√°zquez Blanco\n",
      "@anadebande\n",
      "  - Eloy Su√°rez Lamata\n",
      "@eloysuarezl\n",
      "  - Daniel Senderos/\n",
      "@danielsenderos\n",
      "  - Fuensanta Lima\n",
      "@fuensantalima\n",
      "  - Carla Toscano\n",
      "@eledhmel\n",
      "  - Jami Matamala Alsina\n",
      "@jami_matamala\n",
      "¬∑\n",
      "Apr 1, 2021\n",
      "  - Error al extraer usuario de 1453980082972803076 tras 3 intentos.\n",
      "  - Daniel Senderos/\n",
      "@danielsenderos\n",
      "  - Daniel Senderos/\n",
      "@danielsenderos\n",
      "  - Gen√≠s Boadella\n",
      "@GenisBoadella\n",
      "  - Daniel Senderos/\n",
      "@danielsenderos\n",
      "  - Jos√© Alcaraz Martos\n",
      "@fjosealcaraz\n",
      "  - Pilar Marcos\n",
      "@pilarmarcosd\n",
      "  - Meritxell Batet\n",
      "@meritxell_batet\n",
      "¬∑\n",
      "Jan 26, 2021\n",
      "  - V√≠ctorS√°nchezdelReal\n",
      "@sanchezdelreal\n",
      "  - Victor P√≠riz Maya\n",
      "@vicpiriz1975\n",
      "  - V√≠ctorS√°nchezdelReal\n",
      "@sanchezdelreal\n",
      "  - Error al extraer usuario de 1456244674264551427 tras 3 intentos.\n",
      "  - Carlos Fidalgo\n",
      "@CarlosFidalgoG\n",
      "¬∑\n",
      "Oct 3, 2021\n",
      "  - Joan Capdevila ŸÜ\n",
      "@capdevilajoan\n",
      "  - Fernando Varela\n",
      "@Fervabi\n",
      "¬∑\n",
      "May 11, 2021\n",
      "  - Daniel Senderos/\n",
      "@danielsenderos\n",
      "  - Jordi √âvole\n",
      "@jordievole\n",
      "¬∑\n",
      "Jan 17, 2021\n",
      "  - Pilar Marcos\n",
      "@pilarmarcosd\n",
      "  - Mario / „Éû„É™„Ç¶„Çπ\n",
      "@mario_gix\n",
      "¬∑\n",
      "Oct 18, 2021\n",
      "  - Juan Cuatrecasas As√∫a/\n",
      "@CuatrecasasJuan\n",
      "  - Juan Cuatrecasas As√∫a/\n",
      "@CuatrecasasJuan\n",
      "  - Pere Joan Pons Sampietro\n",
      "@perejoanpons\n",
      "  - Victor P√≠riz Maya\n",
      "@vicpiriz1975\n",
      "  - Jos√© Alcaraz Martos\n",
      "@fjosealcaraz\n",
      "  - Sabah ÿµÿ®ÿßÿ≠\n",
      "@Sabah_Yacoubi\n",
      "¬∑\n",
      "Apr 23, 2021\n",
      "  - Daniel Senderos/\n",
      "@danielsenderos\n",
      "  - Agust√≠n Almod√≥bar Barcel√≥\n",
      "@aalmodobar\n",
      "  - Carmen Riolobos\n",
      "@CarmenRiolobos\n",
      "  - Fco. J. Contreras\n",
      "@fjconpe\n",
      "  - Jes√∫s Cobos\n",
      "@j_cobos\n",
      "¬∑\n",
      "Apr 14, 2021\n",
      "  - Jos√© Alcaraz Martos\n",
      "@fjosealcaraz\n",
      "  - V√≠ctorS√°nchezdelReal\n",
      "@sanchezdelreal\n",
      "  - Martina Velarde\n",
      "@MartinaVelardeG\n",
      "¬∑\n",
      "Sep 27, 2021\n",
      "  - 100%Andaluza\n",
      "@CristinaCabezon\n",
      "¬∑\n",
      "Oct 17, 2021\n",
      "  - Pau Mar√≠-Klose\n",
      "@pmklose\n",
      "  - Ines Granollers\n",
      "@InesGranollers\n",
      "  - Mariona Illamola Daus√†\n",
      "@MarionaID\n",
      "  - Yolanda D√≠az\n",
      "@Yolanda_Diaz_\n",
      "  - Ricardo Chamorro Delmo\n",
      "@rchamode\n",
      "  - sol cruz guzman\n",
      "@solcruzguzman\n",
      "  - In√©s Arrimadas\n",
      "@InesArrimadas\n",
      "  - Error al extraer usuario de 1365950788460281856 tras 3 intentos.\n",
      "  - Daniel Senderos/\n",
      "@danielsenderos\n",
      "¬∑\n",
      "Aug 19, 2021\n",
      "  - Ione Belarra\n",
      "@ionebelarra\n",
      "  - Error al extraer usuario de 1475867310661513216 tras 3 intentos.\n",
      "  - Edurne Uriarte\n",
      "@EdurneUriarte\n",
      "  - Roc√≠o De Meer ŸÜ\n",
      "@MeerRocio\n",
      "  - Carla Toscano\n",
      "@eledhmel\n",
      "¬∑\n",
      "Feb 19, 2021\n",
      "  - Iv√°n Espinosa de los Monteros\n",
      "@ivanedlm\n",
      "  - Arnau Ram√≠rez\n",
      "@arnauramirez\n",
      "  - Emilio del Valle\n",
      "@edelvallerod\n",
      "  - Malena Nevado\n",
      "@malenanevado\n",
      "  - N√©stor Rego\n",
      "@NestorRego\n",
      "  - \n",
      "  - Pere Joan Pons Sampietro\n",
      "@perejoanpons\n",
      "¬∑\n",
      "Jun 15, 2021\n",
      "  - V√≠ctor Gonz√°lez\n",
      "@vicpiedra\n",
      "  - Ana Zurita\n",
      "@AnaZurita7\n",
      "  - Daniel Senderos/\n",
      "@danielsenderos\n",
      "  - Toni Lopez\n",
      "@tonilopez_Vox\n",
      "¬∑\n",
      "Sep 3, 2021\n",
      "  - Sergio Gutierrez\n",
      "@Sergio_GP\n",
      "¬∑\n",
      "Aug 10, 2021\n",
      "  - Georgina Trias\n",
      "@georginatrias10\n",
      "  - Pere Joan Pons Sampietro\n",
      "@perejoanpons\n",
      "  - Jose Luis Aceves/\n",
      "@JLAceves\n",
      "  - √ç√±igo Errej√≥n\n",
      "@ierrejon\n",
      "  - Daniel Senderos/\n",
      "@danielsenderos\n",
      "  - Fuensanta Lima\n",
      "@fuensantalima\n",
      "  - H√®ctor L√≥pez Bofill\n",
      "@lopezbofill\n",
      "¬∑\n",
      "Jul 25, 2021\n",
      "  - Rodrigo Jim√©nez Revuelta\n",
      "@rodrijr111\n",
      "  - ESPol√≠tica\n",
      "@ESPpolitica_TW\n",
      "¬∑\n",
      "Sep 23, 2021\n",
      "  - Xavier Eritja Ciur√≥\n",
      "@xavieritja\n",
      "  - Cristina Esteban Calonje\n",
      "@CrisCalonje\n",
      "  - Error al extraer usuario de 1359887073235329029 tras 3 intentos.\n",
      "  - Jos√© Alcaraz Martos\n",
      "@fjosealcaraz\n",
      "  - V√≠ctorS√°nchezdelReal\n",
      "@sanchezdelreal\n",
      "  - Error al extraer usuario de 1450563371259072519 tras 3 intentos.\n",
      "  - Carmen Riolobos\n",
      "@CarmenRiolobos\n",
      "  - Lola G√≥mez\n",
      "@lolagmnews\n",
      "¬∑\n",
      "Feb 9, 2021\n",
      "  - Mario Garc√©s Sanagust√≠n\n",
      "@MarioGarcesSan\n",
      "¬∑\n",
      "Aug 3, 2021\n",
      "  - Mireia Veh√≠\n",
      "@Mireia_veca\n",
      "  - Victor P√≠riz Maya\n",
      "@vicpiriz1975\n",
      "  - Merc√® Perea Conillas\n",
      "@MercePerea\n",
      "  - Maria Dantas (@mariadantas.bsky.social)\n",
      "@_Maria_Dantas_\n",
      "¬∑\n",
      "Feb 10, 2021\n",
      "  - Santiago Abascal\n",
      "@Santi_ABASCAL\n",
      "  - √Ångeles Marra \\\n",
      "@AngelesMarra\n",
      "  - NUET\n",
      "@NUET\n",
      "  - Juan de la Rosa\n",
      "@jdelarosa100\n",
      "¬∑\n",
      "Jul 19, 2021\n",
      "  - Daniel Senderos/\n",
      "@danielsenderos\n",
      "  - fran\n",
      "@flacambra1975\n",
      "¬∑\n",
      "Nov 4, 2021\n",
      "  - Beatriz Micaela Carrillo de los Reyes\n",
      "@BeaMCarrillo\n",
      "¬∑\n",
      "May 30, 2021\n",
      "  - Fco. J. Contreras\n",
      "@fjconpe\n",
      "  - Ana Zurita\n",
      "@AnaZurita7\n",
      "  - Jos√© Alcaraz Martos\n",
      "@fjosealcaraz\n",
      "  - Cayetana √Ålvarez de Toledo\n",
      "@cayetanaAT\n",
      "  - Error al extraer usuario de 1386642603182002176 tras 3 intentos.\n",
      "  - Merc√® Perea Conillas\n",
      "@MercePerea\n",
      "  - Martina Velarde\n",
      "@MartinaVelardeG\n",
      "¬∑\n",
      "Nov 1, 2021\n",
      "  - Edurne Uriarte\n",
      "@EdurneUriarte\n",
      "  - Jos√© Belmonte\n",
      "@JbsJos\n",
      "¬∑\n",
      "Feb 18, 2021\n",
      "  - M Luz Mart√≠nez Seijo\n",
      "@luzseijo\n",
      "  - Rub√©n Manso Olivar\n",
      "@rubenmansolivar\n",
      "  - Fco. J. Contreras\n",
      "@fjconpe\n",
      "  - N√©stor Rego\n",
      "@NestorRego\n",
      "  - #DefensaTurnoLibre\n",
      "@defturnolibre\n",
      "¬∑\n",
      "Nov 12, 2021\n",
      "  - Ana Zurita\n",
      "@AnaZurita7\n",
      "  - Fl√≤scul Llavallol i Bracons\n",
      "@Rampoina\n",
      "¬∑\n",
      "Jun 23, 2021\n",
      "  - Joan Margall Sastre\n",
      "@joanmargall\n",
      "  - Jos√© Ram√≠rez del R√≠o ŸÜ\n",
      "@joseramirezdel2\n",
      "  - Jon Inarritu\n",
      "@JonInarritu\n",
      "  - Error al extraer usuario de 1357070890807271428 tras 3 intentos.\n",
      "  - Martina Velarde\n",
      "@MartinaVelardeG\n",
      "  - Error al extraer usuario de 1419427790886248449 tras 3 intentos.\n",
      "  - Pedro Casares\n",
      "@pedro_casares\n",
      "  - Agust√≠n Almod√≥bar Barcel√≥\n",
      "@aalmodobar\n",
      "  - V√≠ctorS√°nchezdelReal\n",
      "@sanchezdelreal\n",
      "  - Santi Navarro Angl√≠\n",
      "@Sanagli\n",
      "¬∑\n",
      "Oct 5, 2021\n",
      "  - Roberto Mor√≠s\n",
      "@MorisSiero\n",
      "  - Pepe Ortiz Vejer\n",
      "@vejer_ortiz\n",
      "  - Error al extraer usuario de 1425414550258585601 tras 3 intentos.\n",
      "  - Agust√≠n Almod√≥bar Barcel√≥\n",
      "@aalmodobar\n",
      "  - MARIA CARLEX\n",
      "@MCarlex\n",
      "¬∑\n",
      "Mar 9, 2021\n",
      "  - Jaume Alonso-Cuevillas i Sayrol (JACS)\n",
      "@JACS_JaumeACS\n",
      "  - Daniel Senderos/\n",
      "@danielsenderos\n",
      "¬∑\n",
      "Dec 2, 2021\n",
      "  - Montse M√≠nguez\n",
      "@montseminguez\n",
      "  - Daniel Senderos/\n",
      "@danielsenderos\n",
      "  - Pilar Cancela/\n",
      "@PiliCancela\n",
      "¬∑\n",
      "Jan 10, 2021\n",
      "  - Meritxell Batet\n",
      "@meritxell_batet\n",
      "  - Agust√≠n Almod√≥bar Barcel√≥\n",
      "@aalmodobar\n",
      "  - √ç√±igo Errej√≥n\n",
      "@ierrejon\n",
      "  - Sergio √Ålvarez\n",
      "@SergioSariegu\n",
      "¬∑\n",
      "Oct 4, 2021\n",
      "  - Macarena Olona\n",
      "@Macarena_Olona\n",
      "  - Pedro S√°nchez\n",
      "@sanchezcastejon\n",
      "  - Jos√© Alcaraz Martos\n",
      "@fjosealcaraz\n",
      "  - Macarena Olona\n",
      "@Macarena_Olona\n",
      "  - Carmela Silva\n",
      "@carmelasilva\n",
      "¬∑\n",
      "Jul 14, 2021\n",
      "  - Cesar Ramos\n",
      "@CesarJRamos\n",
      "  - Ana Oramas\n",
      "@anioramas\n",
      "  - @LaLidieta\n",
      "@lalidieta\n",
      "¬∑\n",
      "Oct 19, 2021\n",
      "  - Ant√≥n G√≥mez-Reino Varela\n",
      "@AntonGomezReino\n",
      "  - Agust√≠n Almod√≥bar Barcel√≥\n",
      "@aalmodobar\n",
      "  - Ana Pastor Juli√°n\n",
      "@anapastorjulian\n",
      "  - Carmen Navarro Lacoba\n",
      "@CnLacoba\n",
      "  - Pau Mar√≠-Klose\n",
      "@pmklose\n",
      "¬∑\n",
      "Jan 28, 2021\n",
      "  - Daniel Senderos/\n",
      "@danielsenderos\n",
      "  - Ignacio L√≥pez Cano\n",
      "@nasholop\n",
      "  - Carme Garcia Suarez\n",
      "@carmegarciasu\n",
      "¬∑\n",
      "Oct 29, 2021\n",
      "  - Sigueme por Sevilla\n",
      "@AM322422\n",
      "¬∑\n",
      "Jun 6, 2021\n",
      "  - Macarena Olona\n",
      "@Macarena_Olona\n",
      "  - Fco. J. Contreras\n",
      "@fjconpe\n",
      "  - Gerardo Pisarello\n",
      "@G_Pisarello\n",
      "¬∑\n",
      "May 31, 2021\n",
      "  - Mazzinguerzetta\n",
      "@Mazzinguerzett1\n",
      "¬∑\n",
      "Feb 2, 2021\n",
      "  - Ione Belarra\n",
      "@ionebelarra\n",
      "  - Teodoro Garc√≠a Egea\n",
      "@TeoGarciaEgea\n",
      "  - Daniel Senderos/\n",
      "@danielsenderos\n",
      "  - Carla Toscano\n",
      "@eledhmel\n",
      "¬∑\n",
      "Jan 5, 2021\n",
      "  - Error al extraer usuario de 1349010882873991169 tras 3 intentos.\n",
      "  - Cayetana √Ålvarez de Toledo\n",
      "@cayetanaAT\n",
      "  - Marta Mart√≠n Llaguno\n",
      "@martamartirio\n",
      "  - Mariona Illamola Daus√†\n",
      "@MarionaID\n",
      "  - mjesus moro almaraz\n",
      "@MoroMjesus\n",
      "  - Daniel Senderos/\n",
      "@danielsenderos\n",
      "  - Arnau Ram√≠rez\n",
      "@arnauramirez\n",
      "  - Mar√≠a Mu√±oz\n",
      "@mariadelamiel\n",
      "  - Error al extraer usuario de 1374977300803022850 tras 3 intentos.\n",
      "  - Ignacio Garriga\n",
      "@Igarrigavaz\n",
      "  - V√≠ctorS√°nchezdelReal\n",
      "@sanchezdelreal\n",
      "  - Rub√©n Manso Olivar\n",
      "@rubenmansolivar\n",
      "  - Agust√≠n Almod√≥bar Barcel√≥\n",
      "@aalmodobar\n",
      "  - Santiago Abascal\n",
      "@Santi_ABASCAL\n",
      "¬∑\n",
      "Apr 8, 2021\n",
      "  - Maria Dantas (@mariadantas.bsky.social)\n",
      "@_Maria_Dantas_\n",
      "  - Pau Mar√≠-Klose\n",
      "@pmklose\n",
      "¬∑\n",
      "Jan 8, 2021\n",
      "  - Valentina Martinez\n",
      "@valentinam\n",
      "  - Pablo S√°ez\n",
      "@PabloSaezAM\n",
      "  - Rub√©n Manso Olivar\n",
      "@rubenmansolivar\n",
      "¬∑\n",
      "Oct 2, 2021\n",
      "  - Alberto Garz√≥n\n",
      "@agarzon\n",
      "¬∑\n",
      "Jan 8, 2021\n",
      "  - Concep Ca√±adell\n",
      "@conceptermens\n",
      "  - Rosa Romero\n",
      "@rosaromerocr\n",
      "  - Error al extraer usuario de 1423180009619996674 tras 3 intentos.\n",
      "  - Pablo S√°ez\n",
      "@PabloSaezAM\n",
      "  - Daniel Senderos/\n",
      "@danielsenderos\n",
      "  - Fernando Gonzalez de la Higuera Solis\n",
      "@Fernand43573512\n",
      "¬∑\n",
      "Dec 31, 2021\n",
      "  - Bea Fanjul\n",
      "@bea_fanjul\n",
      "  - Montse M√≠nguez\n",
      "@montseminguez\n",
      "  - Error al extraer usuario de 1461051135339470850 tras 3 intentos.\n",
      "  - V√≠ctorS√°nchezdelReal\n",
      "@sanchezdelreal\n",
      "  - Pepe Ortiz Vejer\n",
      "@vejer_ortiz\n",
      "  - Junts per Catalunya Congr√©s i Senat\n",
      "@JuntsxCatMadrid\n",
      "¬∑\n",
      "Mar 23, 2021\n",
      "  - JD\n",
      "@jes_dav_\n",
      "¬∑\n",
      "Mar 23, 2021\n",
      "  - Daniel Senderos/\n",
      "@danielsenderos\n",
      "  - Miquel Jerez\n",
      "@miqueljerez\n",
      "  - Rub√©n Manso Olivar\n",
      "@rubenmansolivar\n",
      "  - Marisa Saavedra\n",
      "@MarisaSaavedraM\n",
      "  - Maria Dantas (@mariadantas.bsky.social)\n",
      "@_Maria_Dantas_\n",
      "¬∑\n",
      "Mar 17, 2021\n",
      "  - Iv√°n Espinosa de los Monteros\n",
      "@ivanedlm\n",
      "  - V√≠ctor Gonz√°lez\n",
      "@vicpiedra\n",
      "  - Jos√© Ignacio Ech√°niz\n",
      "@JIEchaniz\n",
      "  - Omar Anguita P√©rez\n",
      "@AnguitaOmar\n",
      "  - Joan Duran i Ferrer\n",
      "@joanduranf\n",
      "¬∑\n",
      "Jul 6, 2021\n",
      "  - Omar Anguita P√©rez\n",
      "@AnguitaOmar\n",
      "  - Fco. J. Contreras\n",
      "@fjconpe\n",
      "  - Ana V√°zquez Blanco\n",
      "@anadebande\n",
      "  - Marina Trades\n",
      "@cat_nordic\n",
      "¬∑\n",
      "Feb 2, 2021\n",
      "  - Jorge Casas Neira\n",
      "@JorgeCasasNeira\n",
      "¬∑\n",
      "Sep 8, 2021\n",
      "  - Carmen Riolobos\n",
      "@CarmenRiolobos\n",
      "  - Daniel Senderos/\n",
      "@danielsenderos\n",
      "  - Andr√©s Lorite\n",
      "@AndresLorite\n",
      "  - V√≠ctorS√°nchezdelReal\n",
      "@sanchezdelreal\n",
      "¬∑\n",
      "Apr 4, 2021\n",
      "  - Omar Anguita P√©rez\n",
      "@AnguitaOmar\n",
      "  - Jos√© Alcaraz Martos\n",
      "@fjosealcaraz\n",
      "  - Malena Nevado\n",
      "@malenanevado\n",
      "¬∑\n",
      "Dec 11, 2021\n",
      "  - Mariona Illamola Daus√†\n",
      "@MarionaID\n",
      "  - Edurne Uriarte\n",
      "@EdurneUriarte\n",
      "  - Sof√≠a Hernanz Costa\n",
      "@Hernanzsofia\n",
      "  - Rub√©n Manso Olivar\n",
      "@rubenmansolivar\n",
      "¬∑\n",
      "Feb 14, 2021\n",
      "  - V√≠ctorS√°nchezdelReal\n",
      "@sanchezdelreal\n",
      "  - Error al extraer usuario de 1438563996962021376 tras 3 intentos.\n",
      "  - V√≠ctorS√°nchezdelReal\n",
      "@sanchezdelreal\n",
      "¬∑\n",
      "Sep 19, 2021\n",
      "  - Carmen Riolobos\n",
      "@CarmenRiolobos\n",
      "  - Magdalena Valerio\n",
      "@mvalerio_gu\n",
      "¬∑\n",
      "Dec 29, 2021\n",
      "  - L√≠dia Guinart Moreno/\n",
      "@lidiaguinart\n",
      "  - Andrea Fern√°ndez.\n",
      "@afernb\n",
      "¬∑\n",
      "Aug 14, 2021\n",
      "  - Roc√≠o De Meer ŸÜ\n",
      "@MeerRocio\n",
      "  - Marta Rosique i Saltor\n",
      "@MartaRosiq\n",
      "  - Jos√© Zaragoza\n",
      "@J_Zaragoza_\n",
      "  - Georgina Trias\n",
      "@georginatrias10\n",
      "  - Chopenawer\n",
      "@dchopenawer\n",
      "¬∑\n",
      "Feb 4, 2021\n",
      "  - Georgina Trias\n",
      "@georginatrias10\n",
      "¬∑\n",
      "Sep 8, 2021\n",
      "  - Can Pixa\n",
      "@CPIXA1\n",
      "¬∑\n",
      "Mar 11, 2021\n",
      "  - Daniel Senderos/\n",
      "@danielsenderos\n",
      "  - Error al extraer usuario de 1434612581004718083 tras 3 intentos.\n",
      "  - Maria Dantas (@mariadantas.bsky.social)\n",
      "@_Maria_Dantas_\n",
      "  - Alberto Herrero\n",
      "@herrerobono\n",
      "  - Rosa Romero\n",
      "@rosaromerocr\n",
      "  - Carmen Andr√©s A√±√≥n\n",
      "@carmenandres_\n",
      "  - Javier Benegas\n",
      "@BenegasJ\n",
      "¬∑\n",
      "Mar 29, 2021\n",
      "  - Pilar Cancela/\n",
      "@PiliCancela\n",
      "  - Fco. J. Contreras\n",
      "@fjconpe\n",
      "  - Daniel Senderos/\n",
      "@danielsenderos\n",
      "  - Jaume Asens\n",
      "@Jaumeasens\n",
      "  - Bel√©n Fern√°ndez/\n",
      "@BelenFCasero\n",
      "  - Oskar Matute\n",
      "@OskarMatute\n",
      "  - Arnau Ram√≠rez\n",
      "@arnauramirez\n",
      "  - Error al extraer usuario de 1444780438510358531 tras 3 intentos.\n",
      "  - Mario Garc√©s Sanagust√≠n\n",
      "@MarioGarcesSan\n",
      "  - Marisa Saavedra\n",
      "@MarisaSaavedraM\n",
      "  - Iv√°n Espinosa de los Monteros\n",
      "@ivanedlm\n",
      "  - Daniel Senderos/\n",
      "@danielsenderos\n",
      "  - Agust√≠n Almod√≥bar Barcel√≥\n",
      "@aalmodobar\n",
      "  - Pepe Ortiz Vejer\n",
      "@vejer_ortiz\n",
      "  - Jaume Asens\n",
      "@Jaumeasens\n",
      "  - Laura Borr√†s\n",
      "@LauraBorras\n",
      "  - Reyes Romero\n",
      "@rromerovilches\n",
      "¬∑\n",
      "Apr 21, 2021\n",
      "  - Marta Mart√≠n Llaguno\n",
      "@martamartirio\n",
      "  - In√©s Arrimadas\n",
      "@InesArrimadas\n",
      "  - Laura Borr√†s\n",
      "@LauraBorras\n",
      "  - ùêÜùêöùêõùê´ùê¢ùêûùê• ùêÑùê•ùê®ùê´ùê´ùê¢ùêöùê†ùêö\n",
      "@gabrielorriaga\n",
      "¬∑\n",
      "Jun 22, 2021\n",
      "  - Pilar Marcos\n",
      "@pilarmarcosd\n",
      "  - Error al extraer usuario de 1475937662490062849 tras 3 intentos.\n",
      "  - Sebastian Ledesma Ma\n",
      "@SebastianLede15\n",
      "  - Ricardo Chamorro Delmo\n",
      "@rchamode\n",
      "  - Ignacio Garriga\n",
      "@Igarrigavaz\n",
      "  - Emilio del Valle\n",
      "@edelvallerod\n",
      "  - Maria Dantas (@mariadantas.bsky.social)\n",
      "@_Maria_Dantas_\n",
      "¬∑\n",
      "Jul 7, 2021\n",
      "  - V√≠ctorS√°nchezdelReal\n",
      "@sanchezdelreal\n",
      "  - In√©s Arrimadas\n",
      "@InesArrimadas\n",
      "  - V√≠ctor Gonz√°lez\n",
      "@vicpiedra\n",
      "  - Daniel Senderos/\n",
      "@danielsenderos\n",
      "  - Pilar Marcos\n",
      "@pilarmarcosd\n",
      "  - V√≠ctorS√°nchezdelReal\n",
      "@sanchezdelreal\n",
      "¬∑\n",
      "Feb 19, 2021\n",
      "  - Nuria Varela\n",
      "@NuriaVarela\n",
      "¬∑\n",
      "Mar 24, 2021\n",
      "  - Daniel Senderos/\n",
      "@danielsenderos\n",
      "  - Od√≥n Elorza Activista por la Democracia\n",
      "@odonelorza2011\n",
      "¬∑\n",
      "Mar 28, 2021\n",
      "  - V√≠ctorS√°nchezdelReal\n",
      "@sanchezdelreal\n",
      "  - √Ångeles Marra \\\n",
      "@AngelesMarra\n",
      "  - √ç√±igo Errej√≥n\n",
      "@ierrejon\n",
      "  - Juanjo Aizcorbe Torra\n",
      "@JuanjoAizcorbe\n",
      "  - Error al extraer usuario de 1359959517681901580 tras 3 intentos.\n",
      "  - Error al extraer usuario de 1458767236748001289 tras 3 intentos.\n",
      "  - √ç√±igo Errej√≥n\n",
      "@ierrejon\n",
      "  - Joan Mena\n",
      "@joanmena\n",
      "¬∑\n",
      "Nov 23, 2021\n",
      "  - Merc√® Perea Conillas\n",
      "@MercePerea\n",
      "  - Pablo Casado Blanco\n",
      "@pablocasado_\n",
      "  - Albert Botran Pahissa\n",
      "@albertbotran\n",
      "  - Miriam Nogueras\n",
      "@miriamnoguerasM\n",
      "  - Yolanda D√≠az\n",
      "@Yolanda_Diaz_\n",
      "  - Cesar Ramos\n",
      "@CesarJRamos\n",
      "  - Roc√≠o De Meer ŸÜ\n",
      "@MeerRocio\n",
      "  - Pau Mar√≠-Klose\n",
      "@pmklose\n",
      "  - In√©s Saban√©s\n",
      "@isabanes\n",
      "  - Susana Sumelzo Jord√°n\n",
      "@SSumelzo\n",
      "  - Ant√≤nia Jover\n",
      "@Antonia_Jover_\n",
      "  - Error al extraer usuario de 1368934094546042882 tras 3 intentos.\n",
      "  - Daniel Senderos/\n",
      "@danielsenderos\n",
      "  - Malena Nevado\n",
      "@malenanevado\n",
      "¬∑\n",
      "Dec 21, 2021\n",
      "  - Edmundo Bal\n",
      "@BalEdmundo\n",
      "  - Mar√≠a Guijarro\n",
      "@Maritxu30\n",
      "¬∑\n",
      "Apr 13, 2021\n",
      "  - Mar√≠a Mu√±oz\n",
      "@mariadelamiel\n",
      "¬∑\n",
      "Oct 14, 2021\n",
      "  - Alicia Garc√≠a\n",
      "@AliciaGarcia_Av\n",
      "  - SETI I\n",
      "@rameneses1\n",
      "¬∑\n",
      "Aug 2, 2021\n",
      "  - ùóóùóòùó¶ùóñùó¢ùó°ùó¢ùóñùóúùóóùó¢ ùïè\n",
      "@J_V_Madrid\n",
      "¬∑\n",
      "Dec 20, 2021\n",
      "  - Martina Velarde\n",
      "@MartinaVelardeG\n",
      "  - Miguel √Å. Castell√≥n\n",
      "@mcastellonPP\n",
      "  - Joan Baldov√≠ ;)\n",
      "@joanbaldovi\n",
      "  - Susana Sumelzo Jord√°n\n",
      "@SSumelzo\n",
      "  - Ricardo Chamorro Delmo\n",
      "@rchamode\n",
      "  - Gabriel Rufi√°n\n",
      "@gabrielrufian\n",
      "  - Ana Pastor Juli√°n\n",
      "@anapastorjulian\n",
      "  - Carlos Garc√≠a Adanero\n",
      "@GarciaAdanero\n",
      "¬∑\n",
      "Feb 25, 2021\n",
      "  - Error al extraer usuario de 1468518558149795845 tras 3 intentos.\n",
      "  - Martina Velarde\n",
      "@MartinaVelardeG\n",
      "¬∑\n",
      "Sep 27, 2021\n",
      "  - Francisco J. Delgado\n",
      "@PadreFJD\n",
      "¬∑\n",
      "Apr 12, 2021\n",
      "  - Error al extraer usuario de 1475871667083694082 tras 3 intentos.\n",
      "  - √ç√±igo Errej√≥n\n",
      "@ierrejon\n",
      "  - Fernando Guti√©rrez D√≠az de Otazu\n",
      "@otazu35\n",
      "  - Txema Guijarro\n",
      "@TxemaGuijarro\n",
      "  - Jos√© Ram√≠rez del R√≠o ŸÜ\n",
      "@joseramirezdel2\n",
      "  - Emilio del Valle\n",
      "@edelvallerod\n",
      "  - Bel√©n Fern√°ndez/\n",
      "@BelenFCasero\n",
      "  - Macarena Olona\n",
      "@Macarena_Olona\n",
      "¬∑\n",
      "Dec 7, 2021\n",
      "  - √Ångeles Marra \\\n",
      "@AngelesMarra\n",
      "  - German Renau\n",
      "@germanrenau\n",
      "  - Daniel Senderos/\n",
      "@danielsenderos\n",
      "  - Alberto Garz√≥n\n",
      "@agarzon\n",
      "  - Agust√≠n Almod√≥bar Barcel√≥\n",
      "@aalmodobar\n",
      "  - Malena Nevado\n",
      "@malenanevado\n",
      "  - Juli Mart√≠nez Amor√≥s\n",
      "@eljuliet_bnv\n",
      "¬∑\n",
      "Nov 23, 2021\n",
      "  - Daniel Senderos/\n",
      "@danielsenderos\n",
      "  - Maria Dantas (@mariadantas.bsky.social)\n",
      "@_Maria_Dantas_\n",
      "  - Rodrigo Jim√©nez Revuelta\n",
      "@rodrijr111\n",
      "  - Ana V√°zquez Blanco\n",
      "@anadebande\n",
      "  - Jose Antonio Rodr√≠guez Salas Ó®Ä\n",
      "@JoseantonioJun\n",
      "¬∑\n",
      "Dec 25, 2021\n",
      "  - Marga Prohens\n",
      "@MargaProhens\n",
      "  - Daniel Senderos/\n",
      "@danielsenderos\n",
      "  - Juan Luis Steegmann\n",
      "@jlsteeg_doc\n",
      "¬∑\n",
      "Nov 9, 2021\n",
      "  - M¬™ Carmen Mart√≠nez\n",
      "@MCMartinezWine\n",
      "¬∑\n",
      "Nov 23, 2021\n",
      "  - Pilar Marcos\n",
      "@pilarmarcosd\n",
      "  - Ant√≥n G√≥mez-Reino Varela\n",
      "@AntonGomezReino\n",
      "  - V√≠ctorS√°nchezdelReal\n",
      "@sanchezdelreal\n",
      "¬∑\n",
      "Jan 29, 2021\n",
      "  - Mar√≠a Mu√±oz\n",
      "@mariadelamiel\n",
      "¬∑\n",
      "Jan 26, 2021\n",
      "  - Agust√≠n Almod√≥bar Barcel√≥\n",
      "@aalmodobar\n",
      "  - Albert Botran Pahissa\n",
      "@albertbotran\n",
      "  - Meritxell Batet\n",
      "@meritxell_batet\n",
      "  - V√≠ctor Gonz√°lez\n",
      "@vicpiedra\n",
      "  - Rafa Lomana\n",
      "@RafaLomana\n",
      "  - Luis Gestoso\n",
      "@LuisGestoso\n",
      "  - Eduardo Carazo\n",
      "@educarazo\n",
      "  - Error al extraer usuario de 1400488232580702208 tras 3 intentos.\n",
      "  - Error al extraer usuario de 1349462952915689473 tras 3 intentos.\n",
      "  - √ç√±igo Errej√≥n\n",
      "@ierrejon\n",
      "¬∑\n",
      "Jun 21, 2021\n",
      "  - Martina Velarde\n",
      "@MartinaVelardeG\n",
      "  - Martina Velarde\n",
      "@MartinaVelardeG\n",
      "  - Ricardo Chamorro Delmo\n",
      "@rchamode\n",
      "  - Pau Mar√≠-Klose\n",
      "@pmklose\n",
      "¬∑\n",
      "Sep 10, 2021\n",
      "  - Error al extraer usuario de 1375339582582104064 tras 3 intentos.\n",
      "  - Javier S√°enz del Castillo\n",
      "@javiersaenzdelc\n",
      "¬∑\n",
      "Aug 7, 2021\n",
      "  - Alberto Herrero\n",
      "@herrerobono\n",
      "  - antonio hurtado\n",
      "@AntonioHurtado\n",
      "  - Daniel Senderos/\n",
      "@danielsenderos\n",
      "  - Pedro Navarro\n",
      "@pedronavarrol\n",
      "  - Fuensanta Lima\n",
      "@fuensantalima\n",
      "  - interino en abuso\n",
      "@Trabucoman1\n",
      "¬∑\n",
      "Jan 10, 2021\n",
      "  - Jos√© Ram√≠rez del R√≠o ŸÜ\n",
      "@joseramirezdel2\n",
      "  - Error al extraer usuario de 1414323167863128064 tras 3 intentos.\n",
      "  - Pere Joan Pons Sampietro\n",
      "@perejoanpons\n",
      "  - V√≠ctorS√°nchezdelReal\n",
      "@sanchezdelreal\n",
      "¬∑\n",
      "Aug 25, 2021\n",
      "  - Teodoro Garc√≠a Egea\n",
      "@TeoGarciaEgea\n",
      "  - May Mari√±o\n",
      "@MAYANTOXO\n",
      "¬∑\n",
      "May 7, 2021\n",
      "  - V√≠ctor Gonz√°lez\n",
      "@vicpiedra\n",
      "  - Fco. J. Contreras\n",
      "@fjconpe\n",
      "¬∑\n",
      "Apr 30, 2021\n",
      "  - Laura Borr√†s\n",
      "@LauraBorras\n",
      "¬∑\n",
      "Oct 19, 2021\n",
      "  - Mar√≠a Guijarro\n",
      "@Maritxu30\n",
      "  - Jaume Alonso-Cuevillas i Sayrol (JACS)\n",
      "@JACS_JaumeACS\n",
      "  - √Ångeles Marra \\\n",
      "@AngelesMarra\n",
      "  - Macarena Olona\n",
      "@Macarena_Olona\n",
      "  - Teodoro Garc√≠a Egea\n",
      "@TeoGarciaEgea\n",
      "¬∑\n",
      "Apr 14, 2021\n",
      "  - Carlos Rojas Garc√≠a\n",
      "@CarlosRojas_PPA\n",
      "  - Roc√≠o De Meer ŸÜ\n",
      "@MeerRocio\n",
      "  - The Ugly\n",
      "@and_the_ugly\n",
      "¬∑\n",
      "Feb 6, 2021\n",
      "  - Juan L√≥pez de Uralde\n",
      "@juralde\n",
      "¬∑\n",
      "Nov 1, 2021\n",
      "  - Jos√© Ram√≠rez del R√≠o ŸÜ\n",
      "@joseramirezdel2\n",
      "  - V√≠ctorS√°nchezdelReal\n",
      "@sanchezdelreal\n",
      "¬∑\n",
      "Aug 15, 2021\n",
      "  - Silvia\n",
      "@silfg92\n",
      "¬∑\n",
      "Nov 11, 2021\n",
      "  - Teodoro Garc√≠a Egea\n",
      "@TeoGarciaEgea\n",
      "  - Joan Mena\n",
      "@joanmena\n",
      "  - Gloria Elizo\n",
      "@GloriaElizo\n",
      "  - Jos√© Alcaraz Martos\n",
      "@fjosealcaraz\n",
      "  - Pedro Casares\n",
      "@pedro_casares\n",
      "  - Rafa Mayoral\n",
      "@MayoralRafa\n",
      "  - In√©s Saban√©s\n",
      "@isabanes\n",
      "  - Victor P√≠riz Maya\n",
      "@vicpiriz1975\n",
      "  - V√≠ctorS√°nchezdelReal\n",
      "@sanchezdelreal\n",
      "  - Merc√® Perea Conillas\n",
      "@MercePerea\n",
      "  - carlos_dhe\n",
      "@carlos_dhe\n",
      "¬∑\n",
      "Oct 2, 2021\n",
      "  - Andr√©s Lorite\n",
      "@AndresLorite\n",
      "  - Marta Pastor\n",
      "@MartaPastor\n",
      "¬∑\n",
      "Feb 18, 2021\n",
      "  - Maria Dantas (@mariadantas.bsky.social)\n",
      "@_Maria_Dantas_\n",
      "  - jhonny\n",
      "@Jonytorrero\n",
      "¬∑\n",
      "Nov 14, 2021\n",
      "  - V√≠ctorS√°nchezdelReal\n",
      "@sanchezdelreal\n",
      "  - In√©s Arrimadas\n",
      "@InesArrimadas\n",
      "  - Victor P√≠riz Maya\n",
      "@vicpiriz1975\n",
      "  - Ricardo Chamorro Delmo\n",
      "@rchamode\n",
      "  - Miguel √Ångel Reinoso\n",
      "@mianrey\n",
      "¬∑\n",
      "Dec 23, 2021\n",
      "  - Ana Zurita\n",
      "@AnaZurita7\n",
      "  - Andr√©s Lorite\n",
      "@AndresLorite\n",
      "  - Daniel Senderos/\n",
      "@danielsenderos\n",
      "  - √ç√±igo Errej√≥n\n",
      "@ierrejon\n",
      "¬∑\n",
      "Sep 29, 2021\n",
      "  - Od√≥n Elorza Activista por la Democracia\n",
      "@odonelorza2011\n",
      "¬∑\n",
      "Feb 18, 2021\n",
      "  - Macarena Olona\n",
      "@Macarena_Olona\n",
      "¬∑\n",
      "Feb 7, 2021\n",
      "  - Juan Cuatrecasas As√∫a/\n",
      "@CuatrecasasJuan\n",
      "  - Maria Dantas (@mariadantas.bsky.social)\n",
      "@_Maria_Dantas_\n",
      "  - Maria Dantas (@mariadantas.bsky.social)\n",
      "@_Maria_Dantas_\n",
      "¬∑\n",
      "Mar 9, 2021\n",
      "  - V√≠ctorS√°nchezdelReal\n",
      "@sanchezdelreal\n",
      "  - Od√≥n Elorza Activista por la Democracia\n",
      "@odonelorza2011\n",
      "  - Maria Dantas (@mariadantas.bsky.social)\n",
      "@_Maria_Dantas_\n",
      "  - Daniel Senderos/\n",
      "@danielsenderos\n",
      "  - Rafael Simancas\n",
      "@SimancasRafael\n",
      "  - Meritxell Batet\n",
      "@meritxell_batet\n",
      "  - Pere Joan Pons Sampietro\n",
      "@perejoanpons\n",
      "  - Laura Berja Vega\n",
      "@lauraberja86\n",
      "¬∑\n",
      "Dec 6, 2021\n",
      "  - Montse Bassa i Coll\n",
      "@BassaMontse\n",
      "  - Daniel Senderos/\n",
      "@danielsenderos\n",
      "  - Jos√© √Ångel Alonso\n",
      "@JAngelVillalon\n",
      "  - Error al extraer usuario de 1451885387929038848 tras 3 intentos.\n",
      "  - Javi Merino\n",
      "@javier_merino\n",
      "  - Arnau Ram√≠rez\n",
      "@arnauramirez\n",
      "¬∑\n",
      "May 29, 2021\n",
      "  - Jos√© Alcaraz Martos\n",
      "@fjosealcaraz\n",
      "  - antonio hurtado\n",
      "@AntonioHurtado\n",
      "  - Marcel Vivet Regal√≥n\n",
      "@MarcelVR1\n",
      "¬∑\n",
      "Jul 14, 2021\n",
      "  - Error al extraer usuario de 1444961661555720194 tras 3 intentos.\n",
      "  - Fco. J. Contreras\n",
      "@fjconpe\n",
      "  - V√≠ctorS√°nchezdelReal\n",
      "@sanchezdelreal\n",
      "¬∑\n",
      "Feb 18, 2021\n",
      "  - Alberto Herrero\n",
      "@herrerobono\n",
      "  - Carmen Riolobos\n",
      "@CarmenRiolobos\n",
      "  - Pablo Iglesias {R}\n",
      "@PabloIglesias\n",
      "  - AnaOlmedo\n",
      "@DiQueN0\n",
      "¬∑\n",
      "Feb 6, 2021\n",
      "  - Juan Cuatrecasas As√∫a/\n",
      "@CuatrecasasJuan\n",
      "  - Emilio del Valle\n",
      "@edelvallerod\n",
      "  - Mercedes Iglesias\n",
      "@mercheiglesiasc\n",
      "¬∑\n",
      "Jan 2, 2021\n",
      "  - Rub√©n Manso Olivar\n",
      "@rubenmansolivar\n",
      "¬∑\n",
      "Sep 23, 2021\n",
      "  - Error al extraer usuario de 1412118353288826887 tras 3 intentos.\n",
      "  - Pablo Casado Blanco\n",
      "@pablocasado_\n",
      "  - Marisa Saavedra\n",
      "@MarisaSaavedraM\n",
      "  - Error al extraer usuario de 1383376710465294349 tras 3 intentos.\n",
      "  - Sof√≠a Casta√±√≥n\n",
      "@SofCastanon\n",
      "  - Cristina Esteban Calonje\n",
      "@CrisCalonje\n",
      "  - Merc√® Perea Conillas\n",
      "@MercePerea\n",
      "  - V√≠ctorS√°nchezdelReal\n",
      "@sanchezdelreal\n",
      "¬∑\n",
      "Oct 7, 2021\n",
      "  - Omar Anguita P√©rez\n",
      "@AnguitaOmar\n",
      "  - antonio hurtado\n",
      "@AntonioHurtado\n",
      "  - Marisa Saavedra\n",
      "@MarisaSaavedraM\n",
      "  - Juanjo Aizcorbe Torra\n",
      "@JuanjoAizcorbe\n",
      "  - Carlos Rojas Garc√≠a\n",
      "@CarlosRojas_PPA\n",
      "  - Pau Mar√≠-Klose\n",
      "@pmklose\n",
      "  - Roberto Uriarte\n",
      "@RoberUriarte\n",
      "¬∑\n",
      "Sep 26, 2021\n",
      "  - Daniel Senderos/\n",
      "@danielsenderos\n",
      "  - Error al extraer usuario de 1357451089872904192 tras 3 intentos.\n",
      "  - Error al extraer usuario de 1469761173105123338 tras 3 intentos.\n",
      "  - Macarena Olona\n",
      "@Macarena_Olona\n",
      "  - Daniel Senderos/\n",
      "@danielsenderos\n",
      "  - Emilio del Valle\n",
      "@edelvallerod\n",
      "  - Juan L√≥pez de Uralde\n",
      "@juralde\n",
      "  - Joan Baldov√≠ ;)\n",
      "@joanbaldovi\n",
      "  - Cesar Ramos\n",
      "@CesarJRamos\n",
      "  - Teresa Jim√©nez-Becerril\n",
      "@teresajbecerril\n",
      "  - Iv√°n Espinosa de los Monteros\n",
      "@ivanedlm\n",
      "¬∑\n",
      "Apr 19, 2021\n",
      "  - Pablo Lolaso\n",
      "@PabloLolaso\n",
      "¬∑\n",
      "Apr 29, 2021\n",
      "  - DAO Makrer\n",
      "@daomakrer\n",
      "¬∑\n",
      "Oct 6, 2021\n",
      "  - Santiago Abascal\n",
      "@Santi_ABASCAL\n",
      "¬∑\n",
      "Apr 24, 2021\n",
      "  - Daniel Senderos/\n",
      "@danielsenderos\n",
      "  - Od√≥n Elorza Activista por la Democracia\n",
      "@odonelorza2011\n",
      "¬∑\n",
      "May 6, 2021\n",
      "  - V√≠ctor Gonz√°lez\n",
      "@vicpiedra\n",
      "  - Pablo Casado Blanco\n",
      "@pablocasado_\n",
      "  - Martina Velarde\n",
      "@MartinaVelardeG\n",
      "¬∑\n",
      "Apr 29, 2021\n",
      "  - Juan Cuatrecasas As√∫a/\n",
      "@CuatrecasasJuan\n",
      "¬∑\n",
      "Dec 31, 2021\n",
      "  - Pablo Iglesias {R}\n",
      "@PabloIglesias\n",
      "  - Pilar Marcos\n",
      "@pilarmarcosd\n",
      "  - Pilar Marcos\n",
      "@pilarmarcosd\n",
      "  - Sof√≠a Casta√±√≥n\n",
      "@SofCastanon\n",
      "  - Error al extraer usuario de 1357977951053221889 tras 3 intentos.\n",
      "  - Nieves Ulayar.\n",
      "@nulayar\n",
      "¬∑\n",
      "Mar 10, 2021\n",
      "  - Daniel Senderos/\n",
      "@danielsenderos\n",
      "  - Sara Gim√©nez\n",
      "@SaraGimnez\n",
      "  - Jos√© Alcaraz Martos\n",
      "@fjosealcaraz\n",
      "  - ~Gret~\n",
      "@GRET79\n",
      "¬∑\n",
      "Nov 28, 2021\n",
      "  - Pedro Navarro\n",
      "@pedronavarrol\n",
      "  - Rodrigo Jim√©nez Revuelta\n",
      "@rodrijr111\n",
      "  - Fco. J. Contreras\n",
      "@fjconpe\n",
      "  - Fuensanta Lima\n",
      "@fuensantalima\n",
      "  - Iv√°n Espinosa de los Monteros\n",
      "@ivanedlm\n",
      "  - √ç√±igo Errej√≥n\n",
      "@ierrejon\n",
      "¬∑\n",
      "Nov 30, 2021\n",
      "  - Reyes Romero\n",
      "@rromerovilches\n",
      "  - Vicente Tirado\n",
      "@vicentetiradopp\n",
      "  - Fco. J. Contreras\n",
      "@fjconpe\n",
      "¬∑\n",
      "Feb 20, 2021\n",
      "  - Arnau Ram√≠rez\n",
      "@arnauramirez\n",
      "  - √Ångeles Marra \\\n",
      "@AngelesMarra\n",
      "  - Xavier Eritja Ciur√≥\n",
      "@xavieritja\n",
      "  - Juan L√≥pez de Uralde\n",
      "@juralde\n",
      "  - Pau Mar√≠-Klose\n",
      "@pmklose\n",
      "  - PI\n",
      "@PInterinos\n",
      "¬∑\n",
      "Sep 25, 2021\n",
      "  - Victor P√≠riz Maya\n",
      "@vicpiriz1975\n",
      "  - Error al extraer usuario de 1434445152324620292 tras 3 intentos.\n",
      "  - Marta Mart√≠n Llaguno\n",
      "@martamartirio\n",
      "  - Eul√†lia Gili\n",
      "@eulaliagili\n",
      "¬∑\n",
      "Sep 27, 2021\n",
      "  - Georgina Trias\n",
      "@georginatrias10\n",
      "  - Daniel Senderos/\n",
      "@danielsenderos\n",
      "  - Daniel Senderos/\n",
      "@danielsenderos\n",
      "  - Javier Ortega Smith\n",
      "@Ortega_Smith\n",
      "  - V√≠ctorS√°nchezdelReal\n",
      "@sanchezdelreal\n",
      "¬∑\n",
      "Feb 22, 2021\n",
      "  - Error al extraer usuario de 1425793148299714564 tras 3 intentos.\n",
      "  - Fco. J. Contreras\n",
      "@fjconpe\n",
      "  - Laura Borr√†s\n",
      "@LauraBorras\n",
      "¬∑\n",
      "Feb 23, 2021\n",
      "  - Mariona Illamola Daus√†\n",
      "@MarionaID\n",
      "  - N√©stor Rego\n",
      "@NestorRego\n",
      "  - Jos√© Ram√≠rez del R√≠o ŸÜ\n",
      "@joseramirezdel2\n",
      "  - Eduardo Carazo\n",
      "@educarazo\n",
      "  - Marisa Saavedra\n",
      "@MarisaSaavedraM\n",
      "  - Error al extraer usuario de 1416734573644374018 tras 3 intentos.\n",
      "  - Beatriz Micaela Carrillo de los Reyes\n",
      "@BeaMCarrillo\n",
      "  - S√≤nia Guerra L√≥pez/\n",
      "@SonyaGuerraLpz\n",
      "  - LuJo\n",
      "@LuJo548014lu\n",
      "¬∑\n",
      "Sep 1, 2021\n",
      "  - Maria Dantas (@mariadantas.bsky.social)\n",
      "@_Maria_Dantas_\n",
      "  - Marta Mart√≠n Llaguno\n",
      "@martamartirio\n",
      "  - Laura Berja Vega\n",
      "@lauraberja86\n",
      "  - Pau Mar√≠-Klose\n",
      "@pmklose\n",
      "¬∑\n",
      "Nov 19, 2021\n",
      "  - Pau Mar√≠-Klose\n",
      "@pmklose\n",
      "  - Carmen Riolobos\n",
      "@CarmenRiolobos\n",
      "  - Agust√≠n Almod√≥bar Barcel√≥\n",
      "@aalmodobar\n",
      "  - Javier Alfonso Cend√≥n\n",
      "@alfonsocendon\n",
      "  - Fco. J. Contreras\n",
      "@fjconpe\n",
      "¬∑\n",
      "Nov 21, 2021\n",
      "  - Mar Garc√≠a Puig\n",
      "@margpuig\n",
      "  - Mariona Illamola Daus√†\n",
      "@MarionaID\n",
      "  - Lepetitpep\n",
      "@lepetitpep\n",
      "¬∑\n",
      "Mar 10, 2021\n",
      "  - V√≠ctorS√°nchezdelReal\n",
      "@sanchezdelreal\n",
      "¬∑\n",
      "May 23, 2021\n",
      "  - Reyes Romero\n",
      "@rromerovilches\n",
      "¬∑\n",
      "Jan 14, 2021\n",
      "  - Luc√≠a Mu√±oz Dalda\n",
      "@luciadalda\n",
      "  - Patricia Rueda\n",
      "@_patricia_rueda\n",
      "  - Ignacio L√≥pez Cano\n",
      "@nasholop\n",
      "¬∑\n",
      "Mar 20, 2021\n",
      "  - Macarena Olona\n",
      "@Macarena_Olona\n",
      "  - Rodrigo Jim√©nez Revuelta\n",
      "@rodrijr111\n",
      "  - Mariona Illamola Daus√†\n",
      "@MarionaID\n",
      "  - Daniel Senderos/\n",
      "@danielsenderos\n",
      "  - Eloy Su√°rez Lamata\n",
      "@eloysuarezl\n",
      "  - Reyes Romero\n",
      "@rromerovilches\n",
      "  - SVQCapital Econ√≥mica\n",
      "@SVQCapEcon\n",
      "¬∑\n",
      "Nov 2, 2021\n",
      "  - Jos√© Alcaraz Martos\n",
      "@fjosealcaraz\n",
      "¬∑\n",
      "Apr 24, 2021\n",
      "  - Jordi Salvador Duch\n",
      "@jsalvadorduch\n",
      "¬∑\n",
      "Mar 23, 2021\n",
      "  - Jaume Alonso-Cuevillas i Sayrol (JACS)\n",
      "@JACS_JaumeACS\n",
      "  - Pablo Montesinos\n",
      "@montesinospablo\n",
      "  - Sergio Gutierrez\n",
      "@Sergio_GP\n",
      "  - Error al extraer usuario de 1366350122574094337 tras 3 intentos.\n",
      "  - Error al extraer usuario de 1362528893517918209 tras 3 intentos.\n",
      "  - V√≠ctorS√°nchezdelReal\n",
      "@sanchezdelreal\n",
      "  - Reza por un pol√≠tico\n",
      "@rezaporpolitico\n",
      "¬∑\n",
      "Mar 21, 2021\n",
      "  - V√≠ctorS√°nchezdelReal\n",
      "@sanchezdelreal\n",
      "¬∑\n",
      "Aug 25, 2021\n",
      "  - √ç√±igo Errej√≥n\n",
      "@ierrejon\n",
      "  - Pablo Casado Blanco\n",
      "@pablocasado_\n",
      "  - Miriam Nogueras\n",
      "@miriamnoguerasM\n",
      "¬∑\n",
      "Apr 23, 2021\n",
      "  - Jos√© Alcaraz Martos\n",
      "@fjosealcaraz\n",
      "¬∑\n",
      "Jun 17, 2021\n",
      "  - Fco. J. Contreras\n",
      "@fjconpe\n",
      "¬∑\n",
      "May 3, 2021\n",
      "  - Jaume Alonso-Cuevillas i Sayrol (JACS)\n",
      "@JACS_JaumeACS\n",
      "  - Gerardo Pisarello\n",
      "@G_Pisarello\n",
      "  - V√≠ctor Gonz√°lez\n",
      "@vicpiedra\n",
      "  - Valentina Martinez\n",
      "@valentinam\n",
      "  - Kolontai\n",
      "@kolontai1959\n",
      "¬∑\n",
      "Apr 3, 2021\n",
      "  - Arnau Ram√≠rez\n",
      "@arnauramirez\n",
      "  - V√≠ctorS√°nchezdelReal\n",
      "@sanchezdelreal\n",
      "  - *XPep Ca√≠n \"Facta Non Verba\"\n",
      "@ClonPepe\n",
      "¬∑\n",
      "Jun 4, 2021\n",
      "  - S√≤nia Guerra L√≥pez/\n",
      "@SonyaGuerraLpz\n",
      "  - √Ångel Mart√≠nez\n",
      "@angelmartinezx2\n",
      "¬∑\n",
      "Apr 10, 2021\n",
      "  - V√≠ctorS√°nchezdelReal\n",
      "@sanchezdelreal\n",
      "¬∑\n",
      "Feb 13, 2021\n",
      "  - Mar√≠a Mu√±oz\n",
      "@mariadelamiel\n",
      "¬∑\n",
      "Feb 18, 2021\n",
      "  - Marta Mart√≠n Llaguno\n",
      "@martamartirio\n",
      "  - Ione Belarra\n",
      "@ionebelarra\n",
      "  - Daniel Senderos/\n",
      "@danielsenderos\n",
      "  - V√≠ctorS√°nchezdelReal\n",
      "@sanchezdelreal\n",
      "  - Ana Pastor Juli√°n\n",
      "@anapastorjulian\n",
      "  - Reza por un pol√≠tico\n",
      "@rezaporpolitico\n",
      "¬∑\n",
      "Aug 16, 2021\n",
      "  - Ana Pastor Juli√°n\n",
      "@anapastorjulian\n",
      "  - Daniel Senderos/\n",
      "@danielsenderos\n",
      "  - Jordi Salvador Duch\n",
      "@jsalvadorduch\n",
      "  - Roc√≠o De Meer ŸÜ\n",
      "@MeerRocio\n",
      "  - Meritxell Batet\n",
      "@meritxell_batet\n",
      "  - Ricardo Chamorro Delmo\n",
      "@rchamode\n",
      "  - Pilar Cancela/\n",
      "@PiliCancela\n",
      "¬∑\n",
      "Sep 6, 2021\n",
      "  - Diego Gago Bugar√≠n\n",
      "@DiegoGagoB\n",
      "  - Maria Dantas (@mariadantas.bsky.social)\n",
      "@_Maria_Dantas_\n",
      "  - mjesus moro almaraz\n",
      "@MoroMjesus\n",
      "  - Merc√® Perea Conillas\n",
      "@MercePerea\n",
      "  - Daniel Senderos/\n",
      "@danielsenderos\n",
      "  - Beatriz Micaela Carrillo de los Reyes\n",
      "@BeaMCarrillo\n",
      "  - Laura Borr√†s\n",
      "@LauraBorras\n",
      "¬∑\n",
      "Feb 25, 2021\n",
      "  - V√≠ctorS√°nchezdelReal\n",
      "@sanchezdelreal\n",
      "  - Mireia Veh√≠\n",
      "@Mireia_veca\n",
      "  - Ant√≥n G√≥mez-Reino Varela\n",
      "@AntonGomezReino\n",
      "  - Pablo Casado Blanco\n",
      "@pablocasado_\n",
      "  - Od√≥n Elorza Activista por la Democracia\n",
      "@odonelorza2011\n",
      "¬∑\n",
      "Aug 19, 2021\n",
      "  - Marian_Casares /\n",
      "@mariancasaresh\n",
      "¬∑\n",
      "May 19, 2021\n",
      "  - Error al extraer usuario de 1411033490011869189 tras 3 intentos.\n",
      "  - Error al extraer usuario de 1422867705481371648 tras 3 intentos.\n",
      "  - Malena Nevado\n",
      "@malenanevado\n",
      "  - Juan Cuatrecasas As√∫a/\n",
      "@CuatrecasasJuan\n",
      "  - Arseni\n",
      "@ArseniLaSeu\n",
      "¬∑\n",
      "Apr 24, 2021\n",
      "  - Juan Luis Soto Buril\n",
      "@juanluissotoadd\n",
      "  - Jose Ram√≥n Ortega\n",
      "@jr0rtega\n",
      "¬∑\n",
      "Apr 10, 2021\n",
      "  - Laura Borr√†s\n",
      "@LauraBorras\n",
      "¬∑\n",
      "May 8, 2021\n",
      "  - Sonia Sierra\n",
      "@SoniaSierra02\n",
      "¬∑\n",
      "May 3, 2021\n",
      "  - Jaime de Olano\n",
      "@jaimedeolano\n",
      "  - Daniel Senderos/\n",
      "@danielsenderos\n",
      "  - Jaume Alonso-Cuevillas i Sayrol (JACS)\n",
      "@JACS_JaumeACS\n",
      "  - Rafa Lomana\n",
      "@RafaLomana\n",
      "  - √Ålex Dorado N√°jera\n",
      "@DoradoAlex\n",
      "¬∑\n",
      "Feb 23, 2021\n",
      "  - Error al extraer usuario de 1396437893531508737 tras 3 intentos.\n",
      "  - Mireia Veh√≠\n",
      "@Mireia_veca\n",
      "  - Teresa Jim√©nez-Becerril\n",
      "@teresajbecerril\n",
      "  - Carolina Espa√±a\n",
      "@CarolinaEspanaR\n",
      "  - Pablo Hispan\n",
      "@HispanPablo\n",
      "  - Laura Borr√†s\n",
      "@LauraBorras\n",
      "¬∑\n",
      "Jun 21, 2021\n",
      "  - Pablo Iglesias {R}\n",
      "@PabloIglesias\n",
      "  - √ç√±igo Errej√≥n\n",
      "@ierrejon\n",
      "  - Bego Nasarre /\n",
      "@Begonasarre\n",
      "  - Roser Maestro\n",
      "@Roser_Maestro\n",
      "  - Laura Borr√†s\n",
      "@LauraBorras\n",
      "  - Fco. J. Contreras\n",
      "@fjconpe\n",
      "¬∑\n",
      "Oct 20, 2021\n",
      "  - V√≠ctorS√°nchezdelReal\n",
      "@sanchezdelreal\n",
      "  - √Ångeles Marra \\\n",
      "@AngelesMarra\n",
      "  - Mar√≠a Ramallo\n",
      "@MariaRamallov\n",
      "  - Daniel Senderos/\n",
      "@danielsenderos\n",
      "  - Pilar Cancela/\n",
      "@PiliCancela\n",
      "¬∑\n",
      "May 11, 2021\n",
      "  - Francisco Longo\n",
      "@francisco_longo\n",
      "¬∑\n",
      "Feb 6, 2021\n",
      "  - Daniel Senderos/\n",
      "@danielsenderos\n",
      "  - Error al extraer usuario de 1404494869792448524 tras 3 intentos.\n",
      "  - Patricia Rueda\n",
      "@_patricia_rueda\n",
      "  - Yolanda D√≠az\n",
      "@Yolanda_Diaz_\n",
      "  - Error al extraer usuario de 1387466653634547716 tras 3 intentos.\n",
      "  - √ç√±igo Errej√≥n\n",
      "@ierrejon\n",
      "¬∑\n",
      "Feb 15, 2021\n",
      "  - Malena Nevado\n",
      "@malenanevado\n",
      "  - Error al extraer usuario de 1413200007847628801 tras 3 intentos.\n",
      "  - Alicia Garc√≠a\n",
      "@AliciaGarcia_Av\n",
      "  - M Luz Mart√≠nez Seijo\n",
      "@luzseijo\n",
      "  - Emilio del Valle\n",
      "@edelvallerod\n",
      "  - Luc√≠a Mu√±oz Dalda\n",
      "@luciadalda\n",
      "  - Pere Joan Pons Sampietro\n",
      "@perejoanpons\n",
      "¬∑\n",
      "Nov 29, 2021\n",
      "  - Daniel Senderos/\n",
      "@danielsenderos\n",
      "  - Gloria Elizo\n",
      "@GloriaElizo\n",
      "  - Elvira Ram√≥n\n",
      "@ElviraRamon\n",
      "  - Mario Garc√©s Sanagust√≠n\n",
      "@MarioGarcesSan\n",
      "  - Omar Anguita P√©rez\n",
      "@AnguitaOmar\n",
      "  - Helena Caballero\n",
      "@Caballerohelena\n",
      "  - Carol\n",
      "@ElislotedeCaro\n",
      "¬∑\n",
      "Jun 15, 2021\n",
      "  - Despistaku\n",
      "@Despistaku\n",
      "¬∑\n",
      "Nov 10, 2021\n",
      "  - Montse M√≠nguez\n",
      "@montseminguez\n",
      "  - V√≠ctor Gonz√°lez\n",
      "@vicpiedra\n",
      "  - Macarena Olona\n",
      "@Macarena_Olona\n",
      "  - Pau Mar√≠-Klose\n",
      "@pmklose\n",
      "  - Beatriz Mu√±oz Gonz√°lez\n",
      "@45Beatriz\n",
      "¬∑\n",
      "May 26, 2021\n",
      "  - Ant√≤nia Jover\n",
      "@Antonia_Jover_\n",
      "  - Matea Fesa\n",
      "@Mateafesa\n",
      "¬∑\n",
      "Apr 19, 2021\n",
      "  - Susana Sumelzo Jord√°n\n",
      "@SSumelzo\n",
      "  - Santos Cerd√°n Le√≥n\n",
      "@santicl\n",
      "  - Ana Pastor Juli√°n\n",
      "@anapastorjulian\n",
      "  - Jaume Alonso-Cuevillas i Sayrol (JACS)\n",
      "@JACS_JaumeACS\n",
      "  - Rodrigo Jim√©nez Revuelta\n",
      "@rodrijr111\n",
      "  - Bea Fanjul\n",
      "@bea_fanjul\n",
      "  - Omar Anguita P√©rez\n",
      "@AnguitaOmar\n",
      "  - Daniel Senderos/\n",
      "@danielsenderos\n",
      "  - Javi Merino\n",
      "@javier_merino\n",
      "  - √ç√±igo Errej√≥n\n",
      "@ierrejon\n",
      "¬∑\n",
      "Aug 13, 2021\n",
      "  - In√©s Saban√©s\n",
      "@isabanes\n",
      "  - Maria Dantas (@mariadantas.bsky.social)\n",
      "@_Maria_Dantas_\n",
      "¬∑\n",
      "Feb 17, 2021\n",
      "  - Error al extraer usuario de 1415370753474760705 tras 3 intentos.\n",
      "  - Luis Gestoso\n",
      "@LuisGestoso\n",
      "  - Error al extraer usuario de 1415625819444162563 tras 3 intentos.\n",
      "  - Fco. J. Contreras\n",
      "@fjconpe\n",
      "  - Maria Dantas (@mariadantas.bsky.social)\n",
      "@_Maria_Dantas_\n",
      "  - Txema Guijarro\n",
      "@TxemaGuijarro\n",
      "  - N√©stor Rego\n",
      "@NestorRego\n",
      "  - Juan L√≥pez de Uralde\n",
      "@juralde\n",
      "  - Gen√≠s Boadella\n",
      "@GenisBoadella\n",
      "  - Concep Ca√±adell\n",
      "@conceptermens\n",
      "  - Fco. J. Contreras\n",
      "@fjconpe\n",
      "  - In√©s Saban√©s\n",
      "@isabanes\n",
      "  - antonio hurtado\n",
      "@AntonioHurtado\n",
      "  - In√©s Saban√©s\n",
      "@isabanes\n",
      "¬∑\n",
      "Jan 1, 2021\n",
      "  - Ines Granollers\n",
      "@InesGranollers\n",
      "  - Joan Capdevila ŸÜ\n",
      "@capdevilajoan\n",
      "  - Cristina Esteban Calonje\n",
      "@CrisCalonje\n",
      "  - Od√≥n Elorza Activista por la Democracia\n",
      "@odonelorza2011\n",
      "¬∑\n",
      "Nov 20, 2021\n",
      "  - Agust√≠n Almod√≥bar Barcel√≥\n",
      "@aalmodobar\n",
      "  - Merc√® Perea Conillas\n",
      "@MercePerea\n",
      "  - Daniel Senderos/\n",
      "@danielsenderos\n",
      "  - Luis Gestoso\n",
      "@LuisGestoso\n",
      "  - Presidenta Laura Borr√†s\n",
      "@mhp_LauraBorras\n",
      "¬∑\n",
      "Nov 2, 2021\n",
      "  - Jos√© Alcaraz Martos\n",
      "@fjosealcaraz\n",
      "  - Fco. J. Contreras\n",
      "@fjconpe\n",
      "  - Maria Dantas (@mariadantas.bsky.social)\n",
      "@_Maria_Dantas_\n",
      "¬∑\n",
      "Dec 10, 2021\n",
      "  - Jaume Asens\n",
      "@Jaumeasens\n",
      "  - Marta Mart√≠n Llaguno\n",
      "@martamartirio\n",
      "  - Carla Toscano\n",
      "@eledhmel\n",
      "¬∑\n",
      "Aug 16, 2021\n",
      "  - Alberto Rodr√≠guez\n",
      "@Alber_Canarias\n",
      "¬∑\n",
      "Apr 10, 2021\n",
      "  - Od√≥n Elorza Activista por la Democracia\n",
      "@odonelorza2011\n",
      "  - VOX Sevilla\n",
      "@VOXSevilla_\n",
      "¬∑\n",
      "Feb 24, 2021\n",
      "  - Ana V√°zquez Blanco\n",
      "@anadebande\n",
      "  - Pilar Marcos\n",
      "@pilarmarcosd\n",
      "  - Maria Dantas (@mariadantas.bsky.social)\n",
      "@_Maria_Dantas_\n",
      "  - Mireia Veh√≠\n",
      "@Mireia_veca\n",
      "  - Marga Prohens\n",
      "@MargaProhens\n",
      "  - Ana Pastor Juli√°n\n",
      "@anapastorjulian\n",
      "  - Error al extraer usuario de 1411059798062338049 tras 3 intentos.\n",
      "  - Pau Mar√≠-Klose\n",
      "@pmklose\n",
      "¬∑\n",
      "Mar 20, 2021\n",
      "  - In√©s Arrimadas\n",
      "@InesArrimadas\n",
      "  - Carla Toscano\n",
      "@eledhmel\n",
      "  - \n",
      "  - S√≤nia Guerra L√≥pez/\n",
      "@SonyaGuerraLpz\n",
      "  - X\n",
      "@brain__teaser\n",
      "¬∑\n",
      "Jul 5, 2021\n",
      "  - Error al extraer usuario de 1445458943312994309 tras 3 intentos.\n",
      "  - aitor\n",
      "@aitoribar18\n",
      "¬∑\n",
      "Nov 17, 2021\n",
      "  - Ana V√°zquez Blanco\n",
      "@anadebande\n",
      "  - Daniel Senderos/\n",
      "@danielsenderos\n",
      "  - antonio hurtado\n",
      "@AntonioHurtado\n",
      "  - V√≠ctorS√°nchezdelReal\n",
      "@sanchezdelreal\n",
      "¬∑\n",
      "Jan 2, 2021\n",
      "  - Daniel Senderos/\n",
      "@danielsenderos\n",
      "  - Error al extraer usuario de 1440008163231739909 tras 3 intentos.\n",
      "  - Pedro Navarro\n",
      "@pedronavarrol\n",
      "  - Daniel Senderos/\n",
      "@danielsenderos\n",
      "  - Marcos de Quinto\n",
      "@MarcosdeQuinto\n",
      "¬∑\n",
      "Mar 29, 2021\n",
      "  - Pablo Cambronero\n",
      "@PabloCamPiq\n",
      "¬∑\n",
      "Feb 4, 2021\n",
      "  - Pedro Casares\n",
      "@pedro_casares\n",
      "  - Error al extraer usuario de 1434627749696638980 tras 3 intentos.\n",
      "  - Error al extraer usuario de 1433014611578691584 tras 3 intentos.\n",
      "  - Gloria Elizo\n",
      "@GloriaElizo\n",
      "  - Macarena Olona\n",
      "@Macarena_Olona\n",
      "  - Carla Toscano\n",
      "@eledhmel\n",
      "  - Marta Mart√≠n Llaguno\n",
      "@martamartirio\n",
      "  - LA GACETA\n",
      "@gaceta_es\n",
      "¬∑\n",
      "Jan 31, 2021\n",
      "  - Pedro Casares\n",
      "@pedro_casares\n",
      "  - Reyes Romero\n",
      "@rromerovilches\n",
      "  - Cesar Ramos\n",
      "@CesarJRamos\n",
      "  - V√≠ctorS√°nchezdelReal\n",
      "@sanchezdelreal\n",
      "¬∑\n",
      "Aug 26, 2021\n",
      "  - Pablo Iglesias {R}\n",
      "@PabloIglesias\n",
      "  - Emilio del Valle\n",
      "@edelvallerod\n",
      "  - Mertxe Aizpurua\n",
      "@MertxeAizpurua\n",
      "  - Victor P√≠riz Maya\n",
      "@vicpiriz1975\n",
      "  - Barbijaputa\n",
      "@Barbijaputa\n",
      "¬∑\n",
      "Mar 17, 2021\n",
      "  - Maria Dantas (@mariadantas.bsky.social)\n",
      "@_Maria_Dantas_\n",
      "  - Emilio del Valle\n",
      "@edelvallerod\n",
      "  - Daniel Senderos/\n",
      "@danielsenderos\n",
      "  - Meritxell Batet\n",
      "@meritxell_batet\n",
      "  - Pilar Marcos\n",
      "@pilarmarcosd\n",
      "¬∑\n",
      "Jul 14, 2021\n",
      "  - Error al extraer usuario de 1430827446354522113 tras 3 intentos.\n",
      "  - V√≠ctorS√°nchezdelReal\n",
      "@sanchezdelreal\n",
      "  - Jes√∫s G. CONDE\n",
      "@JGCdelCastillo\n",
      "¬∑\n",
      "Dec 3, 2021\n",
      "  - Joan Baldov√≠ ;)\n",
      "@joanbaldovi\n",
      "  - Ana V√°zquez Blanco\n",
      "@anadebande\n",
      "  - Jon Inarritu\n",
      "@JonInarritu\n",
      "  - Alberto Garz√≥n\n",
      "@agarzon\n",
      "  - Jose Luis Aceves/\n",
      "@JLAceves\n",
      "  - Victor P√≠riz Maya\n",
      "@vicpiriz1975\n",
      "¬∑\n",
      "Nov 7, 2021\n",
      "  - Laura Borr√†s\n",
      "@LauraBorras\n",
      "¬∑\n",
      "Nov 6, 2021\n",
      "  - Pedro S√°nchez\n",
      "@sanchezcastejon\n",
      "¬∑\n",
      "Sep 9, 2021\n",
      "  - Sof√≠a Casta√±√≥n\n",
      "@SofCastanon\n",
      "  - Error al extraer usuario de 1388425145258332163 tras 3 intentos.\n",
      "  - Santos Cerd√°n Le√≥n\n",
      "@santicl\n",
      "  - Juan L√≥pez de Uralde\n",
      "@juralde\n",
      "  - Aitor Arranz Sanz\n",
      "@sanz_arranz\n",
      "¬∑\n",
      "Sep 6, 2021\n",
      "  - Luc√≠a Mu√±oz Dalda\n",
      "@luciadalda\n",
      "  - Laura Borr√†s\n",
      "@LauraBorras\n",
      "  - Alberto Garz√≥n\n",
      "@agarzon\n",
      "  - Isabel Franco €û\n",
      "@Isabel_Franco_\n",
      "  - NUET\n",
      "@NUET\n",
      "  - Pablo Casado Blanco\n",
      "@pablocasado_\n",
      "  - Ana Pastor Juli√°n\n",
      "@anapastorjulian\n",
      "  - Alfonso R G√≥mez Celis\n",
      "@gomezdcelis\n",
      "  - Daniel Senderos/\n",
      "@danielsenderos\n",
      "  - Pau Mar√≠-Klose\n",
      "@pmklose\n",
      "¬∑\n",
      "Oct 22, 2021\n",
      "  - Tom√†s Bordoy\n",
      "@tomasbordoy\n",
      "¬∑\n",
      "Mar 14, 2021\n",
      "  - Daniel Senderos/\n",
      "@danielsenderos\n",
      "  - Marta Mart√≠n Llaguno\n",
      "@martamartirio\n",
      "  - sol cruz guzman\n",
      "@solcruzguzman\n",
      "  - Error al extraer usuario de 1453038792978411522 tras 3 intentos.\n",
      "  - Rub√©n Esteban P√©rez\n",
      "@Ruben_ICOG\n",
      "¬∑\n",
      "Jun 17, 2021\n",
      "  - Iv√°n Espinosa de los Monteros\n",
      "@ivanedlm\n",
      "  - Irene Varela\n",
      "@irenevarela6\n",
      "¬∑\n",
      "Apr 7, 2021\n",
      "  - Error al extraer usuario de 1430228603862650884 tras 3 intentos.\n",
      "  - El Cin√©fago Gerardo MAGRO\n",
      "@ElCinefago\n",
      "¬∑\n",
      "Jan 8, 2021\n",
      "  - Error al extraer usuario de 1430219593964994566 tras 3 intentos.\n",
      "  - PSOE Congreso\n",
      "@gpscongreso\n",
      "¬∑\n",
      "Jun 13, 2021\n",
      "  - Mireia Borr√°s\n",
      "@_mireiaborras\n",
      "  - In√©s Arrimadas\n",
      "@InesArrimadas\n",
      "  - Ignacio L√≥pez Cano\n",
      "@nasholop\n",
      "  - Malena Nevado\n",
      "@malenanevado\n",
      "  - Amparo Rubiales\n",
      "@AmparoRubiales\n",
      "¬∑\n",
      "Mar 1, 2021\n",
      "  - Tu abandono me puede MATAR\n",
      "@tu_abandono\n",
      "¬∑\n",
      "Feb 7, 2021\n",
      "  - V√≠ctorS√°nchezdelReal\n",
      "@sanchezdelreal\n",
      "¬∑\n",
      "Aug 20, 2021\n",
      "  - Sof√≠a Casta√±√≥n\n",
      "@SofCastanon\n",
      "  - Jos√© Ram√≠rez del R√≠o ŸÜ\n",
      "@joseramirezdel2\n",
      "  - Javi Merino\n",
      "@javier_merino\n",
      "  - Emilio del Valle\n",
      "@edelvallerod\n",
      "¬∑\n",
      "Nov 1, 2021\n",
      "  - sol cruz guzman\n",
      "@solcruzguzman\n",
      "  - Daniel Senderos/\n",
      "@danielsenderos\n",
      "  - Pablo Casado Blanco\n",
      "@pablocasado_\n",
      "  - Victor P√≠riz Maya\n",
      "@vicpiriz1975\n",
      "  - Error al extraer usuario de 1430571133372452867 tras 3 intentos.\n",
      "  - Pablo Casado Blanco\n",
      "@pablocasado_\n",
      "  - Martina Velarde\n",
      "@MartinaVelardeG\n",
      "  - Carlota Merch√°n\n",
      "@CarlotaMerchn\n",
      "¬∑\n",
      "Nov 14, 2021\n",
      "  - Pablo Stefanoni\n",
      "@PabloAStefanoni\n",
      "¬∑\n",
      "Apr 23, 2021\n",
      "  - Jos√© Alcaraz Martos\n",
      "@fjosealcaraz\n",
      "  - Mckenzie\n",
      "@manessacr\n",
      "¬∑\n",
      "Feb 19, 2021\n",
      "  - L√≠dia Guinart Moreno/\n",
      "@lidiaguinart\n",
      "  - Gloria Elizo\n",
      "@GloriaElizo\n",
      "  - Teodoro Garc√≠a Egea\n",
      "@TeoGarciaEgea\n",
      "  - Od√≥n Elorza Activista por la Democracia\n",
      "@odonelorza2011\n",
      "¬∑\n",
      "Jul 13, 2021\n",
      "  - Daniel Senderos/\n",
      "@danielsenderos\n",
      "  - Mario Garc√©s Sanagust√≠n\n",
      "@MarioGarcesSan\n",
      "  - Pepe Ortiz Vejer\n",
      "@vejer_ortiz\n",
      "  - Macarena Montesinos de Miguel\n",
      "@MackMontesinos\n",
      "  - Victor P√≠riz Maya\n",
      "@vicpiriz1975\n",
      "  - Cristina Esteban Calonje\n",
      "@CrisCalonje\n",
      "  - Cesar Ramos\n",
      "@CesarJRamos\n",
      "¬∑\n",
      "Mar 10, 2021\n",
      "  - Ricardo Chamorro Delmo\n",
      "@rchamode\n",
      "¬∑\n",
      "Mar 8, 2021\n",
      "  - Fco. J. Contreras\n",
      "@fjconpe\n",
      "¬∑\n",
      "Jan 8, 2021\n",
      "  - Ricardo Chamorro Delmo\n",
      "@rchamode\n",
      "  - Malena Nevado\n",
      "@malenanevado\n",
      "¬∑\n",
      "Nov 17, 2021\n",
      "  - Cristina Esteban Calonje\n",
      "@CrisCalonje\n",
      "¬∑\n",
      "Jan 2, 2021\n",
      "  - Sergio Sayas\n",
      "@sergiosayas\n",
      "  - Daniel Senderos/\n",
      "@danielsenderos\n",
      "  - Santiago Abascal\n",
      "@Santi_ABASCAL\n",
      "  - Mar√≠a Mu√±oz\n",
      "@mariadelamiel\n",
      "  - Agust√≠n Almod√≥bar Barcel√≥\n",
      "@aalmodobar\n",
      "  - Daniel Senderos/\n",
      "@danielsenderos\n",
      "  - antonio hurtado\n",
      "@AntonioHurtado\n",
      "  - Laura Borr√†s\n",
      "@LauraBorras\n",
      "¬∑\n",
      "Nov 14, 2021\n",
      "  - Fco. J. Contreras\n",
      "@fjconpe\n",
      "  - Pau Mar√≠-Klose\n",
      "@pmklose\n",
      "  - V√≠ctorS√°nchezdelReal\n",
      "@sanchezdelreal\n",
      "¬∑\n",
      "Aug 29, 2021\n",
      "  - Cesar Ramos\n",
      "@CesarJRamos\n",
      "  - P. Juan Manuel G√≥ngora\n",
      "@patergongora\n",
      "¬∑\n",
      "Jan 22, 2021\n",
      "  - Marisol S√°nchez J√≥dar\n",
      "@msolsj\n",
      "  - Merc√® Perea Conillas\n",
      "@MercePerea\n",
      "  - Daniel Senderos/\n",
      "@danielsenderos\n",
      "  - Aina Vidal S√°ez\n",
      "@AinaVS\n",
      "  - Teresa Jim√©nez-Becerril\n",
      "@teresajbecerril\n",
      "  - Juan L√≥pez de Uralde\n",
      "@juralde\n",
      "  - Jos√© Ignacio Ech√°niz\n",
      "@JIEchaniz\n",
      "  - Error al extraer usuario de 1348013526183522308 tras 3 intentos.\n",
      "  - Vicente Tirado\n",
      "@vicentetiradopp\n",
      "  - In√©s Saban√©s\n",
      "@isabanes\n",
      "  - Maria Dantas (@mariadantas.bsky.social)\n",
      "@_Maria_Dantas_\n",
      "¬∑\n",
      "Mar 25, 2021\n",
      "  - V√≠ctorS√°nchezdelReal\n",
      "@sanchezdelreal\n",
      "  - Iv√°n Espinosa de los Monteros\n",
      "@ivanedlm\n",
      "  - Rosa Romero\n",
      "@rosaromerocr\n",
      "  - Reyes Romero\n",
      "@rromerovilches\n",
      "  - Fco. J. Contreras\n",
      "@fjconpe\n",
      "  - Daniel Senderos/\n",
      "@danielsenderos\n",
      "¬∑\n",
      "Aug 19, 2021\n",
      "  - Javier S√°nchez Serna\n",
      "@J_Sanchez_Serna\n",
      "  - Laura Borr√†s\n",
      "@LauraBorras\n",
      "  - Error al extraer usuario de 1371179416152379394 tras 3 intentos.\n",
      "  - Pablo Calvo Liste\n",
      "@pcalvoliste\n",
      "  - V√≠ctorS√°nchezdelReal\n",
      "@sanchezdelreal\n",
      "  - Teodoro Garc√≠a Egea\n",
      "@TeoGarciaEgea\n",
      "  - Error al extraer usuario de 1465763703220019202 tras 3 intentos.\n",
      "  - Montserrat Caupena\n",
      "@Montcau\n",
      "¬∑\n",
      "Dec 3, 2021\n",
      "  - Error al extraer usuario de 1363590627800330240 tras 3 intentos.\n",
      "  - V√≠ctorS√°nchezdelReal\n",
      "@sanchezdelreal\n",
      "¬∑\n",
      "Mar 27, 2021\n",
      "  - Toni Aira\n",
      "@toniaira\n",
      "¬∑\n",
      "Feb 19, 2021\n",
      "  - Pedro Casares\n",
      "@pedro_casares\n",
      "  - Joan Mena\n",
      "@joanmena\n",
      "  - Gloria Elizo\n",
      "@GloriaElizo\n",
      "  - V√≠ctorS√°nchezdelReal\n",
      "@sanchezdelreal\n",
      "¬∑\n",
      "Sep 18, 2021\n",
      "  - Miriam Nogueras\n",
      "@miriamnoguerasM\n",
      "  - Daniel Senderos/\n",
      "@danielsenderos\n",
      "  - Mariona Illamola Daus√†\n",
      "@MarionaID\n",
      "  - Juan L√≥pez de Uralde\n",
      "@juralde\n",
      "  - Juan Cuatrecasas As√∫a/\n",
      "@CuatrecasasJuan\n",
      "  - Ana V√°zquez Blanco\n",
      "@anadebande\n",
      "  - Bel√©n Fern√°ndez/\n",
      "@BelenFCasero\n",
      "  - Maria Dantas (@mariadantas.bsky.social)\n",
      "@_Maria_Dantas_\n",
      "  - VOX Catalu√±a\n",
      "@VOX_Cataluna\n",
      "¬∑\n",
      "Mar 12, 2021\n",
      "  - Alberto Garz√≥n\n",
      "@agarzon\n",
      "  - Rosa Romero\n",
      "@rosaromerocr\n",
      "  - Daniel Senderos/\n",
      "@danielsenderos\n",
      "  - Laura Borr√†s\n",
      "@LauraBorras\n",
      "¬∑\n",
      "May 26, 2021\n",
      "  - H√©ctor G√≥mez\n",
      "@Hectorgomezh\n",
      "  - Omar Anguita P√©rez\n",
      "@AnguitaOmar\n",
      "  - Pilar Rahola\n",
      "@RaholaOficial\n",
      "¬∑\n",
      "Jun 10, 2021\n",
      "  - VilaWeb\n",
      "@VilaWeb\n",
      "¬∑\n",
      "Mar 26, 2021\n",
      "  - Od√≥n Elorza Activista por la Democracia\n",
      "@odonelorza2011\n",
      "  - Daniel Senderos/\n",
      "@danielsenderos\n",
      "  - Alfonso R G√≥mez Celis\n",
      "@gomezdcelis\n",
      "  - Gabriel Rufi√°n\n",
      "@gabrielrufian\n",
      "  - Cuca Gamarra\n",
      "@cucagamarra\n",
      "  - Maria Dantas (@mariadantas.bsky.social)\n",
      "@_Maria_Dantas_\n",
      "  - Meritxell Batet\n",
      "@meritxell_batet\n",
      "¬∑\n",
      "Nov 26, 2021\n",
      "  - Jose Luis Aceves/\n",
      "@JLAceves\n",
      "  - Juanjo Aizcorbe Torra\n",
      "@JuanjoAizcorbe\n",
      "  - √ç√±igo Errej√≥n\n",
      "@ierrejon\n",
      "  - √Åfrica Moreno\n",
      "@AfricaMoreno\n",
      "¬∑\n",
      "Aug 28, 2021\n",
      "  - Daniel Senderos/\n",
      "@danielsenderos\n",
      "  - Andrea Fern√°ndez.\n",
      "@afernb\n",
      "¬∑\n",
      "Mar 8, 2021\n",
      "  - M Luz Mart√≠nez Seijo\n",
      "@luzseijo\n",
      "  - Macarena Olona\n",
      "@Macarena_Olona\n",
      "  - Macarena Olona\n",
      "@Macarena_Olona\n",
      "  - Fco. J. Contreras\n",
      "@fjconpe\n",
      "  - Emilio del Valle\n",
      "@edelvallerod\n",
      "  - Gabriel Rufi√°n\n",
      "@gabrielrufian\n",
      "  - Eneko Andueza\n",
      "@enekoandueza\n",
      "¬∑\n",
      "Oct 31, 2021\n",
      "  - Error al extraer usuario de 1448923922351656962 tras 3 intentos.\n",
      "  - Od√≥n Elorza Activista por la Democracia\n",
      "@odonelorza2011\n",
      "¬∑\n",
      "Dec 22, 2021\n",
      "  - Daniel Senderos/\n",
      "@danielsenderos\n",
      "  - Daniel Senderos/\n",
      "@danielsenderos\n",
      "  - Malena Nevado\n",
      "@malenanevado\n",
      "  - Ines Granollers\n",
      "@InesGranollers\n",
      "  - Daniel Senderos/\n",
      "@danielsenderos\n",
      "  - Error al extraer usuario de 1423604369623326723 tras 3 intentos.\n",
      "  - Isidro M. Oblanca\n",
      "@imoblanca\n",
      "  - Fuensanta Lima\n",
      "@fuensantalima\n",
      "  - Leire D√≠ez\n",
      "@leirediezpas\n",
      "¬∑\n",
      "Mar 31, 2021\n",
      "  - Joan Margall Sastre\n",
      "@joanmargall\n",
      "  - Ana Zurita\n",
      "@AnaZurita7\n",
      "  - Error al extraer usuario de 1454109910241849350 tras 3 intentos.\n",
      "  - Laura Borr√†s\n",
      "@LauraBorras\n",
      "  - Jose Ram√≥n Ortega\n",
      "@jr0rtega\n",
      "¬∑\n",
      "Aug 21, 2021\n",
      "  - Eva Patricia Bueno/\n",
      "@evapatriciab\n",
      "  - V√≠ctorS√°nchezdelReal\n",
      "@sanchezdelreal\n",
      "¬∑\n",
      "May 4, 2021\n",
      "  - Luis Faci\n",
      "@lfaci\n",
      "¬∑\n",
      "Dec 5, 2021\n",
      "  - Carmen Riolobos\n",
      "@CarmenRiolobos\n",
      "  - Aina Vidal S√°ez\n",
      "@AinaVS\n",
      "¬∑\n",
      "Feb 4, 2021\n",
      "  - Reyes Romero\n",
      "@rromerovilches\n",
      "  - Pilar Cancela/\n",
      "@PiliCancela\n",
      "  - JPB\n",
      "@PouBoada\n",
      "¬∑\n",
      "May 13, 2021\n",
      "  - √ç√±igo Errej√≥n\n",
      "@ierrejon\n",
      "¬∑\n",
      "Dec 14, 2021\n",
      "  - Daniel Senderos/\n",
      "@danielsenderos\n",
      "  - Carlos Rojas Garc√≠a\n",
      "@CarlosRojas_PPA\n",
      "  - Luc√≠a Mu√±oz Dalda\n",
      "@luciadalda\n",
      "  - Pilar Cancela/\n",
      "@PiliCancela\n",
      "¬∑\n",
      "Apr 10, 2021\n",
      "  - Daniel Senderos/\n",
      "@danielsenderos\n",
      "  - Daniel Senderos/\n",
      "@danielsenderos\n",
      "  - Reyes Romero\n",
      "@rromerovilches\n",
      "  - Pablo Calvo Liste\n",
      "@pcalvoliste\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Ruta al archivo generado previamente\n",
    "INPUT_JSON = 'spain/Completado/tweets_espa√±oles_evaluados_completo.json'\n",
    "\n",
    "with open(INPUT_JSON, encoding='utf-8') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "num_users = len(data)\n",
    "total_tweets = 0\n",
    "total_replies = 0\n",
    "users_sin_tweets = []\n",
    "\n",
    "for entry in data:\n",
    "    tweets = entry.get('tweets', [])\n",
    "    total_tweets += len(tweets)\n",
    "\n",
    "    if not tweets:\n",
    "        users_sin_tweets.append(entry['user'])\n",
    "\n",
    "    for tweet in tweets:\n",
    "        replies = tweet.get('replies', [])\n",
    "        total_replies += len(replies)\n",
    "\n",
    "# C√°lculo de media de replies por tweet\n",
    "avg_replies = total_replies / total_tweets if total_tweets > 0 else 0\n",
    "\n",
    "# Resultados\n",
    "print(\"üìä Estad√≠sticas generales\")\n",
    "print(f\"üë§ N√∫mero de usuarios:       {num_users}\")\n",
    "print(f\"üí¨ Total de tweets:          {total_tweets}\")\n",
    "print(f\"üí≠ Total de respuestas:      {total_replies}\")\n",
    "print(f\"üìà Promedio respuestas/tweet:{avg_replies:.2f}\")\n",
    "\n",
    "# Usuarios sin tweets\n",
    "if users_sin_tweets:\n",
    "    print(\"\\n‚ö†Ô∏è Usuarios sin tweets:\")\n",
    "    for name in users_sin_tweets:\n",
    "        print(f\"  - {name}\")\n",
    "else:\n",
    "    print(\"\\n‚úÖ Todos los usuarios tienen al menos un tweet.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "461d8295-951b-48fc-9aec-7dd9eecadd87",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'tweets_espa√±oles_evaluados_completo.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[30]\u001b[39m\u001b[32m, line 19\u001b[39m\n\u001b[32m     16\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(POLITICOS_PATH, \u001b[33m\"\u001b[39m\u001b[33mr\u001b[39m\u001b[33m\"\u001b[39m, encoding=\u001b[33m\"\u001b[39m\u001b[33mutf-8\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[32m     17\u001b[39m     politicos = json.load(f)\n\u001b[32m---> \u001b[39m\u001b[32m19\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mTWEETS_PATH\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mr\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mutf-8\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[32m     20\u001b[39m     tweets_data = json.load(f)\n\u001b[32m     22\u001b[39m \u001b[38;5;66;03m# ‚Äî Agrupar tweets por @usuario ‚Äî\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/tljh/user/lib/python3.12/site-packages/IPython/core/interactiveshell.py:325\u001b[39m, in \u001b[36m_modified_open\u001b[39m\u001b[34m(file, *args, **kwargs)\u001b[39m\n\u001b[32m    318\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[32m0\u001b[39m, \u001b[32m1\u001b[39m, \u001b[32m2\u001b[39m}:\n\u001b[32m    319\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    320\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mIPython won\u001b[39m\u001b[33m'\u001b[39m\u001b[33mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m by default \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    321\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    322\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33myou can use builtins\u001b[39m\u001b[33m'\u001b[39m\u001b[33m open.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    323\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m325\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: 'tweets_espa√±oles_evaluados_completo.json'"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import unicodedata\n",
    "\n",
    "# ‚Äî Rutas de entrada y salida ‚Äî\n",
    "POLITICOS_PATH = \"spain/politicos_espa√±oles_con_edad.json\"\n",
    "TWEETS_PATH = \"tweets_espa√±oles_evaluados_completo.json\"\n",
    "OUTPUT_PATH = \"politicos_con_tweets_completos.json\"\n",
    "\n",
    "# ‚Äî Funci√≥n de normalizaci√≥n ‚Äî\n",
    "def normalize(text):\n",
    "    text = text.lower().strip()\n",
    "    text = unicodedata.normalize(\"NFKD\", text)\n",
    "    return ''.join(c for c in text if not unicodedata.combining(c))\n",
    "\n",
    "# ‚Äî Cargar archivos ‚Äî\n",
    "with open(POLITICOS_PATH, \"r\", encoding=\"utf-8\") as f:\n",
    "    politicos = json.load(f)\n",
    "\n",
    "with open(TWEETS_PATH, \"r\", encoding=\"utf-8\") as f:\n",
    "    tweets_data = json.load(f)\n",
    "\n",
    "# ‚Äî Agrupar tweets por @usuario ‚Äî\n",
    "def construir_tweet(tweet):\n",
    "    return {\n",
    "        \"id\": tweet.get(\"id\"),\n",
    "        \"text\": tweet.get(\"tweet\"),\n",
    "        \"valoration\": tweet.get(\"analysis\", {}),\n",
    "        \"replies\": tweet.get(\"replies\", [])\n",
    "    }\n",
    "\n",
    "tweets_por_user = {}\n",
    "for tw in tweets_data:\n",
    "    raw_user = tw.get(\"user\", \"\")\n",
    "    if not raw_user or raw_user.startswith(\"Error\"):\n",
    "        continue\n",
    "\n",
    "    # Extraer el @handle\n",
    "    tokens = raw_user.split()\n",
    "    handle = next((t for t in reversed(tokens) if t.startswith(\"@\")), None)\n",
    "    if not handle:\n",
    "        continue\n",
    "\n",
    "    if handle not in tweets_por_user:\n",
    "        tweets_por_user[handle] = []\n",
    "\n",
    "    tweets_por_user[handle].append(construir_tweet(tw))\n",
    "\n",
    "# ‚Äî Fusionar pol√≠ticos con tweets ‚Äî\n",
    "with open(\"users_espa√±oles.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    user_map = json.load(f)\n",
    "\n",
    "# Mapeo r√°pido: @usuario ‚Üí nombre normalizado\n",
    "handle_to_normname = {u['user']: normalize(u['name']) for u in user_map}\n",
    "\n",
    "# Generar resultado\n",
    "final = []\n",
    "for p in politicos:\n",
    "    normname = normalize(p['name'])\n",
    "    handle = next((h for h, n in handle_to_normname.items() if n == normname), None)\n",
    "\n",
    "    tweets = tweets_por_user.get(handle, []) if handle else []\n",
    "\n",
    "    final.append({\n",
    "        \"name\": p[\"name\"],\n",
    "        \"user\": handle,\n",
    "        \"party\": p.get(\"party\"),\n",
    "        \"age\": p.get(\"age\"),\n",
    "        \"gender\": p.get(\"gender\"),\n",
    "        \"tweets\": tweets\n",
    "    })\n",
    "\n",
    "# ‚Äî Guardar JSON final ‚Äî\n",
    "with open(OUTPUT_PATH, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(final, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "print(f\"‚úÖ JSON final generado en: {OUTPUT_PATH}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "417d019b-bc98-4228-a705-5b65b8faee32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archivo guardado como: grecia_anotados/politicos_griegos.json\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Ruta del archivo Excel de entrada\n",
    "input_excel = \"grecia_anotados/politicos_griegos.xlsx\"  # Cambia por tu archivo\n",
    "\n",
    "# Leer la hoja (puedes especificar sheet_name si hay varias hojas)\n",
    "df = pd.read_excel(input_excel)\n",
    "\n",
    "# Convertir a JSON y guardar\n",
    "output_json = \"grecia_anotados/politicos_griegos.json\"\n",
    "df.to_json(output_json, orient=\"records\", force_ascii=False, indent=2)\n",
    "\n",
    "print(f\"Archivo guardado como: {output_json}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e1e2c703-cfa6-4972-b4b7-a59a9f9945e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c7055c04fec43c5b478dc595637ba2c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.10.0.json:   0%|  ‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-29 21:23:56 INFO: Downloaded file to /home/jupyter-lquijano/stanza_resources/resources.json\n",
      "2025-04-29 21:23:56 INFO: Downloading default packages for language: es (Spanish) ...\n",
      "2025-04-29 21:23:57 INFO: File exists: /home/jupyter-lquijano/stanza_resources/es/default.zip\n",
      "2025-04-29 21:24:01 INFO: Finished downloading models and saved to /home/jupyter-lquijano/stanza_resources\n",
      "2025-04-29 21:24:01 INFO: Checking for updates to resources.json in case models have been updated.  Note: this behavior can be turned off with download_method=None or download_method=DownloadMethod.REUSE_RESOURCES\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12b9b5aac5c3474780bf0d4c1af1ab2d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.10.0.json:   0%|  ‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-29 21:24:01 INFO: Downloaded file to /home/jupyter-lquijano/stanza_resources/resources.json\n",
      "2025-04-29 21:24:01 WARNING: Language es package default expects mwt, which has been added\n",
      "2025-04-29 21:24:01 INFO: Loading these models for language: es (Spanish):\n",
      "===============================\n",
      "| Processor | Package         |\n",
      "-------------------------------\n",
      "| tokenize  | combined        |\n",
      "| mwt       | combined        |\n",
      "| pos       | combined_charlm |\n",
      "===============================\n",
      "\n",
      "2025-04-29 21:24:01 INFO: Using device: cpu\n",
      "2025-04-29 21:24:01 INFO: Loading: tokenize\n",
      "2025-04-29 21:24:01 INFO: Loading: mwt\n",
      "2025-04-29 21:24:01 INFO: Loading: pos\n",
      "2025-04-29 21:24:03 INFO: Done loading processors!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Archivo enriquecido guardado como: tweets_features_stanza.json\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import stanza\n",
    "\n",
    "# Paso 1: Descargar modelos si es necesario\n",
    "stanza.download(\"es\")\n",
    "\n",
    "# Paso 2: Inicializar el pipeline de Stanza para espa√±ol\n",
    "nlp = stanza.Pipeline(\"es\", processors=\"tokenize,pos\", use_gpu=False)\n",
    "\n",
    "# Paso 3: Cargar archivo Excel\n",
    "archivo_excel = \"spain/Tweets_etiquetados.xlsx\"\n",
    "df = pd.read_excel(archivo_excel)\n",
    "\n",
    "# Paso 4: Procesar cada tweet\n",
    "resultados = []\n",
    "\n",
    "for _, row in df.iterrows():\n",
    "    tweet_text = str(row[\"text\"])\n",
    "    user = str(row[\"id\"]) if \"id\" in row else \"desconocido\"\n",
    "\n",
    "    # POS tagging con Stanza\n",
    "    doc = nlp(tweet_text)\n",
    "    pos_tags = []\n",
    "    counts = {\"DET\": 0, \"NOUN\": 0, \"VERB\": 0, \"ADJ\": 0, \"PROPN\": 0, \"PRON\": 0}\n",
    "\n",
    "    first_word_pos = None\n",
    "\n",
    "    for sentence in doc.sentences:\n",
    "        for idx, word in enumerate(sentence.words):\n",
    "            pos_tags.append({\n",
    "                \"text\": word.text,\n",
    "                \"pos\": word.upos\n",
    "            })\n",
    "            if word.upos in counts:\n",
    "                counts[word.upos] += 1\n",
    "            if first_word_pos is None and idx == 0:\n",
    "                first_word_pos = word.upos\n",
    "\n",
    "    # Paso 5: Construir el diccionario de salida SIN buscar partidos\n",
    "    resultados.append({\n",
    "        \"id\": user,\n",
    "        \"tweet\": tweet_text,\n",
    "        \"num_determinantes\": counts[\"DET\"],\n",
    "        \"num_nouns\": counts[\"NOUN\"],\n",
    "        \"num_verbs\": counts[\"VERB\"],\n",
    "        \"num_adjectives\": counts[\"ADJ\"],\n",
    "        \"num_proper_nouns\": counts[\"PROPN\"],\n",
    "        \"starts_with_pronoun\": first_word_pos == \"PRON\",\n",
    "        \"ratio_noun_to_verb\": round(counts[\"NOUN\"] / counts[\"VERB\"], 2) if counts[\"VERB\"] > 0 else None\n",
    "    })\n",
    "\n",
    "# Paso 6: Guardar el resultado en JSON\n",
    "output_file = \"tweets_features_stanza.json\"\n",
    "with open(output_file, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(resultados, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "print(f\"‚úÖ Archivo enriquecido guardado como: {output_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4206332a-0cb2-44bf-a3d4-53bc13fc051f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c16e9addbde242c488b8dac86146605d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.10.0.json:   0%|  ‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-29 21:48:42 INFO: Downloaded file to /home/jupyter-lquijano/stanza_resources/resources.json\n",
      "2025-04-29 21:48:42 INFO: Downloading default packages for language: el (Greek) ...\n",
      "2025-04-29 21:48:43 INFO: File exists: /home/jupyter-lquijano/stanza_resources/el/default.zip\n",
      "2025-04-29 21:48:44 INFO: Finished downloading models and saved to /home/jupyter-lquijano/stanza_resources\n",
      "2025-04-29 21:48:44 INFO: Checking for updates to resources.json in case models have been updated.  Note: this behavior can be turned off with download_method=None or download_method=DownloadMethod.REUSE_RESOURCES\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b819ae693a2340659f075897cb947f15",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.10.0.json:   0%|  ‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-29 21:48:44 INFO: Downloaded file to /home/jupyter-lquijano/stanza_resources/resources.json\n",
      "2025-04-29 21:48:44 WARNING: Language el package default expects mwt, which has been added\n",
      "2025-04-29 21:48:44 INFO: Loading these models for language: el (Greek):\n",
      "============================\n",
      "| Processor | Package      |\n",
      "----------------------------\n",
      "| tokenize  | gdt          |\n",
      "| mwt       | gdt          |\n",
      "| pos       | gdt_nocharlm |\n",
      "============================\n",
      "\n",
      "2025-04-29 21:48:44 WARNING: GPU requested, but is not available!\n",
      "2025-04-29 21:48:44 INFO: Using device: cpu\n",
      "2025-04-29 21:48:44 INFO: Loading: tokenize\n",
      "2025-04-29 21:48:44 INFO: Loading: mwt\n",
      "2025-04-29 21:48:44 INFO: Loading: pos\n",
      "2025-04-29 21:48:45 INFO: Done loading processors!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Archivo enriquecido guardado como: tweets_griegos_features_stanza.json\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import stanza\n",
    "\n",
    "# Paso 1: Descargar modelo de griego si es necesario\n",
    "stanza.download(\"el\")\n",
    "\n",
    "# Paso 2: Inicializar el pipeline de Stanza para griego\n",
    "nlp = stanza.Pipeline(\"el\", processors=\"tokenize,pos\", use_gpu=True)\n",
    "\n",
    "# Paso 3: Cargar archivo JSON\n",
    "archivo_json = \"grecia_anotados/Preprado/Tweets_griegos.json\"\n",
    "with open(archivo_json, \"r\", encoding=\"utf-8\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# Paso 4: Procesar cada tweet\n",
    "resultados = []\n",
    "\n",
    "for item in data:\n",
    "    tweet_text = str(item.get(\"tweet\", \"\"))\n",
    "    tweet_id = str(item.get(\"id\", \"desconocido\"))\n",
    "\n",
    "    # POS tagging con Stanza\n",
    "    doc = nlp(tweet_text)\n",
    "    pos_tags = []\n",
    "    counts = {\"DET\": 0, \"NOUN\": 0, \"VERB\": 0, \"ADJ\": 0, \"PROPN\": 0, \"PRON\": 0}\n",
    "    first_word_pos = None\n",
    "\n",
    "    for sentence in doc.sentences:\n",
    "        for idx, word in enumerate(sentence.words):\n",
    "            pos_tags.append({\n",
    "                \"text\": word.text,\n",
    "                \"pos\": word.upos\n",
    "            })\n",
    "            if word.upos in counts:\n",
    "                counts[word.upos] += 1\n",
    "            if first_word_pos is None and idx == 0:\n",
    "                first_word_pos = word.upos\n",
    "\n",
    "    # Paso 5: A√±adir los features directamente al objeto original\n",
    "    item[\"pos_features\"] = {\n",
    "        \"num_determinantes\": counts[\"DET\"],\n",
    "        \"num_nouns\": counts[\"NOUN\"],\n",
    "        \"num_verbs\": counts[\"VERB\"],\n",
    "        \"num_adjectives\": counts[\"ADJ\"],\n",
    "        \"num_proper_nouns\": counts[\"PROPN\"],\n",
    "        \"starts_with_pronoun\": first_word_pos == \"PRON\",\n",
    "        \"ratio_noun_to_verb\": round(counts[\"NOUN\"] / counts[\"VERB\"], 2) if counts[\"VERB\"] > 0 else None\n",
    "    }\n",
    "\n",
    "# Paso 6: Guardar el resultado en un nuevo JSON\n",
    "output_file = \"tweets_griegos_features_stanza.json\"\n",
    "with open(output_file, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(data, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "print(f\"‚úÖ Archivo enriquecido guardado como: {output_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5bf10a5a-95d9-4a16-8c50-d0a97ddb3454",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Se a√±adieron los POS features al analysis de cada tweet correctamente.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# 1. Cargar el JSON principal (con an√°lisis de sentimiento, emociones, etc.)\n",
    "with open(\"grecia_anotados/Preprado/Tweets_griegos.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    tweets_analizados = json.load(f)\n",
    "\n",
    "# 2. Cargar el JSON con los features POS (stanza)\n",
    "with open(\"tweets_griegos_features_stanza.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    tweets_features = json.load(f)\n",
    "\n",
    "# 3. Crear un mapa r√°pido: texto del tweet -> pos_features\n",
    "mapa_features = {\n",
    "    item[\"tweet\"].strip(): item.get(\"pos_features\", {})\n",
    "    for item in tweets_features\n",
    "}\n",
    "\n",
    "# 4. Insertar los pos_features en el analysis de cada tweet\n",
    "for tweet in tweets_analizados:\n",
    "    texto = tweet[\"tweet\"].strip()\n",
    "    features = mapa_features.get(texto, None)\n",
    "    if features:\n",
    "        tweet.setdefault(\"analysis\", {})[\"pos_features\"] = features  # A√±adir pos_features dentro de analysis\n",
    "\n",
    "# 5. Guardar el nuevo JSON enriquecido\n",
    "with open(\"tweets_completos_con_analysis_y_pos.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(tweets_analizados, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "print(\"‚úÖ Se a√±adieron los POS features al analysis de cada tweet correctamente.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "15b80490-4c27-4023-9bc2-0961fffddf66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Archivo actualizado con la polaridad ideol√≥gica.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# 1. Cargar JSON con los an√°lisis y partidos\n",
    "with open(\"grecia_anotados/Preprado/Griegos.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# 2. Crear diccionario de partidos ‚Üí polaridad\n",
    "partido_a_ideologia = {\n",
    "    \"ŒùŒ≠Œ± ŒîŒ∑ŒºŒøŒ∫œÅŒ±œÑŒØŒ±\": \"derecha\",\n",
    "    \"ŒïŒªŒªŒ∑ŒΩŒπŒ∫ŒÆ ŒõœçœÉŒ∑\": \"derecha\",\n",
    "    \"ŒëŒΩŒµŒæŒ¨œÅœÑŒ∑œÑŒøŒπ ŒàŒªŒªŒ∑ŒΩŒµœÇ\": \"derecha\",\n",
    "    \"ŒïŒ∏ŒΩŒπŒ∫ŒÆ ŒîŒ∑ŒºŒπŒøœÖœÅŒ≥ŒØŒ±\": \"derecha\",\n",
    "    \"Œ£œÖŒΩŒ±œÉœÄŒπœÉŒºœåœÇ Œ°ŒπŒ∂ŒøœÉœÄŒ±œÉœÑŒπŒ∫ŒÆœÇ ŒëœÅŒπœÉœÑŒµœÅŒ¨œÇ ‚Äì Œ†œÅŒøŒøŒ¥ŒµœÖœÑŒπŒ∫ŒÆ Œ£œÖŒºŒºŒ±œáŒØŒ±\": \"izquierda\",\n",
    "    \"Œ†ŒëŒ£ŒüŒö ‚Äì ŒöŒØŒΩŒ∑ŒºŒ± ŒëŒªŒªŒ±Œ≥ŒÆœÇ\": \"izquierda\",\n",
    "    \"ŒúŒ≠Œ°Œë25\": \"izquierda\",\n",
    "    \"ŒöŒØŒΩŒ∑ŒºŒ± ŒëŒªŒªŒ±Œ≥ŒÆœÇ\": \"izquierda\",\n",
    "    \"ŒöŒøŒºŒºŒøœÖŒΩŒπœÉœÑŒπŒ∫œå ŒöœåŒºŒºŒ± ŒïŒªŒªŒ¨Œ¥Œ±œÇ\": \"izquierda\",\n",
    "    \"ŒöŒØŒΩŒ∑ŒºŒ± ŒîŒ∑ŒºŒøŒ∫œÅŒ±œÑœéŒΩ Œ£ŒøœÉŒπŒ±ŒªŒπœÉœÑœéŒΩ\": \"izquierda\"\n",
    "}\n",
    "\n",
    "# 3. Suponemos que en cada tweet tienes la clave 'party' ya puesta\n",
    "for tweet in data:\n",
    "    partido = tweet.get(\"party\", \"\").strip()\n",
    "    polaridad = partido_a_ideologia.get(partido)\n",
    "    tweet[\"polaridad_ideologica\"] = polaridad  # Puede ser None si el partido no est√° en el mapeo\n",
    "\n",
    "# 4. Guardar resultado\n",
    "with open(\"grecia_anotados/Preprado/Griegos_f.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(data, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "print(\"‚úÖ Archivo actualizado con la polaridad ideol√≥gica.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "3f8a1e48-09cf-4a49-9de5-864a5a2002b9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'user': 'Giannis Plakiotakis\\n@G_Plakiotakis',\n",
       "  'tweet': 'Œ§Œ∑ŒΩ Œ§ŒµœÑŒ¨œÅœÑŒ∑ œÑŒø œÄœÅœâŒØ, œÉœÑŒπœÇ 9:15 œÉœÑŒøŒΩ Œ£ŒöŒëŒ™ Œ∫Œ±Œπ œÑŒ∑ŒΩ ŒµŒ∫œÄŒøŒºœÄŒÆ \"Œ£ŒÆŒºŒµœÅŒ±\" #Œ†ŒªŒ±Œ∫ŒπœâœÑŒ¨Œ∫Œ∑œÇ #Œ£ŒöŒëŒ™ https://t.co/PynuyD0upJ',\n",
       "  'replies': [],\n",
       "  'analysis': {'sentiment': {'label': 'neutral', 'score': 0.8632032871246338},\n",
       "   'emotions': [{'label': 'optimism', 'score': 0.593174934387207},\n",
       "    {'label': 'joy', 'score': 0.19987452030181885},\n",
       "    {'label': 'anger', 'score': 0.12021705508232117}],\n",
       "   'hate': {'label': 'not hate', 'score': 0.7837180495262146},\n",
       "   'translation': 'Wednesday morning, at 9:15 p.m. and today\\'s \"Today\" issue #Scaoits https://t.co/PynuyD0upJ',\n",
       "   'summary': ' Wednesday morning, at 9:15 p.m. and today\\'s \"Today\" issue #Scaoits .',\n",
       "   'pos_features': {'num_determinantes': 5,\n",
       "    'num_nouns': 6,\n",
       "    'num_verbs': 0,\n",
       "    'num_adjectives': 0,\n",
       "    'num_proper_nouns': 0,\n",
       "    'starts_with_pronoun': False,\n",
       "    'ratio_noun_to_verb': None}},\n",
       "  'id': '1349005840745984007',\n",
       "  'label': '0',\n",
       "  'annotator': 'tiebreak_rule',\n",
       "  'name': 'Giannis Plakiotakis',\n",
       "  'age': None,\n",
       "  'gender': None,\n",
       "  'party': None},\n",
       " {'user': 'ŒöŒ±œÑŒµœÅŒØŒΩŒ± ŒùŒøœÑŒøœÄŒøœçŒªŒøœÖ\\n@katenotopoulou',\n",
       "  'tweet': 'Œ†œÅŒøœáŒµŒπœÅŒøŒ≥œÅŒ¨œÜŒ∑ŒºŒ± Œø ŒΩŒ≠ŒøœÇ ŒüœÅŒ≥Œ±ŒΩŒπœÉŒºœåœÇ ŒïœÉœâœÑŒµœÅŒπŒ∫ŒÆœÇ Œ•œÄŒ∑œÅŒµœÉŒØŒ±œÇ œÑŒøœÖ ŒîŒÆŒºŒøœÖ ŒòŒµœÉœÉŒ±ŒªŒøŒΩŒØŒ∫Œ∑œÇ. ŒîŒµŒΩ ŒªŒ±ŒºŒ≤Œ¨ŒΩŒµŒπ œÖœÄœåœàŒ∑ Œ∫Œ±Œπ Œ¥ŒµŒΩ Œ±ŒΩœÑŒ±œÄŒøŒ∫œÅŒØŒΩŒµœÑŒ±Œπ œÉœÑŒπœÇ Œ±œÄŒ±ŒπœÑŒÆœÉŒµŒπœÇ œÉœçŒ≥œáœÅŒøŒΩŒ∑œÇ Œ¥ŒπŒ±Œ∫œÖŒ≤Œ≠œÅŒΩŒ∑œÉŒ∑œÇ œÑœâŒΩ Œ¥ŒÆŒºœâŒΩ. ŒîŒµŒΩ ŒµŒ∫œÉœÖŒ≥œáœÅŒøŒΩŒØŒ∂ŒµŒπ œÑŒ∑ ŒªŒµŒπœÑŒøœÖœÅŒ≥ŒØŒ± œÑŒøœÖ ŒîŒÆŒºŒøœÖ ŒòŒµœÉœÉŒ±ŒªŒøŒΩŒØŒ∫Œ∑œÇ. https://t.co/qbZZ5XsbpC',\n",
       "  'replies': [],\n",
       "  'analysis': {'sentiment': {'label': 'neutral', 'score': 0.7721729874610901},\n",
       "   'emotions': [{'label': 'optimism', 'score': 0.5586957931518555},\n",
       "    {'label': 'joy', 'score': 0.2313828319311142},\n",
       "    {'label': 'anger', 'score': 0.13311350345611572}],\n",
       "   'hate': {'label': 'not hate', 'score': 0.8688682317733765},\n",
       "   'translation': 'The new Internal Service Agency of the Thessaloniki City of Thessaloniki. It does not take into account and does not meet the modern government requirements of the municipalities. It does not modernize the operation of the Thessaloniki City. https://t.co/qbZ5XsbpC',\n",
       "   'summary': \" The new Internal Service Agency of the Thessaloniki City does not meet the modern government requirements of the municipalities . It does not modernize the operation of the city, according to the city's mayor . The new agency does not take into account and does not .\",\n",
       "   'pos_features': {'num_determinantes': 6,\n",
       "    'num_nouns': 9,\n",
       "    'num_verbs': 4,\n",
       "    'num_adjectives': 2,\n",
       "    'num_proper_nouns': 2,\n",
       "    'starts_with_pronoun': False,\n",
       "    'ratio_noun_to_verb': 2.25}},\n",
       "  'id': '1352200868943245313',\n",
       "  'label': '-1',\n",
       "  'annotator': 'tiebreak_rule',\n",
       "  'name': 'ŒöŒ±œÑŒµœÅŒØŒΩŒ± ŒùŒøœÑŒøœÄŒøœçŒªŒøœÖ',\n",
       "  'age': 36,\n",
       "  'gender': 'femenino',\n",
       "  'party': 'Œ£œÖŒΩŒ±œÉœÄŒπœÉŒºœåœÇ Œ°ŒπŒ∂ŒøœÉœÄŒ±œÉœÑŒπŒ∫ŒÆœÇ ŒëœÅŒπœÉœÑŒµœÅŒ¨œÇ ‚Äì Œ†œÅŒøŒøŒ¥ŒµœÖœÑŒπŒ∫ŒÆ Œ£œÖŒºŒºŒ±œáŒØŒ±'}]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Carga tus datos (aqu√≠ se asume que ya los has cargado como listas de diccionarios)\n",
    "# json1 es la lista con tweets, json2 la lista con informaci√≥n personal\n",
    "\n",
    "with open('grecia_anotados/Preprado/tweets_completos_con_analysis_y_pos.json', 'r', encoding='utf-8') as f:\n",
    "    tweets_data = json.load(f)\n",
    "\n",
    "with open('grecia_anotados/politicos_griegos.json', 'r', encoding='utf-8') as f:\n",
    "    info_data = json.load(f)\n",
    "\n",
    "# Crear un diccionario para b√∫squeda r√°pida por nombre\n",
    "info_dict = {entry['name']: entry for entry in info_data}\n",
    "\n",
    "# Funci√≥n para extraer el nombre del campo \"user\"\n",
    "def extract_name(user_str):\n",
    "    return user_str.split('\\n')[0].strip()\n",
    "\n",
    "# Lista final combinada\n",
    "combined = []\n",
    "\n",
    "for tweet_entry in tweets_data:\n",
    "    name = extract_name(tweet_entry[\"user\"])\n",
    "    persona_info = info_dict.get(name, {})  # Si no se encuentra, ser√° un dict vac√≠o\n",
    "    \n",
    "    tweet_copy = tweet_entry.copy()\n",
    "    tweet_copy[\"name\"] = name  # A√±adir campo separado\n",
    "    tweet_copy[\"age\"] = persona_info.get(\"age\")\n",
    "    tweet_copy[\"gender\"] = persona_info.get(\"gender\")\n",
    "    tweet_copy[\"party\"] = persona_info.get(\"party\")\n",
    "    \n",
    "    combined.append(tweet_copy)\n",
    "\n",
    "# Guardar resultado\n",
    "with open('combined.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(combined, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "# Mostrar una muestra\n",
    "combined[:2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "62c6d318-df4e-46eb-a495-c7015c5327b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "142\n",
      "No se encontr√≥ informaci√≥n para 73 personas.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import unicodedata\n",
    "\n",
    "# Funci√≥n para normalizar nombres (quita acentos, pone min√∫sculas)\n",
    "def normalizar(texto):\n",
    "    if not texto:\n",
    "        return \"\"\n",
    "    texto = unicodedata.normalize('NFKD', texto)\n",
    "    texto = ''.join([c for c in texto if not unicodedata.combining(c)])\n",
    "    return texto.lower().strip()\n",
    "\n",
    "# Cargar el mapeo nombre‚Äìusuario\n",
    "with open('grecia_anotados/users_griegos.json', 'r', encoding='utf-8') as f:\n",
    "    name_user_map = json.load(f)\n",
    "\n",
    "# Cargar la informaci√≥n personal original\n",
    "with open('grecia_anotados/politicos_griegos.json', 'r', encoding='utf-8') as f:\n",
    "    info_data = json.load(f)\n",
    "\n",
    "# Crear diccionario con nombres normalizados para b√∫squeda flexible\n",
    "info_dict_normalizado = {\n",
    "    normalizar(entry[\"name\"]): entry\n",
    "    for entry in info_data\n",
    "}\n",
    "\n",
    "# Construir el nuevo JSON unificado\n",
    "resultado = []\n",
    "no_encontrados = []\n",
    "\n",
    "for entry in name_user_map:\n",
    "    name_original = entry[\"name\"]\n",
    "    user = entry[\"user\"]\n",
    "    name_normalizado = normalizar(name_original)\n",
    "\n",
    "    info = info_dict_normalizado.get(name_normalizado)\n",
    "\n",
    "    if info:\n",
    "        resultado.append({\n",
    "            \"name\": name_original,\n",
    "            \"user\": user,\n",
    "            \"age\": info.get(\"age\"),\n",
    "            \"gender\": info.get(\"gender\"),\n",
    "            \"party\": info.get(\"party\")\n",
    "        })\n",
    "    else:\n",
    "        no_encontrados.append(name_original)\n",
    "        resultado.append({\n",
    "            \"name\": name_original,\n",
    "            \"user\": user,\n",
    "            \"age\": None,\n",
    "            \"gender\": None,\n",
    "            \"party\": None\n",
    "        })\n",
    "\n",
    "# Guardar resultado\n",
    "with open('user_info_completo.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(resultado, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "# Guardar lista de no encontrados (opcional)\n",
    "with open('no_encontrados.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(no_encontrados, f, ensure_ascii=False, indent=2)\n",
    "print(len(resultado))\n",
    "# Mostrar cu√°ntos no se encontraron\n",
    "print(f\"No se encontr√≥ informaci√≥n para {len(no_encontrados)} personas.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3e9a7c6-e6ff-458a-a82d-a28ca96fc105",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "09992d8b-9aa7-4661-825a-9069aa7aa673",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Fusi√≥n completada. Archivo guardado como 'tweets_fusionados.json'.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from collections import defaultdict\n",
    "\n",
    "# Cargar archivos\n",
    "with open('spain/Completado/tweets_espa√±oles_evaluados_completo.json', 'r', encoding='utf-8') as f:\n",
    "    original_data = json.load(f)\n",
    "\n",
    "with open('spain/Tweets_etiquetados.json', 'r', encoding='utf-8') as f:\n",
    "    manual_annotations = json.load(f)\n",
    "\n",
    "with open('tweets_espa√±oles_evaluados_completo.json', 'r', encoding='utf-8') as f:\n",
    "    stanza_sentiment = json.load(f)\n",
    "\n",
    "with open('spain/usuarios_con_tweets_y_detalles.json', 'r', encoding='utf-8') as f:\n",
    "    user_info = json.load(f)\n",
    "\n",
    "# Convertir anotaciones y sentimientos en diccionarios para acceso r√°pido\n",
    "annotation_dict = {str(item['id']): item for item in manual_annotations}\n",
    "stanza_dict = {str(item['id']): item['analysis']['sentiment'] for item in stanza_sentiment}\n",
    "stanza_reply_dict = {str(item['id']): item for item in stanza_sentiment}\n",
    "\n",
    "# Crear √≠ndice de usuario por tweet_id\n",
    "user_by_tweet = {}\n",
    "for user in user_info:\n",
    "    for tid in user['tweet_ids']:\n",
    "        user_by_tweet[str(tid)] = {\n",
    "            \"name\": user['name'],\n",
    "            \"age\": user['age'],\n",
    "            \"gender\": user['gender'],\n",
    "            \"party\": user['party']\n",
    "        }\n",
    "\n",
    "# Organizar resultado final por usuario\n",
    "final_result = defaultdict(lambda: {\n",
    "    \"name\": \"\",\n",
    "    \"age\": None,\n",
    "    \"gender\": \"\",\n",
    "    \"party\": \"\",\n",
    "    \"tweets\": []\n",
    "})\n",
    "\n",
    "for tweet in original_data:\n",
    "    tweet_id = str(tweet['id'])\n",
    "\n",
    "    # Filtrar si no est√° en las anotaciones\n",
    "    if tweet_id not in annotation_dict:\n",
    "        continue\n",
    "\n",
    "    # Verificar si hay datos del usuario\n",
    "    if tweet_id not in user_by_tweet:\n",
    "        continue\n",
    "\n",
    "    user_info_obj = user_by_tweet[tweet_id]\n",
    "    user_key = user_info_obj['name'] + ' ' + user_info_obj['party']\n",
    "\n",
    "    # Agregar informaci√≥n del usuario\n",
    "    final_result[user_key]['name'] = user_info_obj['name']\n",
    "    final_result[user_key]['age'] = user_info_obj['age']\n",
    "    final_result[user_key]['gender'] = user_info_obj['gender']\n",
    "    final_result[user_key]['party'] = user_info_obj['party']\n",
    "\n",
    "    # Agregar anotaciones manuales\n",
    "    annotations = {\n",
    "        \"User1\": annotation_dict[tweet_id][\"User1\"],\n",
    "        \"User2\": annotation_dict[tweet_id][\"User2\"],\n",
    "        \"Total\": annotation_dict[tweet_id][\"Total\"]\n",
    "    }\n",
    "\n",
    "    # A√±adir sentimiento stanza si existe\n",
    "    if tweet_id in stanza_dict:\n",
    "        tweet['analysis']['sentiment_stanza'] = stanza_dict[tweet_id]\n",
    "\n",
    "    # Procesar replies por orden\n",
    "    replies = tweet.get('replies', [])\n",
    "    stanza_replies = stanza_reply_dict.get(tweet_id, {}).get('replies', [])\n",
    "\n",
    "    for idx, reply in enumerate(replies):\n",
    "        if idx < len(stanza_replies):\n",
    "            sentiment_stanza = stanza_replies[idx].get('analysis', {}).get('sentiment')\n",
    "            if sentiment_stanza is not None:\n",
    "                reply['analysis']['sentiment_stanza'] = sentiment_stanza\n",
    "\n",
    "    # Crear estructura final del tweet\n",
    "    tweet_struct = {\n",
    "        \"id\": tweet_id,\n",
    "        \"tweet\": tweet['tweet'],\n",
    "        \"analysis\": tweet['analysis'],\n",
    "        \"annotations\": annotations,\n",
    "        \"replies\": replies\n",
    "    }\n",
    "\n",
    "    final_result[user_key]['tweets'].append(tweet_struct)\n",
    "\n",
    "# Guardar resultado final\n",
    "final_json = list(final_result.values())\n",
    "\n",
    "with open('tweets_fusionados.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(final_json, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "print(\"‚úÖ Fusi√≥n completada. Archivo guardado como 'tweets_fusionados.json'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b15cf3ab-154a-408a-b8fe-8c8a4132a0b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Partidos pol√≠ticos encontrados:\n",
      "- BNG\n",
      "- CCa-PNC-NC\n",
      "- CUP-PR\n",
      "- Cs\n",
      "- ECP\n",
      "- EH Bildu\n",
      "- ERC-Sob\n",
      "- JxCat\n",
      "- MP\n",
      "- NA+\n",
      "- PP\n",
      "- PSOE\n",
      "- UP\n",
      "- VOX\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Cargar el archivo fusionado\n",
    "with open('tweets_fusionados_ideologia.json', 'r', encoding='utf-8') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# Extraer todos los partidos\n",
    "partidos = set()\n",
    "for usuario in data:\n",
    "    partido = usuario.get('party')\n",
    "    if partido:\n",
    "        partidos.add(partido)\n",
    "\n",
    "# Mostrar la lista ordenada\n",
    "partidos_ordenados = sorted(partidos)\n",
    "print(\"Partidos pol√≠ticos encontrados:\")\n",
    "for partido in partidos_ordenados:\n",
    "    print(\"-\", partido)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "74da29f3-3843-4560-a325-23cd3158f178",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Partidos normalizados y clasificados. Guardado como 'tweets_fusionados_ideologia.json'.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Cargar el archivo fusionado\n",
    "with open('tweets_fusionados.json', 'r', encoding='utf-8') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# Normalizar nombres de partidos (guiones inconsistentes)\n",
    "def normalizar_partido(partido):\n",
    "    partido = partido.replace('‚Äì', '-')  # guion largo a guion corto\n",
    "    if partido in ['ERC-Sob', 'ERC‚ÄìSob']:\n",
    "        return 'ERC-Sob'\n",
    "    return partido\n",
    "\n",
    "# Definir agrupaci√≥n ideol√≥gica\n",
    "izquierda = {'BNG', 'CUP-PR', 'ECP', 'EH Bildu', 'ERC-Sob', 'MP', 'PSOE', 'UP'}\n",
    "derecha = {'CCa-PNC-NC', 'Cs', 'JxCat', 'NA+', 'PP', 'VOX'}\n",
    "\n",
    "# Procesar cada usuario\n",
    "for usuario in data:\n",
    "    partido = normalizar_partido(usuario['party'])\n",
    "    usuario['party'] = partido  # actualizar nombre normalizado\n",
    "\n",
    "    if partido in izquierda:\n",
    "        usuario['ideologia'] = 'izquierda'\n",
    "    elif partido in derecha:\n",
    "        usuario['ideologia'] = 'derecha'\n",
    "    else:\n",
    "        usuario['ideologia'] = 'otros'\n",
    "\n",
    "# Guardar el archivo modificado\n",
    "with open('tweets_fusionados_ideologia.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(data, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "print(\"‚úÖ Partidos normalizados y clasificados. Guardado como 'tweets_fusionados_ideologia.json'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "70c46d20-a2eb-4fba-a75e-0f141d79015b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Resultados guardados en 'comparaciones_sesgo.csv'\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import ttest_ind\n",
    "\n",
    "# === 1. Cargar archivo fusionado con ideolog√≠a incluida ===\n",
    "with open('tweets_fusionados_ideologia.json', 'r', encoding='utf-8') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# === 2. Extraer replies con an√°lisis y atributos del autor original ===\n",
    "rows = []\n",
    "for usuario in data:\n",
    "    gender = usuario['gender']\n",
    "    age = usuario['age']\n",
    "    party = usuario['party']\n",
    "    ideologia = usuario['ideologia']\n",
    "\n",
    "    for tweet in usuario['tweets']:\n",
    "        for reply in tweet.get('replies', []):\n",
    "            if not isinstance(reply, dict):\n",
    "                continue\n",
    "            analysis = reply.get('analysis')\n",
    "            if not isinstance(analysis, dict):\n",
    "                continue\n",
    "\n",
    "            hate = analysis.get('hate')\n",
    "            hate_score = hate.get('score') if isinstance(hate, dict) else None\n",
    "\n",
    "            sentiment = analysis.get('sentiment')\n",
    "            sentiment_score = sentiment.get('score') if isinstance(sentiment, dict) else None\n",
    "\n",
    "            emotions_raw = analysis.get('emotions', [])\n",
    "            emotions = {}\n",
    "            if isinstance(emotions_raw, list):\n",
    "                emotions = {\n",
    "                    e['label']: e['score']\n",
    "                    for e in emotions_raw\n",
    "                    if isinstance(e, dict) and 'label' in e and 'score' in e\n",
    "                }\n",
    "\n",
    "            row = {\n",
    "                'gender': gender,\n",
    "                'age': age,\n",
    "                'party': party,\n",
    "                'ideologia': ideologia,\n",
    "                'hate_score': hate_score,\n",
    "                'sentiment_score': sentiment_score,\n",
    "            }\n",
    "            row.update(emotions)\n",
    "            rows.append(row)\n",
    "\n",
    "# === 3. Crear DataFrame ===\n",
    "df = pd.DataFrame(rows)\n",
    "\n",
    "# === 4. Limpiar y categorizar edad ===\n",
    "df = df.dropna(subset=['age'])  # eliminar edad nula\n",
    "df['age_group'] = pd.cut(df['age'], bins=[0, 40, 100], labels=['joven', 'mayor'])\n",
    "\n",
    "# === 5. Funci√≥n para calcular d de Cohen ===\n",
    "def cohens_d(x1, x2):\n",
    "    n1, n2 = len(x1), len(x2)\n",
    "    s1, s2 = np.var(x1, ddof=1), np.var(x2, ddof=1)\n",
    "    s_pooled = np.sqrt(((n1 - 1)*s1 + (n2 - 1)*s2) / (n1 + n2 - 2))\n",
    "    return (np.mean(x1) - np.mean(x2)) / s_pooled\n",
    "\n",
    "# === 6. Comparar todas las m√©tricas contra todos los grupos ===\n",
    "metricas = ['hate_score', 'sentiment_score', 'anger', 'joy', 'sadness', 'optimism']\n",
    "grupos = ['gender', 'ideologia', 'age_group']\n",
    "\n",
    "resultados = []\n",
    "\n",
    "for variable_grupo in grupos:\n",
    "    for metrica in metricas:\n",
    "        grupos_unicos = df[variable_grupo].dropna().unique()\n",
    "        if len(grupos_unicos) != 2:\n",
    "            continue\n",
    "\n",
    "        grupo1, grupo2 = grupos_unicos\n",
    "        datos1 = df[df[variable_grupo] == grupo1][metrica].dropna()\n",
    "        datos2 = df[df[variable_grupo] == grupo2][metrica].dropna()\n",
    "\n",
    "        if len(datos1) < 10 or len(datos2) < 10:\n",
    "            continue\n",
    "\n",
    "        d = cohens_d(datos1, datos2)\n",
    "        t_stat, p_value = ttest_ind(datos1, datos2, equal_var=False)\n",
    "\n",
    "        resultados.append({\n",
    "            \"grupo\": variable_grupo,\n",
    "            \"valor\": metrica,\n",
    "            \"grupo_1\": grupo1,\n",
    "            \"grupo_2\": grupo2,\n",
    "            \"d_cohen\": d,\n",
    "            \"t_stat\": t_stat,\n",
    "            \"p_value\": p_value,\n",
    "            \"n1\": len(datos1),\n",
    "            \"n2\": len(datos2)\n",
    "        })\n",
    "\n",
    "# === 7. Mostrar resultados ordenados ===\n",
    "df_resultados = pd.DataFrame(resultados)\n",
    "df_resultados = df_resultados.sort_values(by='d_cohen', key=lambda x: abs(x), ascending=False)\n",
    "\n",
    "# === 8. Mostrar como tabla interactiva en Jupyter ===\n",
    "df_resultados.to_csv(\"comparaciones_sesgo.csv\", index=False, encoding='utf-8')\n",
    "print(\"‚úÖ Resultados guardados en 'comparaciones_sesgo.csv'\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d7f88336-3fce-42a9-bf63-2be1a5db9106",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Resultados guardados en 'sesgo_modelo_sentimiento.csv'\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import ttest_ind\n",
    "# === Funci√≥n para calcular el tama√±o del efecto (Cohen's d) ===\n",
    "def cohens_d(x1, x2):\n",
    "    n1, n2 = len(x1), len(x2)\n",
    "    s1, s2 = np.var(x1, ddof=1), np.var(x2, ddof=1)\n",
    "    s_pooled = np.sqrt(((n1 - 1)*s1 + (n2 - 1)*s2) / (n1 + n2 - 2))\n",
    "    return (np.mean(x1) - np.mean(x2)) / s_pooled if s_pooled > 0 else 0.0\n",
    "\n",
    "# === 1. Cargar archivo JSON ===\n",
    "with open('grecia_anotados/Preprado/Griegos_f.json', 'r', encoding='utf-8') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# === 2. Extraer predicciones y etiquetas humanas ===\n",
    "rows = []\n",
    "for usuario in data:\n",
    "    gender = usuario.get('gender')\n",
    "    age = usuario.get('age')\n",
    "    party = usuario.get('party')\n",
    "    ideologia = usuario.get('polaridad_ideologica')\n",
    "\n",
    "    for tweet in usuario.get('tweets', []):\n",
    "        for reply in [tweet] + tweet.get('replies', []):\n",
    "            if not isinstance(reply, dict):\n",
    "                continue\n",
    "\n",
    "            label_humana = reply.get('label')\n",
    "            if label_humana not in ['-1', '0', '1']:\n",
    "                continue\n",
    "\n",
    "            analysis = reply.get('analysis')\n",
    "            if not isinstance(analysis, dict):\n",
    "                continue\n",
    "\n",
    "            pred_sentiment = analysis.get('sentiment', {}).get('label')\n",
    "            if pred_sentiment not in ['positive', 'neutral', 'negative']:\n",
    "                continue\n",
    "\n",
    "            # Convertimos para comparar: humano (str) -> modelo (str)\n",
    "            mapping_humano = {'-1': 'negative', '0': 'neutral', '1': 'positive'}\n",
    "            label_humana_str = mapping_humano.get(label_humana)\n",
    "\n",
    "            acierto = int(pred_sentiment == label_humana_str)\n",
    "\n",
    "            rows.append({\n",
    "                'gender': gender,\n",
    "                'age': age,\n",
    "                'party': party,\n",
    "                'ideologia': ideologia,\n",
    "                'acierto': acierto\n",
    "            })\n",
    "\n",
    "# === 3. Crear DataFrame ===\n",
    "df = pd.DataFrame(rows)\n",
    "\n",
    "# === 4. Categorizar edad ===\n",
    "df = df.dropna(subset=['age'])\n",
    "df['age_group'] = pd.cut(df['age'], bins=[0, 40, 100], labels=['joven', 'mayor'])\n",
    "\n",
    "# === 5. Comparar tasa de acierto por grupo ===\n",
    "grupos = ['gender', 'ideologia', 'age_group', 'party']\n",
    "resultados = []\n",
    "\n",
    "for variable in grupos:\n",
    "    grupos_unicos = df[variable].dropna().unique()\n",
    "    if len(grupos_unicos) != 2:\n",
    "        continue\n",
    "\n",
    "    g1, g2 = grupos_unicos\n",
    "    acc1 = df[df[variable] == g1]['acierto']\n",
    "    acc2 = df[df[variable] == g2]['acierto']\n",
    "\n",
    "    if len(acc1) < 10 or len(acc2) < 10:\n",
    "        continue\n",
    "\n",
    "    # Diferencia en tasa de acierto\n",
    "    mean1, mean2 = acc1.mean(), acc2.mean()\n",
    "    d = cohens_d(acc1, acc2)\n",
    "    t_stat, p_value = ttest_ind(acc1, acc2, equal_var=False)\n",
    "\n",
    "    resultados.append({\n",
    "        'grupo': variable,\n",
    "        'grupo_1': g1,\n",
    "        'grupo_2': g2,\n",
    "        'acierto_1': mean1,\n",
    "        'acierto_2': mean2,\n",
    "        'diff': mean1 - mean2,\n",
    "        'd_cohen': d,\n",
    "        't_stat': t_stat,\n",
    "        'p_value': p_value,\n",
    "        'n1': len(acc1),\n",
    "        'n2': len(acc2)\n",
    "    })\n",
    "\n",
    "# === 6. Resultados ordenados por magnitud de efecto ===\n",
    "df_resultados = pd.DataFrame(resultados)\n",
    "df_resultados = df_resultados.sort_values(by='d_cohen', key=lambda x: abs(x), ascending=False)\n",
    "\n",
    "# === 7. Guardar como CSV ===\n",
    "df_resultados.to_csv(\"sesgo_modelo_sentimiento.csv\", index=False, encoding='utf-8')\n",
    "print(\"‚úÖ Resultados guardados en 'sesgo_modelo_sentimiento.csv'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1f763f06-c568-477d-87c9-a3f3b0364789",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ideologia\n",
      "None    925\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df['ideologia'].value_counts(dropna=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ffd6f99a-5f2e-4400-a218-b82c337cace4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Resultados guardados en 'comparaciones_completas.csv'\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import ttest_ind\n",
    "\n",
    "# === 1. Cargar archivo con estructura nueva ===\n",
    "with open('grecia_anotados/Preprado/Griegos.json', 'r', encoding='utf-8') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# === 2. Extraer tweets originales y replies con an√°lisis + atributos del autor ===\n",
    "rows = []\n",
    "for persona in data:\n",
    "    gender = persona.get('gender')\n",
    "    age = persona.get('age')\n",
    "    party = persona.get('party')\n",
    "    ideologia = persona.get('ideologia')\n",
    "\n",
    "    for tweet in persona.get('tweets', []):\n",
    "        for fuente in ['analysis'] + [r.get('analysis') for r in tweet.get('replies', []) if isinstance(r, dict) and 'analysis' in r]:\n",
    "            if not isinstance(fuente, dict):\n",
    "                continue\n",
    "\n",
    "            hate = fuente.get('hate')\n",
    "            hate_score = hate.get('score') if isinstance(hate, dict) else None\n",
    "\n",
    "            sentiment = fuente.get('sentiment')\n",
    "            sentiment_score = sentiment.get('score') if isinstance(sentiment, dict) else None\n",
    "\n",
    "            emotions_raw = fuente.get('emotions', [])\n",
    "            emotions = {}\n",
    "            if isinstance(emotions_raw, list):\n",
    "                emotions = {\n",
    "                    e['label']: e['score']\n",
    "                    for e in emotions_raw\n",
    "                    if isinstance(e, dict) and 'label' in e and 'score' in e\n",
    "                }\n",
    "\n",
    "            row = {\n",
    "                'gender': gender,\n",
    "                'age': age,\n",
    "                'party': party,\n",
    "                'ideologia': ideologia,\n",
    "                'hate_score': hate_score,\n",
    "                'sentiment_score': sentiment_score,\n",
    "            }\n",
    "            row.update(emotions)\n",
    "            rows.append(row)\n",
    "\n",
    "# === 3. Crear DataFrame ===\n",
    "df = pd.DataFrame(rows)\n",
    "\n",
    "# === 4. Limpiar y categorizar edad ===\n",
    "df = df.dropna(subset=['age'])\n",
    "df['age_group'] = pd.cut(df['age'], bins=[0, 40, 100], labels=['joven', 'mayor'])\n",
    "\n",
    "# === 5. Funci√≥n para calcular d de Cohen ===\n",
    "def cohens_d(x1, x2):\n",
    "    n1, n2 = len(x1), len(x2)\n",
    "    s1, s2 = np.var(x1, ddof=1), np.var(x2, ddof=1)\n",
    "    s_pooled = np.sqrt(((n1 - 1)*s1 + (n2 - 1)*s2) / (n1 + n2 - 2))\n",
    "    return (np.mean(x1) - np.mean(x2)) / s_pooled\n",
    "\n",
    "# === 6. Comparar m√©tricas entre grupos ===\n",
    "metricas = ['hate_score', 'sentiment_score', 'anger', 'joy', 'sadness', 'optimism']\n",
    "grupos = ['gender', 'ideologia', 'age_group']\n",
    "\n",
    "resultados = []\n",
    "\n",
    "for variable_grupo in grupos:\n",
    "    for metrica in metricas:\n",
    "        grupos_unicos = df[variable_grupo].dropna().unique()\n",
    "        if len(grupos_unicos) != 2:\n",
    "            continue\n",
    "\n",
    "        grupo1, grupo2 = grupos_unicos\n",
    "        datos1 = df[df[variable_grupo] == grupo1][metrica].dropna()\n",
    "        datos2 = df[df[variable_grupo] == grupo2][metrica].dropna()\n",
    "\n",
    "        if len(datos1) < 10 or len(datos2) < 10:\n",
    "            continue\n",
    "\n",
    "        d = cohens_d(datos1, datos2)\n",
    "        t_stat, p_value = ttest_ind(datos1, datos2, equal_var=False)\n",
    "\n",
    "        resultados.append({\n",
    "            \"grupo\": variable_grupo,\n",
    "            \"valor\": metrica,\n",
    "            \"grupo_1\": grupo1,\n",
    "            \"grupo_2\": grupo2,\n",
    "            \"d_cohen\": d,\n",
    "            \"t_stat\": t_stat,\n",
    "            \"p_value\": p_value,\n",
    "            \"n1\": len(datos1),\n",
    "            \"n2\": len(datos2)\n",
    "        })\n",
    "\n",
    "# === 7. Guardar resultados ===\n",
    "df_resultados = pd.DataFrame(resultados)\n",
    "df_resultados = df_resultados.sort_values(by='d_cohen', key=lambda x: abs(x), ascending=False)\n",
    "df_resultados.to_csv(\"comparaciones_completas.csv\", index=False, encoding='utf-8')\n",
    "print(\"‚úÖ Resultados guardados en 'comparaciones_completas.csv'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0434d065-5415-40f2-a77f-54d1411b3a2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Resultados guardados en 'comparaciones_metricas_espanoles.csv'\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import ttest_ind\n",
    "\n",
    "# === 1. Cargar archivo JSON ===\n",
    "with open('spain/Completado/Spain_Completo.json', 'r', encoding='utf-8') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# === 2. Extraer datos de an√°lisis y atributos del autor ===\n",
    "rows = []\n",
    "for persona in data:\n",
    "    gender = persona.get('gender')\n",
    "    age = persona.get('age')\n",
    "    party = persona.get('party')\n",
    "    ideologia = persona.get('ideologia')\n",
    "\n",
    "    for tweet in persona.get('tweets', []):\n",
    "        # Procesar tweet original\n",
    "        fuentes = [tweet.get('analysis')]\n",
    "        # A√±adir replies\n",
    "        fuentes += [r.get('analysis') for r in tweet.get('replies', []) if isinstance(r, dict) and 'analysis' in r]\n",
    "\n",
    "        for fuente in fuentes:\n",
    "            if not isinstance(fuente, dict):\n",
    "                continue\n",
    "\n",
    "            hate = fuente.get('hate')\n",
    "            hate_score = hate.get('score') if isinstance(hate, dict) else None\n",
    "\n",
    "            sentiment = fuente.get('sentiment')\n",
    "            sentiment_score = sentiment.get('score') if isinstance(sentiment, dict) else None\n",
    "\n",
    "            emotions_raw = fuente.get('emotions', [])\n",
    "            emotions = {}\n",
    "            if isinstance(emotions_raw, list):\n",
    "                emotions = {\n",
    "                    e['label']: e['score']\n",
    "                    for e in emotions_raw\n",
    "                    if isinstance(e, dict) and 'label' in e and 'score' in e\n",
    "                }\n",
    "\n",
    "            row = {\n",
    "                'gender': gender,\n",
    "                'age': age,\n",
    "                'party': party,\n",
    "                'ideologia': ideologia,\n",
    "                'hate_score': hate_score,\n",
    "                'sentiment_score': sentiment_score,\n",
    "            }\n",
    "            row.update(emotions)\n",
    "            rows.append(row)\n",
    "\n",
    "# === 3. Crear DataFrame ===\n",
    "df = pd.DataFrame(rows)\n",
    "\n",
    "# === 4. Limpiar y categorizar edad ===\n",
    "df = df.dropna(subset=['age'])\n",
    "df['age_group'] = pd.cut(df['age'], bins=[0, 40, 100], labels=['joven', 'mayor'])\n",
    "\n",
    "# === 5. Funci√≥n para calcular d de Cohen ===\n",
    "def cohens_d(x1, x2):\n",
    "    n1, n2 = len(x1), len(x2)\n",
    "    s1, s2 = np.var(x1, ddof=1), np.var(x2, ddof=1)\n",
    "    s_pooled = np.sqrt(((n1 - 1)*s1 + (n2 - 1)*s2) / (n1 + n2 - 2))\n",
    "    return (np.mean(x1) - np.mean(x2)) / s_pooled if s_pooled > 0 else 0.0\n",
    "\n",
    "# === 6. Comparar m√©tricas entre grupos ===\n",
    "metricas = ['hate_score', 'sentiment_score', 'anger', 'joy', 'sadness', 'optimism']\n",
    "grupos = ['gender', 'ideologia', 'age_group']\n",
    "\n",
    "resultados = []\n",
    "\n",
    "for variable_grupo in grupos:\n",
    "    for metrica in metricas:\n",
    "        grupos_unicos = df[variable_grupo].dropna().unique()\n",
    "        if len(grupos_unicos) != 2:\n",
    "            continue\n",
    "\n",
    "        grupo1, grupo2 = grupos_unicos\n",
    "        datos1 = df[df[variable_grupo] == grupo1][metrica].dropna()\n",
    "        datos2 = df[df[variable_grupo] == grupo2][metrica].dropna()\n",
    "\n",
    "        if len(datos1) < 10 or len(datos2) < 10:\n",
    "            continue\n",
    "\n",
    "        d = cohens_d(datos1, datos2)\n",
    "        t_stat, p_value = ttest_ind(datos1, datos2, equal_var=False)\n",
    "\n",
    "        resultados.append({\n",
    "            \"grupo\": variable_grupo,\n",
    "            \"valor\": metrica,\n",
    "            \"grupo_1\": grupo1,\n",
    "            \"grupo_2\": grupo2,\n",
    "            \"d_cohen\": d,\n",
    "            \"t_stat\": t_stat,\n",
    "            \"p_value\": p_value,\n",
    "            \"n1\": len(datos1),\n",
    "            \"n2\": len(datos2)\n",
    "        })\n",
    "\n",
    "# === 7. Guardar resultados ===\n",
    "df_resultados = pd.DataFrame(resultados)\n",
    "df_resultados = df_resultados.sort_values(by='d_cohen', key=lambda x: abs(x), ascending=False)\n",
    "df_resultados.to_csv(\"comparaciones_metricas_espanoles.csv\", index=False, encoding='utf-8')\n",
    "\n",
    "print(\"‚úÖ Resultados guardados en 'comparaciones_metricas_espanoles.csv'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f23edda9-37b7-4ce0-b52a-70895ae2e663",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import ttest_ind\n",
    "# === Funci√≥n para calcular el tama√±o del efecto (Cohen's d) ===\n",
    "def cohens_d(x1, x2):\n",
    "    n1, n2 = len(x1), len(x2)\n",
    "    s1, s2 = np.var(x1, ddof=1), np.var(x2, ddof=1)\n",
    "    s_pooled = np.sqrt(((n1 - 1)*s1 + (n2 - 1)*s2) / (n1 + n2 - 2))\n",
    "    return (np.mean(x1) - np.mean(x2)) / s_pooled if s_pooled > 0 else 0.0\n",
    "\n",
    "# === 1. Cargar archivo JSON ===\n",
    "with open('grecia_anotados/Preprado/Griegos_f.json', 'r', encoding='utf-8') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# === 2. Extraer predicciones y etiquetas humanas ===\n",
    "rows = []\n",
    "for usuario in data:\n",
    "    gender = usuario.get('gender')\n",
    "    age = usuario.get('age')\n",
    "    party = usuario.get('party')\n",
    "    ideologia = usuario.get('polaridad_ideologica')\n",
    "\n",
    "    for tweet in usuario.get('tweets', []):\n",
    "        for reply in [tweet] + tweet.get('replies', []):\n",
    "            if not isinstance(reply, dict):\n",
    "                continue\n",
    "\n",
    "            label_humana = reply.get('label')\n",
    "            if label_humana not in ['-1', '0', '1']:\n",
    "                continue\n",
    "\n",
    "            analysis = reply.get('analysis')\n",
    "            if not isinstance(analysis, dict):\n",
    "                continue\n",
    "\n",
    "            pred_sentiment = analysis.get('sentiment', {}).get('label')\n",
    "            if pred_sentiment not in ['positive', 'neutral', 'negative']:\n",
    "                continue\n",
    "\n",
    "            # Convertimos para comparar: humano (str) -> modelo (str)\n",
    "            mapping_humano = {'-1': 'negative', '0': 'neutral', '1': 'positive'}\n",
    "            label_humana_str = mapping_humano.get(label_humana)\n",
    "\n",
    "            acierto = int(pred_sentiment == label_humana_str)\n",
    "\n",
    "            rows.append({\n",
    "                'gender': gender,\n",
    "                'age': age,\n",
    "                'party': party,\n",
    "                'ideologia': ideologia,\n",
    "                'acierto': acierto\n",
    "            })\n",
    "\n",
    "# === 3. Crear DataFrame ===\n",
    "df = pd.DataFrame(rows)\n",
    "\n",
    "# === 4. Categorizar edad ===\n",
    "df = df.dropna(subset=['age'])\n",
    "df['age_group'] = pd.cut(df['age'], bins=[0, 40, 100], labels=['joven', 'mayor'])\n",
    "\n",
    "# === 5. Comparar tasa de acierto por grupo ===\n",
    "grupos = ['gender', 'ideologia', 'age_group', 'party']\n",
    "resultados = []\n",
    "\n",
    "for variable in grupos:\n",
    "    grupos_unicos = df[variable].dropna().unique()\n",
    "    if len(grupos_unicos) != 2:\n",
    "        continue\n",
    "\n",
    "    g1, g2 = grupos_unicos\n",
    "    acc1 = df[df[variable] == g1]['acierto']\n",
    "    acc2 = df[df[variable] == g2]['acierto']\n",
    "\n",
    "    if len(acc1) < 10 or len(acc2) < 10:\n",
    "        continue\n",
    "\n",
    "    # Diferencia en tasa de acierto\n",
    "    mean1, mean2 = acc1.mean(), acc2.mean()\n",
    "    d = cohens_d(acc1, acc2)\n",
    "    t_stat, p_value = ttest_ind(acc1, acc2, equal_var=False)\n",
    "\n",
    "    resultados.append({\n",
    "        'grupo': variable,\n",
    "        'grupo_1': g1,\n",
    "        'grupo_2': g2,\n",
    "        'acierto_1': mean1,\n",
    "        'acierto_2': mean2,\n",
    "        'diff': mean1 - mean2,\n",
    "        'd_cohen': d,\n",
    "        't_stat': t_stat,\n",
    "        'p_value': p_value,\n",
    "        'n1': len(acc1),\n",
    "        'n2': len(acc2)\n",
    "    })\n",
    "\n",
    "# === 6. Resultados ordenados por magnitud de efecto ===\n",
    "df_resultados = pd.DataFrame(resultados)\n",
    "df_resultados = df_resultados.sort_values(by='d_cohen', key=lambda x: abs(x), ascending=False)\n",
    "\n",
    "# === 7. Guardar como CSV ===\n",
    "df_resultados.to_csv(\"sesgo_modelo_sentimiento.csv\", index=False, encoding='utf-8')\n",
    "print(\"‚úÖ Resultados guardados en 'sesgo_modelo_sentimiento.csv'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "64ada2fa-f042-4101-95f9-2d2a7a6b19d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Resultados guardados en 'comparaciones_britanicos.csv'\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import ttest_ind\n",
    "\n",
    "# === 1. Cargar archivo JSON con estructura por nombre de pol√≠tico ===\n",
    "with open('ingleses/fusion_final_con_odio_y_stanza.json', 'r', encoding='utf-8') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# === 2. Extraer datos de tweets y replies con m√©tricas y atributos del autor ===\n",
    "rows = []\n",
    "for nombre, info in data.items():\n",
    "    gender = info.get('Genero')\n",
    "    age = info.get('Edad')\n",
    "    party = info.get('mp_party')\n",
    "    ideologia = info.get('Izquierda/Derecha')\n",
    "    etnia = info.get('Etnia')\n",
    "\n",
    "    for tweet in info.get('tweets', []):\n",
    "        fuentes = [tweet] + tweet.get('replies', [])\n",
    "\n",
    "        for fuente in fuentes:\n",
    "            if not isinstance(fuente, dict):\n",
    "                continue\n",
    "\n",
    "            row = {\n",
    "                'gender': gender,\n",
    "                'age': age,\n",
    "                'party': party,\n",
    "                'ideologia': ideologia,\n",
    "                'etnia': etnia,\n",
    "                'hate_score': fuente.get('hate_score'),\n",
    "                'sentiment_score': fuente.get('sentiment_score'),\n",
    "            }\n",
    "\n",
    "            # A√±adir emociones espec√≠ficas si est√°n presentes\n",
    "            emotion_label = fuente.get('emotion_label')\n",
    "            emotion_score = fuente.get('emotion_score')\n",
    "\n",
    "            if emotion_label in ['joy', 'anger', 'sadness', 'optimism']:\n",
    "                row[emotion_label] = emotion_score\n",
    "\n",
    "            rows.append(row)\n",
    "\n",
    "# === 3. Crear DataFrame ===\n",
    "df = pd.DataFrame(rows)\n",
    "\n",
    "# === 4. Categorizar edad ===\n",
    "df = df.dropna(subset=['age'])\n",
    "df['age_group'] = pd.cut(df['age'], bins=[0, 40, 100], labels=['joven', 'mayor'])\n",
    "\n",
    "# === 5. Funci√≥n para calcular d de Cohen ===\n",
    "def cohens_d(x1, x2):\n",
    "    n1, n2 = len(x1), len(x2)\n",
    "    s1, s2 = np.var(x1, ddof=1), np.var(x2, ddof=1)\n",
    "    s_pooled = np.sqrt(((n1 - 1)*s1 + (n2 - 1)*s2) / (n1 + n2 - 2))\n",
    "    return (np.mean(x1) - np.mean(x2)) / s_pooled\n",
    "\n",
    "# === 6. Comparar m√©tricas entre grupos ===\n",
    "metricas = ['hate_score', 'sentiment_score', 'anger', 'joy', 'sadness', 'optimism']\n",
    "grupos = ['gender', 'ideologia', 'age_group']\n",
    "\n",
    "resultados = []\n",
    "\n",
    "for variable_grupo in grupos:\n",
    "    for metrica in metricas:\n",
    "        grupos_unicos = df[variable_grupo].dropna().unique()\n",
    "        if len(grupos_unicos) != 2:\n",
    "            continue\n",
    "\n",
    "        grupo1, grupo2 = grupos_unicos\n",
    "        datos1 = df[df[variable_grupo] == grupo1][metrica].dropna()\n",
    "        datos2 = df[df[variable_grupo] == grupo2][metrica].dropna()\n",
    "\n",
    "        if len(datos1) < 10 or len(datos2) < 10:\n",
    "            continue\n",
    "\n",
    "        d = cohens_d(datos1, datos2)\n",
    "        t_stat, p_value = ttest_ind(datos1, datos2, equal_var=False)\n",
    "\n",
    "        resultados.append({\n",
    "            \"grupo\": variable_grupo,\n",
    "            \"valor\": metrica,\n",
    "            \"grupo_1\": grupo1,\n",
    "            \"grupo_2\": grupo2,\n",
    "            \"d_cohen\": d,\n",
    "            \"t_stat\": t_stat,\n",
    "            \"p_value\": p_value,\n",
    "            \"n1\": len(datos1),\n",
    "            \"n2\": len(datos2)\n",
    "        })\n",
    "\n",
    "# === 7. Guardar resultados ===\n",
    "df_resultados = pd.DataFrame(resultados)\n",
    "df_resultados = df_resultados.sort_values(by='d_cohen', key=lambda x: abs(x), ascending=False)\n",
    "df_resultados.to_csv(\"comparaciones_britanicos.csv\", index=False, encoding='utf-8')\n",
    "print(\"‚úÖ Resultados guardados en 'comparaciones_britanicos.csv'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "81327c7f-a7d3-4ff7-884a-b9e5e4a39ee6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Resultados guardados en 'sesgo_modelo_sentimiento_espanoles.csv'\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import ttest_ind\n",
    "\n",
    "# === Funci√≥n para calcular el tama√±o del efecto (Cohen's d) ===\n",
    "def cohens_d(x1, x2):\n",
    "    n1, n2 = len(x1), len(x2)\n",
    "    s1, s2 = np.var(x1, ddof=1), np.var(x2, ddof=1)\n",
    "    s_pooled = np.sqrt(((n1 - 1)*s1 + (n2 - 1)*s2) / (n1 + n2 - 2))\n",
    "    return (np.mean(x1) - np.mean(x2)) / s_pooled if s_pooled > 0 else 0.0\n",
    "\n",
    "# === 1. Cargar archivo JSON ===\n",
    "with open('spain/Completado/Spain_Completo.json', 'r', encoding='utf-8') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# === 2. Extraer predicciones y etiquetas humanas ===\n",
    "rows = []\n",
    "for usuario in data:\n",
    "    gender = usuario.get('gender')\n",
    "    age = usuario.get('age')\n",
    "    party = usuario.get('party')\n",
    "    ideologia = usuario.get('ideologia')  # si est√° disponible\n",
    "\n",
    "    for tweet in usuario.get('tweets', []):\n",
    "        # Elegimos tweet original + replies\n",
    "        for fuente in [tweet] + tweet.get('replies', []):\n",
    "            if not isinstance(fuente, dict):\n",
    "                continue\n",
    "\n",
    "            # Etiqueta humana de sentimiento\n",
    "            label_humana = fuente.get('annotations', {}).get('Total')\n",
    "            if label_humana not in [-1, 0, 1, -1.0, 0.0, 1.0]:\n",
    "                continue\n",
    "\n",
    "            # Etiqueta del modelo\n",
    "            analysis = fuente.get('analysis')\n",
    "            if not isinstance(analysis, dict):\n",
    "                continue\n",
    "\n",
    "            pred_sentiment = analysis.get('sentiment', {}).get('label')\n",
    "            if pred_sentiment not in ['positive', 'neutral', 'negative']:\n",
    "                continue\n",
    "\n",
    "            # Convertimos la etiqueta humana a texto para comparar\n",
    "            mapping = {-1: 'negative', 0: 'neutral', 1: 'positive'}\n",
    "            label_humana_str = mapping.get(int(label_humana))\n",
    "\n",
    "            acierto = int(pred_sentiment == label_humana_str)\n",
    "\n",
    "            rows.append({\n",
    "                'gender': gender,\n",
    "                'age': age,\n",
    "                'party': party,\n",
    "                'ideologia': ideologia,\n",
    "                'acierto': acierto\n",
    "            })\n",
    "\n",
    "# === 3. Crear DataFrame ===\n",
    "df = pd.DataFrame(rows)\n",
    "\n",
    "# === 4. Categorizar edad ===\n",
    "df = df.dropna(subset=['age'])\n",
    "df['age_group'] = pd.cut(df['age'], bins=[0, 40, 100], labels=['joven', 'mayor'])\n",
    "\n",
    "# === 5. Comparar tasa de acierto por grupo ===\n",
    "grupos = ['gender', 'ideologia', 'age_group', 'party']\n",
    "resultados = []\n",
    "\n",
    "for variable in grupos:\n",
    "    grupos_unicos = df[variable].dropna().unique()\n",
    "    if len(grupos_unicos) != 2:\n",
    "        continue\n",
    "\n",
    "    g1, g2 = grupos_unicos\n",
    "    acc1 = df[df[variable] == g1]['acierto']\n",
    "    acc2 = df[df[variable] == g2]['acierto']\n",
    "\n",
    "    if len(acc1) < 10 or len(acc2) < 10:\n",
    "        continue\n",
    "\n",
    "    mean1, mean2 = acc1.mean(), acc2.mean()\n",
    "    d = cohens_d(acc1, acc2)\n",
    "    t_stat, p_value = ttest_ind(acc1, acc2, equal_var=False)\n",
    "\n",
    "    resultados.append({\n",
    "        'grupo': variable,\n",
    "        'grupo_1': g1,\n",
    "        'grupo_2': g2,\n",
    "        'acierto_1': mean1,\n",
    "        'acierto_2': mean2,\n",
    "        'diff': mean1 - mean2,\n",
    "        'd_cohen': d,\n",
    "        't_stat': t_stat,\n",
    "        'p_value': p_value,\n",
    "        'n1': len(acc1),\n",
    "        'n2': len(acc2)\n",
    "    })\n",
    "\n",
    "# === 6. Resultados ordenados ===\n",
    "df_resultados = pd.DataFrame(resultados)\n",
    "df_resultados = df_resultados.sort_values(by='d_cohen', key=lambda x: abs(x), ascending=False)\n",
    "\n",
    "# === 7. Guardar resultados ===\n",
    "df_resultados.to_csv(\"sesgo_modelo_sentimiento_espanoles.csv\", index=False, encoding='utf-8')\n",
    "print(\"‚úÖ Resultados guardados en 'sesgo_modelo_sentimiento_espanoles.csv'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c417c617-8ae3-47c5-9300-dbafe9c72096",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Excel generado como 'resumen_politicos_espanoles.xlsx'\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "# === 1. Cargar archivo JSON ===\n",
    "with open(\"spain/Completado/Spain_Completo.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# === 2. Extraer datos de cada pol√≠tico ===\n",
    "rows = []\n",
    "for politico in data:\n",
    "    gender = politico.get(\"gender\")\n",
    "    age = politico.get(\"age\")\n",
    "    party = politico.get(\"party\")\n",
    "    ideologia = politico.get(\"ideologia\")\n",
    "    rows.append({\n",
    "        \"gender\": gender,\n",
    "        \"age\": age,\n",
    "        \"party\": party,\n",
    "        \"ideologia\": ideologia\n",
    "    })\n",
    "\n",
    "df = pd.DataFrame(rows)\n",
    "\n",
    "# === 3. Crear resumen ===\n",
    "resumen = {\n",
    "    \"Total de pol√≠ticos\": [len(df)],\n",
    "    \"N√∫mero de hombres\": [df['gender'].str.lower().eq(\"masculino\").sum()],\n",
    "    \"N√∫mero de mujeres\": [df['gender'].str.lower().eq(\"femenino\").sum()]\n",
    "}\n",
    "df_resumen = pd.DataFrame(resumen)\n",
    "\n",
    "# === 4. Distribuci√≥n por partido e ideolog√≠a ===\n",
    "dist_partido = df['party'].value_counts().rename_axis('partido').reset_index(name='n_politicos')\n",
    "dist_ideologia = df['ideologia'].value_counts().rename_axis('ideologia').reset_index(name='n_politicos')\n",
    "\n",
    "# === 5. Guardar todo en un archivo Excel con varias hojas ===\n",
    "with pd.ExcelWriter(\"resumen_politicos_espanoles.xlsx\") as writer:\n",
    "    df_resumen.to_excel(writer, sheet_name=\"Resumen General\", index=False)\n",
    "    dist_partido.to_excel(writer, sheet_name=\"Por Partido\", index=False)\n",
    "    dist_ideologia.to_excel(writer, sheet_name=\"Por Ideolog√≠a\", index=False)\n",
    "\n",
    "print(\"‚úÖ Excel generado como 'resumen_politicos_espanoles.xlsx'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1d10b231-6bc3-439f-b7bb-91bbbfd0755e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Resultados guardados en 'sesgo_modelo_sentimiento_estructura_nueva.csv'\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import ttest_ind\n",
    "\n",
    "# === Funci√≥n para calcular el tama√±o del efecto (Cohen's d) ===\n",
    "def cohens_d(x1, x2):\n",
    "    n1, n2 = len(x1), len(x2)\n",
    "    s1, s2 = np.var(x1, ddof=1), np.var(x2, ddof=1)\n",
    "    s_pooled = np.sqrt(((n1 - 1)*s1 + (n2 - 1)*s2) / (n1 + n2 - 2))\n",
    "    return (np.mean(x1) - np.mean(x2)) / s_pooled if s_pooled > 0 else 0.0\n",
    "\n",
    "# === 1. Cargar archivo JSON ===\n",
    "with open('ingleses/Ingleses_Completo.json', 'r', encoding='utf-8') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# === 2. Extraer predicciones comparadas con etiqueta humana ===\n",
    "rows = []\n",
    "for tweet in data:\n",
    "    mp = tweet.get(\"mp\", {})\n",
    "    gender = mp.get(\"genero\")\n",
    "    age = mp.get(\"edad\")\n",
    "    party = mp.get(\"party\")\n",
    "    ideologia = mp.get(\"ideologia\")\n",
    "    pais = mp.get(\"pais\")\n",
    "    etnia = mp.get(\"etnia\")\n",
    "\n",
    "    acierto = tweet.get(\"match_sentiment_label\")\n",
    "    if isinstance(acierto, bool):\n",
    "        rows.append({\n",
    "            'gender': gender,\n",
    "            'age': age,\n",
    "            'party': party,\n",
    "            'ideologia': ideologia,\n",
    "            'pais': pais,\n",
    "            'etnia': etnia,\n",
    "            'acierto': int(acierto)  # convertir a 1 (True) o 0 (False)\n",
    "        })\n",
    "\n",
    "# === 3. Crear DataFrame ===\n",
    "df = pd.DataFrame(rows)\n",
    "\n",
    "# === 4. Categorizar edad ===\n",
    "df = df.dropna(subset=['age'])\n",
    "df['age_group'] = pd.cut(df['age'], bins=[0, 40, 100], labels=['joven', 'mayor'])\n",
    "\n",
    "# === 5. Comparar tasa de acierto por grupo ===\n",
    "grupos = ['gender', 'ideologia', 'age_group', 'party', 'etnia']\n",
    "resultados = []\n",
    "\n",
    "for variable in grupos:\n",
    "    grupos_unicos = df[variable].dropna().unique()\n",
    "    if len(grupos_unicos) != 2:\n",
    "        continue  # solo comparar si hay dos grupos\n",
    "\n",
    "    g1, g2 = grupos_unicos\n",
    "    acc1 = df[df[variable] == g1]['acierto']\n",
    "    acc2 = df[df[variable] == g2]['acierto']\n",
    "\n",
    "    if len(acc1) < 10 or len(acc2) < 10:\n",
    "        continue\n",
    "\n",
    "    mean1, mean2 = acc1.mean(), acc2.mean()\n",
    "    d = cohens_d(acc1, acc2)\n",
    "    t_stat, p_value = ttest_ind(acc1, acc2, equal_var=False)\n",
    "\n",
    "    resultados.append({\n",
    "        'grupo': variable,\n",
    "        'grupo_1': g1,\n",
    "        'grupo_2': g2,\n",
    "        'acierto_1': mean1,\n",
    "        'acierto_2': mean2,\n",
    "        'diff': mean1 - mean2,\n",
    "        'd_cohen': d,\n",
    "        't_stat': t_stat,\n",
    "        'p_value': p_value,\n",
    "        'n1': len(acc1),\n",
    "        'n2': len(acc2)\n",
    "    })\n",
    "\n",
    "# === 6. Resultados ordenados ===\n",
    "df_resultados = pd.DataFrame(resultados)\n",
    "df_resultados = df_resultados.sort_values(by='d_cohen', key=lambda x: abs(x), ascending=False)\n",
    "\n",
    "# === 7. Guardar resultados ===\n",
    "df_resultados.to_csv(\"sesgo_modelo_sentimiento_estructura_nueva.csv\", index=False, encoding='utf-8')\n",
    "print(\"‚úÖ Resultados guardados en 'sesgo_modelo_sentimiento_estructura_nueva.csv'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "550a8e87-61ca-487d-9377-9017e60c4d6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting ace_tools\n",
      "  Downloading ace_tools-0.0-py3-none-any.whl.metadata (300 bytes)\n",
      "Downloading ace_tools-0.0-py3-none-any.whl (1.1 kB)\n",
      "Installing collected packages: ace_tools\n",
      "Successfully installed ace_tools-0.0\n"
     ]
    }
   ],
   "source": [
    "!pip install ace_tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "be76ab94-dbd0-446b-888e-60dda42fe526",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Resultados guardados como:\n",
      "- tasas_acierto_genero.csv\n",
      "- tasas_acierto_ideologia.csv\n",
      "- tasas_acierto_edad.csv\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "# Cargar datos\n",
    "with open('tweets_fusionados_ideologia.json', 'r', encoding='utf-8') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# Recolectar datos de tweets originales con anotaci√≥n\n",
    "rows = []\n",
    "for usuario in data:\n",
    "    gender = usuario['gender']\n",
    "    age = usuario['age']\n",
    "    party = usuario['party']\n",
    "    ideologia = usuario['ideologia']\n",
    "    age_group = 'joven' if age is not None and age <= 40 else 'mayor' if age is not None else None\n",
    "\n",
    "    for tweet in usuario['tweets']:\n",
    "        annotations = tweet.get('annotations', {})\n",
    "        total = annotations.get('Total')\n",
    "        if total is None:\n",
    "            continue\n",
    "\n",
    "        # IA 1: Cardiff (sentiment.label)\n",
    "        sentiment_label = tweet['analysis'].get('sentiment', {}).get('label')\n",
    "\n",
    "        # IA 2: Stanza (int: -1, 0, 1)\n",
    "        sentiment_stanza = tweet['analysis'].get('sentiment_stanza')\n",
    "\n",
    "        # Convertir label de texto a n√∫mero\n",
    "        label_map = {'negative': -1, 'neutral': 0, 'positive': 1}\n",
    "        sentiment_cardiff = label_map.get(sentiment_label)\n",
    "\n",
    "        row = {\n",
    "            \"gender\": gender,\n",
    "            \"age_group\": age_group,\n",
    "            \"ideologia\": ideologia,\n",
    "            \"Total\": total,\n",
    "            \"Cardiff\": sentiment_cardiff,\n",
    "            \"Stanza\": sentiment_stanza\n",
    "        }\n",
    "        rows.append(row)\n",
    "\n",
    "# Crear DataFrame\n",
    "df = pd.DataFrame(rows)\n",
    "\n",
    "# Comparar predicciones con etiqueta humana\n",
    "df['acierto_cardiff'] = df['Cardiff'] == df['Total']\n",
    "df['acierto_stanza'] = df['Stanza'] == df['Total']\n",
    "\n",
    "# Agrupar por atributo y calcular tasa de acierto\n",
    "def tasas_acierto_por(variable):\n",
    "    resumen = df.groupby(variable)[['acierto_cardiff', 'acierto_stanza']].mean() * 100\n",
    "    resumen = resumen.rename(columns={\n",
    "        'acierto_cardiff': 'Cardiff (%)',\n",
    "        'acierto_stanza': 'Stanza (%)'\n",
    "    })\n",
    "    return resumen.round(2)\n",
    "\n",
    "# Calcular tasas\n",
    "tasas_por_genero = tasas_acierto_por('gender')\n",
    "tasas_por_ideologia = tasas_acierto_por('ideologia')\n",
    "tasas_por_edad = tasas_acierto_por('age_group')\n",
    "\n",
    "# Guardar a CSV\n",
    "tasas_por_genero.to_csv('tasas_acierto_genero.csv')\n",
    "tasas_por_ideologia.to_csv('tasas_acierto_ideologia.csv')\n",
    "tasas_por_edad.to_csv('tasas_acierto_edad.csv')\n",
    "\n",
    "print(\"‚úÖ Resultados guardados como:\")\n",
    "print(\"- tasas_acierto_genero.csv\")\n",
    "print(\"- tasas_acierto_ideologia.csv\")\n",
    "print(\"- tasas_acierto_edad.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "27ac9ae1-74bd-4117-97e3-0cdd4bc2d5d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Tweets agrupados y completados con datos auxiliares. Guardado como 'tweets_agrupados_completos.json'\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from collections import defaultdict\n",
    "\n",
    "# === 1. Cargar los archivos ===\n",
    "with open(\"tweets_1_giregos.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    tweets_data = json.load(f)\n",
    "\n",
    "with open(\"bloque_1_20_politicos.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    usuarios_extra = json.load(f)\n",
    "\n",
    "# === 2. Crear √≠ndice auxiliar con b√∫squeda flexible ===\n",
    "def buscar_info_extra(nombre):\n",
    "    for entry in usuarios_extra:\n",
    "        if nombre in entry['name']:\n",
    "            return entry\n",
    "    return {}\n",
    "\n",
    "# === 3. Agrupar tweets por usuario ===\n",
    "agrupados = defaultdict(lambda: {\n",
    "    \"name\": None,\n",
    "    \"age\": None,\n",
    "    \"gender\": None,\n",
    "    \"party\": None,\n",
    "    \"tweets\": []\n",
    "})\n",
    "\n",
    "for tweet in tweets_data:\n",
    "    nombre = tweet.get('name')\n",
    "    partido = tweet.get('party')\n",
    "    clave = (nombre, partido)\n",
    "\n",
    "    # Buscar datos extra si faltan\n",
    "    extra_info = buscar_info_extra(nombre)\n",
    "\n",
    "    age = tweet.get(\"age\") or extra_info.get(\"age\")\n",
    "    gender = tweet.get(\"gender\") or extra_info.get(\"gender\")\n",
    "    party = tweet.get(\"party\") or extra_info.get(\"party\")\n",
    "\n",
    "    # Asignar datos del usuario\n",
    "    usuario = agrupados[clave]\n",
    "    usuario[\"name\"] = nombre\n",
    "    usuario[\"age\"] = age if age is not None else None\n",
    "    usuario[\"gender\"] = gender if gender is not None else None\n",
    "    usuario[\"party\"] = party if party is not None else None\n",
    "\n",
    "    # Agregar tweet con toda su estructura\n",
    "    tweet_info = {\n",
    "        \"id\": tweet.get(\"id\"),\n",
    "        \"user\": tweet.get(\"user\"),\n",
    "        \"tweet\": tweet.get(\"tweet\"),\n",
    "        \"label\": tweet.get(\"label\"),\n",
    "        \"annotator\": tweet.get(\"annotator\"),\n",
    "        \"analysis\": tweet.get(\"analysis\"),\n",
    "        \"replies\": tweet.get(\"replies\")\n",
    "    }\n",
    "\n",
    "    usuario[\"tweets\"].append(tweet_info)\n",
    "\n",
    "# === 4. Convertir a lista final y guardar ===\n",
    "resultado = list(agrupados.values())\n",
    "\n",
    "with open(\"tweets_agrupados_completos.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(resultado, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "print(\"‚úÖ Tweets agrupados y completados con datos auxiliares. Guardado como 'tweets_agrupados_completos.json'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "59671d29-16b0-45c1-9b90-d86ad1abbc12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä TOTALES GENERALES:\n",
      "- Total de usuarios: 168\n",
      "- Total de tweets: 959\n",
      "- Total de replies: 2328\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Cargar archivo\n",
    "with open(\"grecia_anotados/Preprado/tweets_agrupados_completos_final.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    usuarios = json.load(f)\n",
    "\n",
    "# Contar totales\n",
    "total_usuarios = len(usuarios)\n",
    "total_tweets = sum(len(u.get(\"tweets\", [])) for u in usuarios)\n",
    "total_replies = sum(len(t.get(\"replies\", [])) for u in usuarios for t in u.get(\"tweets\", []))\n",
    "\n",
    "# Mostrar resultados\n",
    "print(\"üìä TOTALES GENERALES:\")\n",
    "print(f\"- Total de usuarios: {total_usuarios}\")\n",
    "print(f\"- Total de tweets: {total_tweets}\")\n",
    "print(f\"- Total de replies: {total_replies}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e16f7e2d-ac16-4dd8-9e24-0b498ea97949",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Eliminados 41 usuarios con nombre err√≥neo.\n",
      "üìÅ Archivo limpio guardado como 'tweets_agrupados_sin_errores.json'\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Cargar archivo original\n",
    "with open(\"tweets_agrupados_completos.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    usuarios = json.load(f)\n",
    "\n",
    "# Filtrar usuarios v√°lidos\n",
    "usuarios_limpios = [\n",
    "    u for u in usuarios\n",
    "    if not (isinstance(u.get(\"name\"), str) and u[\"name\"].startswith(\"Error al extraer usuario\"))\n",
    "]\n",
    "\n",
    "# Guardar archivo limpio\n",
    "with open(\"tweets_agrupados_sin_errores.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(usuarios_limpios, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "print(f\"‚úÖ Eliminados {len(usuarios) - len(usuarios_limpios)} usuarios con nombre err√≥neo.\")\n",
    "print(\"üìÅ Archivo limpio guardado como 'tweets_agrupados_sin_errores.json'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "76825364-5cf2-431f-8d36-2201742c97ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Archivo actualizado guardado como 'tweets_agrupados_completos_final.json'\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "# === 1. Cargar usuarios con metadatos corregidos desde Excel ===\n",
    "df_corr = pd.read_excel(\"usuarios_incompletos_completados_updated.xlsx\")\n",
    "\n",
    "# Normalizar los nombres para buscar por inclusi√≥n parcial\n",
    "usuarios_corr = []\n",
    "for _, row in df_corr.iterrows():\n",
    "    usuarios_corr.append({\n",
    "        \"name\": str(row[\"name\"]).strip().lower(),\n",
    "        \"age\": row.get(\"age\"),\n",
    "        \"gender\": row.get(\"gender\"),\n",
    "        \"party\": row.get(\"party\")\n",
    "    })\n",
    "\n",
    "# === 2. Cargar el archivo JSON original de tweets agrupados ===\n",
    "with open(\"tweets_agrupados_sin_errores.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    datos = json.load(f)\n",
    "\n",
    "# === 3. Funci√≥n para buscar en lista de usuarios corregidos ===\n",
    "def buscar_metadata(nombre):\n",
    "    nombre = nombre.strip().lower()\n",
    "    for u in usuarios_corr:\n",
    "        if nombre in u[\"name\"] or u[\"name\"] in nombre:\n",
    "            return u\n",
    "    return {}\n",
    "\n",
    "# === 4. Completar los campos que est√©n a None ===\n",
    "for usuario in datos:\n",
    "    if usuario.get(\"age\") is None or usuario.get(\"gender\") is None or usuario.get(\"party\") is None:\n",
    "        info = buscar_metadata(usuario[\"name\"])\n",
    "        if usuario.get(\"age\") is None:\n",
    "            usuario[\"age\"] = info.get(\"age\")\n",
    "        if usuario.get(\"gender\") is None:\n",
    "            usuario[\"gender\"] = info.get(\"gender\")\n",
    "        if usuario.get(\"party\") is None:\n",
    "            usuario[\"party\"] = info.get(\"party\")\n",
    "\n",
    "# === 5. Guardar el nuevo JSON completo ===\n",
    "with open(\"tweets_agrupados_completos_final.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(datos, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "print(\"‚úÖ Archivo actualizado guardado como 'tweets_agrupados_completos_final.json'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1830ffbc-9d45-4fda-a5f6-8fec1c938123",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "# Cargar el archivo limpio y agrupado\n",
    "with open('tweets_agrupados_sin_errores.json', 'r', encoding='utf-8') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# Recolectar datos de tweets originales con anotaci√≥n\n",
    "rows = []\n",
    "for usuario in data:\n",
    "    gender = usuario.get('gender')\n",
    "    age = usuario.get('age')\n",
    "    party = usuario.get('party')\n",
    "    age_group = 'joven' if age is not None and age <= 40 else 'mayor' if age is not None else None\n",
    "\n",
    "    for tweet in usuario.get('tweets', []):\n",
    "        annotations = tweet.get('annotations', {})\n",
    "        total = annotations.get('Total')\n",
    "        if total is None:\n",
    "            continue\n",
    "\n",
    "        # IA 1: Cardiff (sentiment.label)\n",
    "        sentiment_label = tweet['analysis'].get('sentiment', {}).get('label')\n",
    "\n",
    "        # IA 2: Stanza (int: -1, 0, 1)\n",
    "\n",
    "        # Convertir label de texto a n√∫mero\n",
    "        label_map = {'negative': -1, 'neutral': 0, 'positive': 1}\n",
    "        sentiment_cardiff = label_map.get(sentiment_label)\n",
    "\n",
    "        row = {\n",
    "            \"gender\": gender,\n",
    "            \"age_group\": age_group,\n",
    "            \"party\": party,\n",
    "            \"Total\": total,\n",
    "            \"Cardiff\": sentiment_cardiff,\n",
    "        }\n",
    "        rows.append(row)\n",
    "\n",
    "# Crear DataFrame\n",
    "df = pd.DataFrame(rows)\n",
    "\n",
    "# Comparar predicciones con etiqueta humana\n",
    "df['acierto_cardiff'] = df['Cardiff'] == df['Total']\n",
    "\n",
    "# Agrupar por atributo y calcular tasa de acierto\n",
    "def tasas_acierto_por(variable):\n",
    "    resumen = df.groupby(variable)[['acierto_cardiff', 'acierto_stanza']].mean() * 100\n",
    "    resumen = resumen.rename(columns={\n",
    "        'acierto_cardiff': 'Cardiff (%)',\n",
    "        'acierto_stanza': 'Stanza (%)'\n",
    "    })\n",
    "    return resumen.round(2)\n",
    "\n",
    "# Calcular tasas\n",
    "tasas_por_genero = tasas_acierto_por('gender')\n",
    "tasas_por_partido = tasas_acierto_por('party')\n",
    "tasas_por_edad = tasas_acierto_por('age_group')\n",
    "\n",
    "# Guardar a CSV\n",
    "tasas_por_genero.to_csv('tasas_acierto_genero.csv')\n",
    "tasas_por_partido.to_csv('tasas_acierto_partido.csv')\n",
    "tasas_por_edad.to_csv('tasas_acierto_edad.csv')\n",
    "\n",
    "print(\"‚úÖ Resultados guardados como:\")\n",
    "print(\"- tasas_acierto_genero.csv\")\n",
    "print(\"- tasas_acierto_partido.csv\")\n",
    "print(\"- tasas_acierto_edad.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c393fe41-4840-4184-84c8-a762e4c11643",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-06 10:47:18 INFO: Checking for updates to resources.json in case models have been updated.  Note: this behavior can be turned off with download_method=None or download_method=DownloadMethod.REUSE_RESOURCES\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7cf92ba3921e4280b4984bd890d513d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.10.0.json:   0%|  ‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-06 10:47:18 INFO: Downloaded file to /home/jupyter-lquijano/stanza_resources/resources.json\n",
      "2025-05-06 10:47:18 WARNING: Language es package default expects mwt, which has been added\n",
      "2025-05-06 10:47:19 INFO: Loading these models for language: es (Spanish):\n",
      "===============================\n",
      "| Processor | Package         |\n",
      "-------------------------------\n",
      "| tokenize  | combined        |\n",
      "| mwt       | combined        |\n",
      "| pos       | combined_charlm |\n",
      "===============================\n",
      "\n",
      "2025-05-06 10:47:19 INFO: Using device: cuda\n",
      "2025-05-06 10:47:19 INFO: Loading: tokenize\n",
      "2025-05-06 10:47:19 INFO: Loading: mwt\n",
      "2025-05-06 10:47:19 INFO: Loading: pos\n",
      "2025-05-06 10:47:20 INFO: Done loading processors!\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import stanza\n",
    "\n",
    "# Carga el pipeline en espa√±ol\n",
    "nlp = stanza.Pipeline(lang='es', processors='tokenize,pos', tokenize_pretokenized=False)\n",
    "\n",
    "# Lista de etiquetas POS irrelevantes que queremos eliminar\n",
    "irrelevant_pos = {\"DET\", \"ADP\", \"PUNCT\", \"CCONJ\", \"SCONJ\", \"PART\"}\n",
    "\n",
    "def get_filtered_pos(text):\n",
    "    doc = nlp(text)\n",
    "    pos_tags = []\n",
    "    for sentence in doc.sentences:\n",
    "        for word in sentence.words:\n",
    "            if word.upos not in irrelevant_pos:\n",
    "                pos_tags.append(word.upos)\n",
    "    return pos_tags\n",
    "\n",
    "# Carga tus datos (por ejemplo desde un archivo JSON)\n",
    "with open(\"spain/Completado/Spain_Completo.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# Procesa cada tweet y sus replies\n",
    "for person in data:\n",
    "    for tweet in person[\"tweets\"]:\n",
    "        tweet[\"filtered_pos_tags\"] = get_filtered_pos(tweet[\"tweet\"])\n",
    "        for reply in tweet.get(\"replies\", []):\n",
    "            reply[\"filtered_pos_tags\"] = get_filtered_pos(reply[\"reply\"])\n",
    "\n",
    "# Guarda el archivo con las nuevas etiquetas POS filtradas\n",
    "with open(\"datos_filtrados.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(data, f, ensure_ascii=False, indent=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b083ad60-67b8-4e48-8978-4fee3b0dcb5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a24f59f7de4c4a65b4c4c36471c9dda4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.10.0.json:   0%|  ‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-06 11:09:00 INFO: Downloaded file to /home/jupyter-lquijano/stanza_resources/resources.json\n",
      "2025-05-06 11:09:00 INFO: Downloading default packages for language: en (English) ...\n",
      "2025-05-06 11:09:01 INFO: File exists: /home/jupyter-lquijano/stanza_resources/en/default.zip\n",
      "2025-05-06 11:09:04 INFO: Finished downloading models and saved to /home/jupyter-lquijano/stanza_resources\n",
      "2025-05-06 11:09:04 INFO: Checking for updates to resources.json in case models have been updated.  Note: this behavior can be turned off with download_method=None or download_method=DownloadMethod.REUSE_RESOURCES\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c37aa06c365343dda3246b948f997ffc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.10.0.json:   0%|  ‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-06 11:09:04 INFO: Downloaded file to /home/jupyter-lquijano/stanza_resources/resources.json\n",
      "2025-05-06 11:09:04 WARNING: Language en package default expects mwt, which has been added\n",
      "2025-05-06 11:09:05 INFO: Loading these models for language: en (English):\n",
      "===============================\n",
      "| Processor | Package         |\n",
      "-------------------------------\n",
      "| tokenize  | combined        |\n",
      "| mwt       | combined        |\n",
      "| pos       | combined_charlm |\n",
      "===============================\n",
      "\n",
      "2025-05-06 11:09:05 INFO: Using device: cuda\n",
      "2025-05-06 11:09:05 INFO: Loading: tokenize\n",
      "2025-05-06 11:09:05 INFO: Loading: mwt\n",
      "2025-05-06 11:09:05 INFO: Loading: pos\n",
      "2025-05-06 11:09:06 INFO: Done loading processors!\n"
     ]
    }
   ],
   "source": [
    "import stanza\n",
    "import json\n",
    "\n",
    "# Configura el pipeline de ingl√©s\n",
    "stanza.download(\"en\")\n",
    "nlp = stanza.Pipeline(lang='en', processors='tokenize,pos', tokenize_pretokenized=False)\n",
    "\n",
    "# Etiquetas POS que vamos a filtrar (irrelevantes para an√°lisis sem√°ntico)\n",
    "irrelevant_pos = {\"DET\", \"ADP\", \"PUNCT\", \"CCONJ\", \"SCONJ\", \"PART\", \"SYM\", \"X\"}\n",
    "\n",
    "def get_filtered_pos(text):\n",
    "    doc = nlp(text)\n",
    "    pos_tags = []\n",
    "    for sentence in doc.sentences:\n",
    "        for word in sentence.words:\n",
    "            if word.upos not in irrelevant_pos:\n",
    "                pos_tags.append(word.upos)\n",
    "    return pos_tags\n",
    "\n",
    "# Cargar los datos\n",
    "with open(\"ingleses/Ingleses_Completo.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# Procesar cada entrada del JSON\n",
    "for tweet in data:\n",
    "    tweet[\"filtered_pos_tags\"] = get_filtered_pos(tweet[\"text\"])\n",
    "\n",
    "# Guardar los resultados en un nuevo archivo\n",
    "with open(\"tweets_filtrados_ingleses.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(data, f, indent=2, ensure_ascii=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "52fbc246-2f7d-4e99-9e50-9ee7d5b56dc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Resultados guardados en 'cohens_d_analisis.csv'\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import ttest_ind\n",
    "from collections import defaultdict\n",
    "\n",
    "# Cargar datos\n",
    "with open(\"tweets_filtrados_ingleses.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# Clasificaci√≥n de edad\n",
    "def categorizar_edad(edad):\n",
    "    if edad < 40:\n",
    "        return \"joven\"\n",
    "    elif edad <= 60:\n",
    "        return \"adulto\"\n",
    "    else:\n",
    "        return \"mayor\"\n",
    "\n",
    "# Extraer filas con m√©tricas √∫tiles\n",
    "rows = []\n",
    "for entry in data:\n",
    "    mp = entry[\"mp\"]\n",
    "    pos_tags = entry.get(\"filtered_pos_tags\", [])\n",
    "    total = len(pos_tags)\n",
    "    if total == 0:\n",
    "        continue\n",
    "\n",
    "    row = {\n",
    "        \"pais\": mp.get(\"pais\", \"Unknown\"),\n",
    "        \"genero\": mp.get(\"genero\", \"Unknown\"),\n",
    "        \"etnia\": mp.get(\"etnia\", \"Unknown\"),\n",
    "        \"ideologia\": mp.get(\"ideologia\", \"Unknown\"),\n",
    "        \"party\": mp.get(\"party\", \"Unknown\"),\n",
    "        \"edad_grupo\": categorizar_edad(mp.get(\"edad\", 0)),\n",
    "    }\n",
    "\n",
    "    # POS tags\n",
    "    tag_counts = defaultdict(int)\n",
    "    for tag in pos_tags:\n",
    "        tag_counts[tag] += 1\n",
    "    for tag, count in tag_counts.items():\n",
    "        row[f\"POS_{tag}\"] = count / total  # proporci√≥n\n",
    "\n",
    "    # Emociones y scores\n",
    "    nlp = entry.get(\"nlp\", {})\n",
    "    for key in [\"sentiment_score\", \"hate_score\", \"emotion_score\"]:\n",
    "        val = nlp.get(key)\n",
    "        if val is not None:\n",
    "            row[key] = val\n",
    "    for key in [\"joy\", \"anger\", \"sadness\", \"optimism\"]:\n",
    "        if f\"{key}_score\" in nlp:\n",
    "            row[key] = nlp[f\"{key}_score\"]\n",
    "\n",
    "    rows.append(row)\n",
    "\n",
    "# Crear DataFrame\n",
    "df = pd.DataFrame(rows).fillna(0)\n",
    "\n",
    "# Comparaciones a hacer\n",
    "comparisons = {\n",
    "    \"genero\": [\"Male\", \"Female\"],\n",
    "    \"ideologia\": [\"derecha\", \"izquierda\"],\n",
    "    \"edad_grupo\": [\"joven\", \"mayor\"]\n",
    "}\n",
    "\n",
    "# Variables a comparar\n",
    "metricas = [col for col in df.columns if col.startswith(\"POS_\")] + [\n",
    "    \"joy\", \"anger\", \"sadness\", \"optimism\", \"sentiment_score\", \"hate_score\"\n",
    "]\n",
    "\n",
    "# Funci√≥n de Cohen's d\n",
    "def cohens_d(x1, x2):\n",
    "    n1, n2 = len(x1), len(x2)\n",
    "    s1, s2 = np.var(x1, ddof=1), np.var(x2, ddof=1)\n",
    "    s_pooled = np.sqrt(((n1 - 1)*s1 + (n2 - 1)*s2) / (n1 + n2 - 2))\n",
    "    if s_pooled == 0:\n",
    "        return 0.0\n",
    "    return (np.mean(x1) - np.mean(x2)) / s_pooled\n",
    "\n",
    "# Analizar y guardar resultados\n",
    "resultados = []\n",
    "\n",
    "for grupo, (g1, g2) in comparisons.items():\n",
    "    df1 = df[df[grupo] == g1]\n",
    "    df2 = df[df[grupo] == g2]\n",
    "\n",
    "    for metrica in metricas:\n",
    "        if metrica not in df.columns:\n",
    "            continue\n",
    "\n",
    "        x1 = df1[metrica]\n",
    "        x2 = df2[metrica]\n",
    "\n",
    "        if len(x1) < 10 or len(x2) < 10:\n",
    "            continue\n",
    "\n",
    "        d = cohens_d(x1, x2)\n",
    "        t_stat, p_value = ttest_ind(x1, x2, equal_var=False)\n",
    "\n",
    "        resultados.append({\n",
    "            \"grupo\": grupo,\n",
    "            \"valor\": metrica,\n",
    "            \"grupo_1\": g1,\n",
    "            \"grupo_2\": g2,\n",
    "            \"d_cohen\": d,\n",
    "            \"t_stat\": t_stat,\n",
    "            \"p_value\": p_value,\n",
    "            \"n1\": len(x1),\n",
    "            \"n2\": len(x2)\n",
    "        })\n",
    "\n",
    "# Convertir a DataFrame y guardar\n",
    "df_resultados = pd.DataFrame(resultados)\n",
    "df_resultados.to_csv(\"cohens_d_analisis.csv\", index=False)\n",
    "\n",
    "print(\"‚úÖ Resultados guardados en 'cohens_d_analisis.csv'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "99f191c9-5d3e-43d1-9cea-3fea8c3a092f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ An√°lisis completo. Resultados guardados en 'cohens_d_espanol.csv'\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import ttest_ind\n",
    "from collections import defaultdict\n",
    "\n",
    "# Cargar datos\n",
    "with open(\"datos_filtrados.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# Clasificaci√≥n de edad\n",
    "def categorizar_edad(edad):\n",
    "    if edad < 40:\n",
    "        return \"joven\"\n",
    "    elif edad <= 60:\n",
    "        return \"adulto\"\n",
    "    else:\n",
    "        return \"mayor\"\n",
    "\n",
    "# Extraer datos tweet y replies\n",
    "rows = []\n",
    "\n",
    "for persona in data:\n",
    "    genero = persona.get(\"gender\", \"Unknown\")\n",
    "    edad = persona.get(\"age\", None)\n",
    "    edad_grupo = categorizar_edad(edad) if edad is not None else \"Unknown\"\n",
    "    party = persona.get(\"party\", \"Unknown\")\n",
    "    nombre = persona.get(\"name\", \"Unknown\")\n",
    "    pais = \"esp\"\n",
    "\n",
    "    for tweet in persona.get(\"tweets\", []):\n",
    "        # A√±adir tweet principal\n",
    "        for fuente, pos_tags in [(\"tweet\", tweet.get(\"filtered_pos_tags\", []))] + \\\n",
    "                                 [(\"reply\", reply.get(\"filtered_pos_tags\", [])) for reply in tweet.get(\"replies\", [])]:\n",
    "            total = len(pos_tags)\n",
    "            if total == 0:\n",
    "                continue\n",
    "\n",
    "            tag_counts = defaultdict(int)\n",
    "            for tag in pos_tags:\n",
    "                tag_counts[tag] += 1\n",
    "\n",
    "            row = {\n",
    "                \"pais\": pais,\n",
    "                \"genero\": genero,\n",
    "                \"edad_grupo\": edad_grupo,\n",
    "                \"party\": party,\n",
    "                \"origen\": fuente,\n",
    "                \"nombre\": nombre\n",
    "            }\n",
    "\n",
    "            for tag, count in tag_counts.items():\n",
    "                row[f\"POS_{tag}\"] = count / total\n",
    "\n",
    "            rows.append(row)\n",
    "\n",
    "# Crear DataFrame\n",
    "df = pd.DataFrame(rows).fillna(0)\n",
    "\n",
    "# Definir comparaciones posibles\n",
    "comparisons = {}\n",
    "\n",
    "# G√©nero (si hay suficientes ejemplos)\n",
    "generos = df[\"genero\"].value_counts()\n",
    "if len(generos) >= 2 and all(generos >= 10):\n",
    "    comparisons[\"genero\"] = list(generos.index[:2])\n",
    "\n",
    "# Edad (joven vs mayor)\n",
    "comparisons[\"edad_grupo\"] = [\"joven\", \"mayor\"]\n",
    "\n",
    "# Partido (si hay al menos 2 grupos grandes)\n",
    "partidos = df[\"party\"].value_counts()\n",
    "if len(partidos) >= 2 and all(partidos[:2] >= 10):\n",
    "    comparisons[\"party\"] = list(partidos.index[:2])\n",
    "\n",
    "# Variables a comparar (solo POS)\n",
    "metricas = [col for col in df.columns if col.startswith(\"POS_\")]\n",
    "\n",
    "# Funci√≥n de Cohen's d\n",
    "def cohens_d(x1, x2):\n",
    "    n1, n2 = len(x1), len(x2)\n",
    "    s1, s2 = np.var(x1, ddof=1), np.var(x2, ddof=1)\n",
    "    s_pooled = np.sqrt(((n1 - 1)*s1 + (n2 - 1)*s2) / (n1 + n2 - 2))\n",
    "    if s_pooled == 0:\n",
    "        return 0.0\n",
    "    return (np.mean(x1) - np.mean(x2)) / s_pooled\n",
    "\n",
    "# Ejecutar comparaciones\n",
    "resultados = []\n",
    "\n",
    "for grupo, (g1, g2) in comparisons.items():\n",
    "    df1 = df[df[grupo] == g1]\n",
    "    df2 = df[df[grupo] == g2]\n",
    "\n",
    "    for metrica in metricas:\n",
    "        x1 = df1[metrica]\n",
    "        x2 = df2[metrica]\n",
    "\n",
    "        if len(x1) < 10 or len(x2) < 10:\n",
    "            continue\n",
    "\n",
    "        d = cohens_d(x1, x2)\n",
    "        t_stat, p_value = ttest_ind(x1, x2, equal_var=False)\n",
    "\n",
    "        resultados.append({\n",
    "            \"grupo\": grupo,\n",
    "            \"valor\": metrica,\n",
    "            \"grupo_1\": g1,\n",
    "            \"grupo_2\": g2,\n",
    "            \"d_cohen\": round(d, 5),\n",
    "            \"t_stat\": round(t_stat, 5),\n",
    "            \"p_value\": p_value,\n",
    "            \"n1\": len(x1),\n",
    "            \"n2\": len(x2)\n",
    "        })\n",
    "\n",
    "# Exportar resultados\n",
    "df_resultados = pd.DataFrame(resultados)\n",
    "df_resultados.to_csv(\"cohens_d_espanol.csv\", index=False)\n",
    "\n",
    "print(\"‚úÖ An√°lisis completo. Resultados guardados en 'cohens_d_espanol.csv'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c016fb87-85f8-4eaa-8e46-7a18fac896e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Resultados guardados en 'cohens_d_griegos.csv'\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import ttest_ind\n",
    "\n",
    "# Cargar datos griegos\n",
    "with open(\"grecia_anotados/Preprado/Griegos_f.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# Clasificar edad\n",
    "def categorizar_edad(edad):\n",
    "    if edad < 40:\n",
    "        return \"joven\"\n",
    "    elif edad <= 60:\n",
    "        return \"adulto\"\n",
    "    else:\n",
    "        return \"mayor\"\n",
    "\n",
    "# Extraer tweets y replies con m√©tricas POS\n",
    "rows = []\n",
    "\n",
    "for persona in data:\n",
    "    genero = persona.get(\"gender\", \"Unknown\")\n",
    "    edad = persona.get(\"age\", None)\n",
    "    edad_grupo = categorizar_edad(edad) if edad is not None else \"Unknown\"\n",
    "    partido = persona.get(\"party\", \"Unknown\")\n",
    "    ideologia = persona.get(\"polaridad_ideologica\", \"Unknown\")\n",
    "    nombre = persona.get(\"name\", \"Unknown\")\n",
    "    pais = \"gre\"\n",
    "\n",
    "    for tweet in persona.get(\"tweets\", []):\n",
    "        analysis = tweet.get(\"analysis\", {})\n",
    "        pos = analysis.get(\"pos_features\", {})\n",
    "        if not pos:\n",
    "            continue\n",
    "\n",
    "        row = {\n",
    "            \"pais\": pais,\n",
    "            \"nombre\": nombre,\n",
    "            \"gender\": genero,\n",
    "            \"edad_grupo\": edad_grupo,\n",
    "            \"party\": partido,\n",
    "            \"ideologia\": ideologia,\n",
    "        }\n",
    "\n",
    "        for k, v in pos.items():\n",
    "            # convertir a n√∫mero si es posible\n",
    "            if isinstance(v, (int, float)) or (isinstance(v, str) and v.replace('.', '', 1).isdigit()):\n",
    "                row[k] = float(v)\n",
    "\n",
    "        rows.append(row)\n",
    "\n",
    "# Crear DataFrame\n",
    "df = pd.DataFrame(rows).fillna(0)\n",
    "\n",
    "# Comparaciones posibles\n",
    "comparisons = {}\n",
    "\n",
    "if df[\"gender\"].nunique() >= 2:\n",
    "    top2 = df[\"gender\"].value_counts().index[:2]\n",
    "    comparisons[\"gender\"] = list(top2)\n",
    "\n",
    "if df[\"edad_grupo\"].nunique() >= 2:\n",
    "    comparisons[\"edad_grupo\"] = [\"joven\", \"mayor\"]\n",
    "\n",
    "if df[\"party\"].nunique() >= 2:\n",
    "    top2 = df[\"party\"].value_counts().index[:2]\n",
    "    comparisons[\"party\"] = list(top2)\n",
    "\n",
    "if df[\"ideologia\"].nunique() >= 2:\n",
    "    top2 = df[\"ideologia\"].value_counts().index[:2]\n",
    "    comparisons[\"ideologia\"] = list(top2)\n",
    "\n",
    "# M√©tricas POS\n",
    "metricas = [col for col in df.columns if col.startswith(\"num_\") or col.startswith(\"ratio_\")]\n",
    "\n",
    "# Funci√≥n para Cohen's d\n",
    "def cohens_d(x1, x2):\n",
    "    n1, n2 = len(x1), len(x2)\n",
    "    s1, s2 = np.var(x1, ddof=1), np.var(x2, ddof=1)\n",
    "    s_pooled = np.sqrt(((n1 - 1)*s1 + (n2 - 1)*s2) / (n1 + n2 - 2))\n",
    "    return (np.mean(x1) - np.mean(x2)) / s_pooled if s_pooled > 0 else 0\n",
    "\n",
    "# Comparar y guardar resultados\n",
    "resultados = []\n",
    "\n",
    "for grupo, (g1, g2) in comparisons.items():\n",
    "    df1 = df[df[grupo] == g1]\n",
    "    df2 = df[df[grupo] == g2]\n",
    "\n",
    "    for metrica in metricas:\n",
    "        if metrica not in df.columns:\n",
    "            continue\n",
    "\n",
    "        x1 = df1[metrica]\n",
    "        x2 = df2[metrica]\n",
    "\n",
    "        if len(x1) < 10 or len(x2) < 10:\n",
    "            continue\n",
    "\n",
    "        d = cohens_d(x1, x2)\n",
    "        t_stat, p_value = ttest_ind(x1, x2, equal_var=False)\n",
    "\n",
    "        resultados.append({\n",
    "            \"grupo\": grupo,\n",
    "            \"valor\": metrica,\n",
    "            \"grupo_1\": g1,\n",
    "            \"grupo_2\": g2,\n",
    "            \"d_cohen\": round(d, 5),\n",
    "            \"t_stat\": round(t_stat, 5),\n",
    "            \"p_value\": p_value,\n",
    "            \"n1\": len(x1),\n",
    "            \"n2\": len(x2)\n",
    "        })\n",
    "\n",
    "# Guardar resultados\n",
    "df_resultados = pd.DataFrame(resultados)\n",
    "df_resultados.to_csv(\"cohens_d_griegos.csv\", index=False)\n",
    "\n",
    "print(\"‚úÖ Resultados guardados en 'cohens_d_griegos.csv'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a8b445d-9446-4f8a-8c40-93b89e0d00fd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
