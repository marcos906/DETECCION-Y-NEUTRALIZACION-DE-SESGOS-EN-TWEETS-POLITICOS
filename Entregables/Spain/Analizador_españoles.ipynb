{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1ac284a4-0b5c-4971-a542-89492ba51f94",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter-lquijano/.local/lib/python3.12/site-packages/transformers/pipelines/text_classification.py:106: UserWarning: `return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Procesando tweet 1/300\n",
      " Tweet: Algo importante se me escapa. \n",
      "Cuál es la clave de estos movimientos por “la Salud y la Libertad”\n",
      "\n",
      " Quizás la desconfianza y el escepticismo de sectores ciudadanos hacia todo lo que sea política, de la mano de los populismos ?\n",
      " Analysis tweet: {\n",
      "  \"sentiment\": {\n",
      "    \"label\": \"neutral\",\n",
      "    \"score\": 0.8190348148345947\n",
      "  },\n",
      "  \"emotions\": [\n",
      "    {\n",
      "      \"label\": \"joy\",\n",
      "      \"score\": 0.36138203740119934\n",
      "    },\n",
      "    {\n",
      "      \"label\": \"anger\",\n",
      "      \"score\": 0.26649489998817444\n",
      "    },\n",
      "    {\n",
      "      \"label\": \"optimism\",\n",
      "      \"score\": 0.2236553579568863\n",
      "    }\n",
      "  ],\n",
      "  \"hate\": {\n",
      "    \"label\": \"not hate\",\n",
      "    \"score\": 0.7658279538154602\n",
      "  },\n",
      "  \"translation\": \"Something important escapes me. What is the key to these movements by “health and Liberty” Maybe the distrust and scepticism of citizens’ sectors towards everything political, from the hands of the populists?\",\n",
      "  \"summary\": \" What is the key to these movements by “health and Liberty” Maybe the distrust and scepticism of citizens’ sectors towards everything political, from the hands of the populists? Maybe the\"\n",
      "}\n",
      "  Procesando reply 1/13\n",
      "   Reply: Detrás hay más q las corrientes negacionistas y conspiranoicas. Algo de fondo está pasando en las sociedades occidentales. Podría ser un gesto de hartazgo y rebeldía en sectores ciudadanos, fruto de la antipolítica q promueven los populistas al amparo de la crisis y la pandemia.\n",
      "   Analysis reply: {\n",
      "  \"sentiment\": {\n",
      "    \"label\": \"neutral\",\n",
      "    \"score\": 0.8367464542388916\n",
      "  },\n",
      "  \"emotions\": [\n",
      "    {\n",
      "      \"label\": \"anger\",\n",
      "      \"score\": 0.39548054337501526\n",
      "    },\n",
      "    {\n",
      "      \"label\": \"optimism\",\n",
      "      \"score\": 0.2555277943611145\n",
      "    },\n",
      "    {\n",
      "      \"label\": \"sadness\",\n",
      "      \"score\": 0.18180646002292633\n",
      "    }\n",
      "  ],\n",
      "  \"hate\": {\n",
      "    \"label\": \"not hate\",\n",
      "    \"score\": 0.8323462009429932\n",
      "  },\n",
      "  \"translation\": \"There are more q of the negationist and conspirator currents. Something of the background is going on in Western societies. It could be a cartoon gesture and rebellion in urban sectors, the fruit of antipolitical q promotes the populists in the face of the crisis and pandemic.\",\n",
      "  \"summary\": \" There are more q of the negationist and conspirator currents. Something of the background is going on in Western societies. It could be a cartoon gesture and rebellion in urban sectors .\"\n",
      "}\n",
      "  Procesando reply 2/13\n",
      "   Reply: Sociedades muy narcisistas. \n",
      "Qué tipo de referentes gustan a la gente? \n",
      "Qué leen, qué ven en la tv? \n",
      "Si a eso le sumas la falta de pedagogía política...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 115\u001b[39m\n\u001b[32m    113\u001b[39m reply_text = reply.get(\u001b[33m\"\u001b[39m\u001b[33mreply\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    114\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m   Reply:\u001b[39m\u001b[33m\"\u001b[39m, reply_text)\n\u001b[32m--> \u001b[39m\u001b[32m115\u001b[39m reply_analysis = \u001b[43manalyze_text\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreply_text\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlang\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    116\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m   Analysis reply:\u001b[39m\u001b[33m\"\u001b[39m, json.dumps(reply_analysis, ensure_ascii=\u001b[38;5;28;01mFalse\u001b[39;00m, indent=\u001b[32m2\u001b[39m))\n\u001b[32m    117\u001b[39m reply[\u001b[33m\"\u001b[39m\u001b[33manalysis\u001b[39m\u001b[33m\"\u001b[39m] = reply_analysis\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 77\u001b[39m, in \u001b[36manalyze_text\u001b[39m\u001b[34m(text, lang)\u001b[39m\n\u001b[32m     75\u001b[39m \u001b[38;5;66;03m# Traducción a inglés si no es inglés\u001b[39;00m\n\u001b[32m     76\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m lang != \u001b[33m\"\u001b[39m\u001b[33men\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m---> \u001b[39m\u001b[32m77\u001b[39m     tr = \u001b[43mtranslation_pipe\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_length\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m256\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[32m0\u001b[39m][\u001b[33m\"\u001b[39m\u001b[33mtranslation_text\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m     78\u001b[39m     res[\u001b[33m\"\u001b[39m\u001b[33mtranslation\u001b[39m\u001b[33m\"\u001b[39m] = tr\n\u001b[32m     79\u001b[39m     summary_input = tr\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/transformers/pipelines/text2text_generation.py:382\u001b[39m, in \u001b[36mTranslationPipeline.__call__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    352\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, *args, **kwargs):\n\u001b[32m    353\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33mr\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    354\u001b[39m \u001b[33;03m    Translate the text(s) given as inputs.\u001b[39;00m\n\u001b[32m    355\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    380\u001b[39m \u001b[33;03m          token ids of the translation.\u001b[39;00m\n\u001b[32m    381\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m382\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/transformers/pipelines/text2text_generation.py:173\u001b[39m, in \u001b[36mText2TextGenerationPipeline.__call__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    144\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, *args, **kwargs):\n\u001b[32m    145\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33mr\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    146\u001b[39m \u001b[33;03m    Generate the output text(s) using text(s) given as inputs.\u001b[39;00m\n\u001b[32m    147\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    170\u001b[39m \u001b[33;03m          ids of the generated text.\u001b[39;00m\n\u001b[32m    171\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m173\u001b[39m     result = \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    174\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    175\u001b[39m         \u001b[38;5;28misinstance\u001b[39m(args[\u001b[32m0\u001b[39m], \u001b[38;5;28mlist\u001b[39m)\n\u001b[32m    176\u001b[39m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mall\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(el, \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m el \u001b[38;5;129;01min\u001b[39;00m args[\u001b[32m0\u001b[39m])\n\u001b[32m    177\u001b[39m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mall\u001b[39m(\u001b[38;5;28mlen\u001b[39m(res) == \u001b[32m1\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m result)\n\u001b[32m    178\u001b[39m     ):\n\u001b[32m    179\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m [res[\u001b[32m0\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m result]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/transformers/pipelines/base.py:1379\u001b[39m, in \u001b[36mPipeline.__call__\u001b[39m\u001b[34m(self, inputs, num_workers, batch_size, *args, **kwargs)\u001b[39m\n\u001b[32m   1371\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mnext\u001b[39m(\n\u001b[32m   1372\u001b[39m         \u001b[38;5;28miter\u001b[39m(\n\u001b[32m   1373\u001b[39m             \u001b[38;5;28mself\u001b[39m.get_iterator(\n\u001b[32m   (...)\u001b[39m\u001b[32m   1376\u001b[39m         )\n\u001b[32m   1377\u001b[39m     )\n\u001b[32m   1378\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1379\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrun_single\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpreprocess_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mforward_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpostprocess_params\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/transformers/pipelines/base.py:1386\u001b[39m, in \u001b[36mPipeline.run_single\u001b[39m\u001b[34m(self, inputs, preprocess_params, forward_params, postprocess_params)\u001b[39m\n\u001b[32m   1384\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mrun_single\u001b[39m(\u001b[38;5;28mself\u001b[39m, inputs, preprocess_params, forward_params, postprocess_params):\n\u001b[32m   1385\u001b[39m     model_inputs = \u001b[38;5;28mself\u001b[39m.preprocess(inputs, **preprocess_params)\n\u001b[32m-> \u001b[39m\u001b[32m1386\u001b[39m     model_outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mforward_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1387\u001b[39m     outputs = \u001b[38;5;28mself\u001b[39m.postprocess(model_outputs, **postprocess_params)\n\u001b[32m   1388\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m outputs\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/transformers/pipelines/base.py:1286\u001b[39m, in \u001b[36mPipeline.forward\u001b[39m\u001b[34m(self, model_inputs, **forward_params)\u001b[39m\n\u001b[32m   1284\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m inference_context():\n\u001b[32m   1285\u001b[39m         model_inputs = \u001b[38;5;28mself\u001b[39m._ensure_tensor_on_device(model_inputs, device=\u001b[38;5;28mself\u001b[39m.device)\n\u001b[32m-> \u001b[39m\u001b[32m1286\u001b[39m         model_outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mforward_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1287\u001b[39m         model_outputs = \u001b[38;5;28mself\u001b[39m._ensure_tensor_on_device(model_outputs, device=torch.device(\u001b[33m\"\u001b[39m\u001b[33mcpu\u001b[39m\u001b[33m\"\u001b[39m))\n\u001b[32m   1288\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/transformers/pipelines/text2text_generation.py:202\u001b[39m, in \u001b[36mText2TextGenerationPipeline._forward\u001b[39m\u001b[34m(self, model_inputs, **generate_kwargs)\u001b[39m\n\u001b[32m    199\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mgeneration_config\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m generate_kwargs:\n\u001b[32m    200\u001b[39m     generate_kwargs[\u001b[33m\"\u001b[39m\u001b[33mgeneration_config\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[38;5;28mself\u001b[39m.generation_config\n\u001b[32m--> \u001b[39m\u001b[32m202\u001b[39m output_ids = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mgenerate_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    203\u001b[39m out_b = output_ids.shape[\u001b[32m0\u001b[39m]\n\u001b[32m    204\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.framework == \u001b[33m\"\u001b[39m\u001b[33mpt\u001b[39m\u001b[33m\"\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/torch/utils/_contextlib.py:116\u001b[39m, in \u001b[36mcontext_decorator.<locals>.decorate_context\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    113\u001b[39m \u001b[38;5;129m@functools\u001b[39m.wraps(func)\n\u001b[32m    114\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdecorate_context\u001b[39m(*args, **kwargs):\n\u001b[32m    115\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[32m--> \u001b[39m\u001b[32m116\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/transformers/generation/utils.py:2484\u001b[39m, in \u001b[36mGenerationMixin.generate\u001b[39m\u001b[34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, use_model_defaults, **kwargs)\u001b[39m\n\u001b[32m   2477\u001b[39m     input_ids, model_kwargs = \u001b[38;5;28mself\u001b[39m._expand_inputs_for_generation(\n\u001b[32m   2478\u001b[39m         input_ids=input_ids,\n\u001b[32m   2479\u001b[39m         expand_size=generation_config.num_beams,\n\u001b[32m   2480\u001b[39m         is_encoder_decoder=\u001b[38;5;28mself\u001b[39m.config.is_encoder_decoder,\n\u001b[32m   2481\u001b[39m         **model_kwargs,\n\u001b[32m   2482\u001b[39m     )\n\u001b[32m   2483\u001b[39m     \u001b[38;5;66;03m# 12. run beam sample\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m2484\u001b[39m     result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_beam_search\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2485\u001b[39m \u001b[43m        \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2486\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlogits_processor\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprepared_logits_processor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2487\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstopping_criteria\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprepared_stopping_criteria\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2488\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgeneration_config\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgeneration_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2489\u001b[39m \u001b[43m        \u001b[49m\u001b[43msynced_gpus\u001b[49m\u001b[43m=\u001b[49m\u001b[43msynced_gpus\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2490\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2491\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2493\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m generation_mode == GenerationMode.GROUP_BEAM_SEARCH:\n\u001b[32m   2494\u001b[39m     \u001b[38;5;66;03m# 11. prepare beam search scorer\u001b[39;00m\n\u001b[32m   2495\u001b[39m     beam_scorer = BeamSearchScorer(\n\u001b[32m   2496\u001b[39m         batch_size=batch_size,\n\u001b[32m   2497\u001b[39m         num_beams=generation_config.num_beams,\n\u001b[32m   (...)\u001b[39m\u001b[32m   2503\u001b[39m         max_length=generation_config.max_length,\n\u001b[32m   2504\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/transformers/generation/utils.py:3904\u001b[39m, in \u001b[36mGenerationMixin._beam_search\u001b[39m\u001b[34m(self, input_ids, logits_processor, stopping_criteria, generation_config, synced_gpus, **model_kwargs)\u001b[39m\n\u001b[32m   3901\u001b[39m model_inputs.update({\u001b[33m\"\u001b[39m\u001b[33moutput_attentions\u001b[39m\u001b[33m\"\u001b[39m: output_attentions} \u001b[38;5;28;01mif\u001b[39;00m output_attentions \u001b[38;5;28;01melse\u001b[39;00m {})\n\u001b[32m   3902\u001b[39m model_inputs.update({\u001b[33m\"\u001b[39m\u001b[33moutput_hidden_states\u001b[39m\u001b[33m\"\u001b[39m: output_hidden_states} \u001b[38;5;28;01mif\u001b[39;00m output_hidden_states \u001b[38;5;28;01melse\u001b[39;00m {})\n\u001b[32m-> \u001b[39m\u001b[32m3904\u001b[39m model_outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m   3906\u001b[39m \u001b[38;5;66;03m# synced_gpus: don't waste resources running the code we don't need; kwargs must be updated before skipping\u001b[39;00m\n\u001b[32m   3907\u001b[39m model_kwargs = \u001b[38;5;28mself\u001b[39m._update_model_kwargs_for_generation(\n\u001b[32m   3908\u001b[39m     model_outputs,\n\u001b[32m   3909\u001b[39m     model_kwargs,\n\u001b[32m   3910\u001b[39m     is_encoder_decoder=\u001b[38;5;28mself\u001b[39m.config.is_encoder_decoder,\n\u001b[32m   3911\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/torch/nn/modules/module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/torch/nn/modules/module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/transformers/models/marian/modeling_marian.py:1400\u001b[39m, in \u001b[36mMarianMTModel.forward\u001b[39m\u001b[34m(self, input_ids, attention_mask, decoder_input_ids, decoder_attention_mask, head_mask, decoder_head_mask, cross_attn_head_mask, encoder_outputs, past_key_values, inputs_embeds, decoder_inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[39m\n\u001b[32m   1395\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m decoder_input_ids \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m decoder_inputs_embeds \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   1396\u001b[39m         decoder_input_ids = shift_tokens_right(\n\u001b[32m   1397\u001b[39m             labels, \u001b[38;5;28mself\u001b[39m.config.pad_token_id, \u001b[38;5;28mself\u001b[39m.config.decoder_start_token_id\n\u001b[32m   1398\u001b[39m         )\n\u001b[32m-> \u001b[39m\u001b[32m1400\u001b[39m outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1401\u001b[39m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1402\u001b[39m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1403\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdecoder_input_ids\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdecoder_input_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1404\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoder_outputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mencoder_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1405\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdecoder_attention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdecoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1406\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1407\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdecoder_head_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdecoder_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1408\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcross_attn_head_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcross_attn_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1409\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1410\u001b[39m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[43m=\u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1411\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdecoder_inputs_embeds\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdecoder_inputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1412\u001b[39m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1413\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1414\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1415\u001b[39m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1416\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1417\u001b[39m lm_logits = \u001b[38;5;28mself\u001b[39m.lm_head(outputs[\u001b[32m0\u001b[39m]) + \u001b[38;5;28mself\u001b[39m.final_logits_bias\n\u001b[32m   1419\u001b[39m masked_lm_loss = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/torch/nn/modules/module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/torch/nn/modules/module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/transformers/models/marian/modeling_marian.py:1192\u001b[39m, in \u001b[36mMarianModel.forward\u001b[39m\u001b[34m(self, input_ids, attention_mask, decoder_input_ids, decoder_attention_mask, head_mask, decoder_head_mask, cross_attn_head_mask, encoder_outputs, past_key_values, inputs_embeds, decoder_inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[39m\n\u001b[32m   1185\u001b[39m     encoder_outputs = BaseModelOutput(\n\u001b[32m   1186\u001b[39m         last_hidden_state=encoder_outputs[\u001b[32m0\u001b[39m],\n\u001b[32m   1187\u001b[39m         hidden_states=encoder_outputs[\u001b[32m1\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(encoder_outputs) > \u001b[32m1\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1188\u001b[39m         attentions=encoder_outputs[\u001b[32m2\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(encoder_outputs) > \u001b[32m2\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1189\u001b[39m     )\n\u001b[32m   1191\u001b[39m \u001b[38;5;66;03m# decoder outputs consists of (dec_features, past_key_value, dec_hidden, dec_attn)\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1192\u001b[39m decoder_outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdecoder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1193\u001b[39m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdecoder_input_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1194\u001b[39m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdecoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1195\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m=\u001b[49m\u001b[43mencoder_outputs\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1196\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1197\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdecoder_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1198\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcross_attn_head_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcross_attn_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1199\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1200\u001b[39m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdecoder_inputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1201\u001b[39m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1202\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1203\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1204\u001b[39m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1205\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1207\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m return_dict:\n\u001b[32m   1208\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m decoder_outputs + encoder_outputs\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/torch/nn/modules/module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/torch/nn/modules/module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/transformers/models/marian/modeling_marian.py:992\u001b[39m, in \u001b[36mMarianDecoder.forward\u001b[39m\u001b[34m(self, input_ids, attention_mask, encoder_hidden_states, encoder_attention_mask, head_mask, cross_attn_head_mask, past_key_values, inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[39m\n\u001b[32m    979\u001b[39m     layer_outputs = \u001b[38;5;28mself\u001b[39m._gradient_checkpointing_func(\n\u001b[32m    980\u001b[39m         decoder_layer.\u001b[34m__call__\u001b[39m,\n\u001b[32m    981\u001b[39m         hidden_states,\n\u001b[32m   (...)\u001b[39m\u001b[32m    989\u001b[39m         use_cache,\n\u001b[32m    990\u001b[39m     )\n\u001b[32m    991\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m992\u001b[39m     layer_outputs = \u001b[43mdecoder_layer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    993\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    994\u001b[39m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    995\u001b[39m \u001b[43m        \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m=\u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    996\u001b[39m \u001b[43m        \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    997\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlayer_head_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    998\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcross_attn_layer_head_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    999\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcross_attn_head_mask\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcross_attn_head_mask\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\n\u001b[32m   1000\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1001\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1002\u001b[39m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1003\u001b[39m \u001b[43m        \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1004\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1005\u001b[39m hidden_states = layer_outputs[\u001b[32m0\u001b[39m]\n\u001b[32m   1007\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m use_cache:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/torch/nn/modules/module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/torch/nn/modules/module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/transformers/models/marian/modeling_marian.py:421\u001b[39m, in \u001b[36mMarianDecoderLayer.forward\u001b[39m\u001b[34m(self, hidden_states, attention_mask, encoder_hidden_states, encoder_attention_mask, layer_head_mask, cross_attn_layer_head_mask, past_key_value, output_attentions, use_cache)\u001b[39m\n\u001b[32m    419\u001b[39m \u001b[38;5;66;03m# cross_attn cached key/values tuple is at positions 3,4 of present_key_value tuple\u001b[39;00m\n\u001b[32m    420\u001b[39m cross_attn_past_key_value = past_key_value[-\u001b[32m2\u001b[39m:] \u001b[38;5;28;01mif\u001b[39;00m past_key_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m421\u001b[39m hidden_states, cross_attn_weights, cross_attn_present_key_value = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mencoder_attn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    422\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    423\u001b[39m \u001b[43m    \u001b[49m\u001b[43mkey_value_states\u001b[49m\u001b[43m=\u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    424\u001b[39m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    425\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlayer_head_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcross_attn_layer_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    426\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcross_attn_past_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    427\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    428\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    429\u001b[39m hidden_states = nn.functional.dropout(hidden_states, p=\u001b[38;5;28mself\u001b[39m.dropout, training=\u001b[38;5;28mself\u001b[39m.training)\n\u001b[32m    430\u001b[39m hidden_states = residual + hidden_states\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/torch/nn/modules/module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/torch/nn/modules/module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/transformers/models/marian/modeling_marian.py:241\u001b[39m, in \u001b[36mMarianAttention.forward\u001b[39m\u001b[34m(self, hidden_states, key_value_states, past_key_value, attention_mask, layer_head_mask, output_attentions)\u001b[39m\n\u001b[32m    237\u001b[39m     attn_weights_reshaped = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    239\u001b[39m attn_probs = nn.functional.dropout(attn_weights, p=\u001b[38;5;28mself\u001b[39m.dropout, training=\u001b[38;5;28mself\u001b[39m.training)\n\u001b[32m--> \u001b[39m\u001b[32m241\u001b[39m attn_output = \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbmm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mattn_probs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue_states\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    243\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m attn_output.size() != (bsz * \u001b[38;5;28mself\u001b[39m.num_heads, tgt_len, \u001b[38;5;28mself\u001b[39m.head_dim):\n\u001b[32m    244\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    245\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m`attn_output` should be of size \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m(bsz\u001b[38;5;250m \u001b[39m*\u001b[38;5;250m \u001b[39m\u001b[38;5;28mself\u001b[39m.num_heads,\u001b[38;5;250m \u001b[39mtgt_len,\u001b[38;5;250m \u001b[39m\u001b[38;5;28mself\u001b[39m.head_dim)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, but is\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    246\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mattn_output.size()\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    247\u001b[39m     )\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# Si te faltan dependencias, descomenta y ejecuta:\n",
    "# !pip install torch transformers sentencepiece tiktoken protobuf\n",
    "\n",
    "import json\n",
    "from transformers import pipeline, logging\n",
    "\n",
    "# Suprimir warnings de Transformers\n",
    "logging.set_verbosity_error()\n",
    "\n",
    "# Forzar uso de CPU (cambia a 0 para GPU si tu VRAM lo permite)\n",
    "DEVICE = -1\n",
    "\n",
    "# 1) Configuración de pipelines\n",
    "sentiment_pipe = pipeline(\n",
    "    \"sentiment-analysis\",\n",
    "    model=\"cardiffnlp/twitter-roberta-base-sentiment-latest\",\n",
    "    tokenizer=\"cardiffnlp/twitter-roberta-base-sentiment-latest\",\n",
    "    device=DEVICE\n",
    ")\n",
    "emotion_pipe = pipeline(\n",
    "    \"text-classification\",\n",
    "    model=\"cardiffnlp/twitter-roberta-base-emotion\",\n",
    "    tokenizer=\"cardiffnlp/twitter-roberta-base-emotion\",\n",
    "    return_all_scores=True,\n",
    "    device=DEVICE\n",
    ")\n",
    "hate_pipe = pipeline(\n",
    "    \"zero-shot-classification\",\n",
    "    model=\"joeddav/xlm-roberta-large-xnli\",\n",
    "    tokenizer=\"joeddav/xlm-roberta-large-xnli\",\n",
    "    device=DEVICE\n",
    ")\n",
    "translation_pipe = pipeline(\n",
    "    \"translation\",\n",
    "    model=\"Helsinki-NLP/opus-mt-mul-en\",\n",
    "    tokenizer=\"Helsinki-NLP/opus-mt-mul-en\",\n",
    "    device=DEVICE\n",
    ")\n",
    "summarization_pipe = pipeline(\n",
    "    \"summarization\",\n",
    "    model=\"sshleifer/distilbart-cnn-12-6\",\n",
    "    tokenizer=\"sshleifer/distilbart-cnn-12-6\",\n",
    "    device=DEVICE\n",
    ")\n",
    "\n",
    "# 2) Función de análisis\n",
    "def analyze_text(text, lang):\n",
    "    text = text or \"\"\n",
    "    if not text.strip():\n",
    "        return {\n",
    "            \"sentiment\": None,\n",
    "            \"emotions\": [],\n",
    "            \"hate\": None,\n",
    "            \"translation\": None,\n",
    "            \"summary\": None\n",
    "        }\n",
    "\n",
    "    res = {}\n",
    "    # Sentiment\n",
    "    s = sentiment_pipe(text)[0]\n",
    "    res[\"sentiment\"] = {\"label\": s[\"label\"], \"score\": float(s[\"score\"])}\n",
    "\n",
    "    # Emotions top 3\n",
    "    emos = emotion_pipe(text)[0]\n",
    "    top3 = sorted(emos, key=lambda x: x[\"score\"], reverse=True)[:3]\n",
    "    res[\"emotions\"] = [{\"label\": e[\"label\"], \"score\": float(e[\"score\"])} for e in top3]\n",
    "\n",
    "    # Hate vs Not Hate (skip si falla)\n",
    "    try:\n",
    "        z = hate_pipe(text, candidate_labels=[\"hate\", \"not hate\"])\n",
    "        res[\"hate\"] = {\"label\": z[\"labels\"][0], \"score\": float(z[\"scores\"][0])}\n",
    "    except ValueError:\n",
    "        res[\"hate\"] = None\n",
    "\n",
    "    # Traducción a inglés si no es inglés\n",
    "    if lang != \"en\":\n",
    "        tr = translation_pipe(text, max_length=256)[0][\"translation_text\"]\n",
    "        res[\"translation\"] = tr\n",
    "        summary_input = tr\n",
    "    else:\n",
    "        res[\"translation\"] = text\n",
    "        summary_input = text\n",
    "\n",
    "    # Resumen dinámico (más corto que la entrada)\n",
    "    tok = summarization_pipe.tokenizer\n",
    "    ids = tok.encode(summary_input, return_tensors=\"pt\")[0]\n",
    "    max_len = max(5, min(60, len(ids) - 2))\n",
    "    sm = summarization_pipe(summary_input, max_length=max_len, min_length=5)[0][\"summary_text\"]\n",
    "    res[\"summary\"] = sm\n",
    "\n",
    "    return res\n",
    "\n",
    "# 3) Cargar, procesar y guardar JSON mostrando progreso de tweets y replies\n",
    "input_path = \"tweets_españoles_anotados_finales_id.json\"   \n",
    "output_path = \"tweets_españoles_evaluados.json\"  \n",
    "lang = \"el\"  # 'el' para griego, 'es' para español, 'en' para inglés\n",
    "\n",
    "with open(input_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "total = len(data)\n",
    "for idx, item in enumerate(data, start=1):\n",
    "    print(f\"Procesando tweet {idx}/{total}\")\n",
    "    tweet_text = item.get(\"tweet\", \"\")\n",
    "    print(\" Tweet:\", tweet_text)\n",
    "    tweet_analysis = analyze_text(tweet_text, lang)\n",
    "    print(\" Analysis tweet:\", json.dumps(tweet_analysis, ensure_ascii=False, indent=2))\n",
    "    item[\"analysis\"] = tweet_analysis\n",
    "\n",
    "    replies = item.get(\"replies\", [])\n",
    "    for r_idx, reply in enumerate(replies, start=1):\n",
    "        print(f\"  Procesando reply {r_idx}/{len(replies)}\")\n",
    "        reply_text = reply.get(\"reply\", \"\")\n",
    "        print(\"   Reply:\", reply_text)\n",
    "        reply_analysis = analyze_text(reply_text, lang)\n",
    "        print(\"   Analysis reply:\", json.dumps(reply_analysis, ensure_ascii=False, indent=2))\n",
    "        reply[\"analysis\"] = reply_analysis\n",
    "\n",
    "with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(data, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "print(f\"\\n✅ Análisis completado. Resultado guardado en {output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3564a319-0fd6-42ad-9d6b-5afea1880b71",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install sacremoses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f17b296b-5894-49aa-b375-5a39835e10f6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa0accec86e34936a6dce0cf52248ab3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.10.0.json:   0%|  …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-30 07:55:51 INFO: Downloaded file to /home/jupyter-lquijano/stanza_resources/resources.json\n",
      "2025-04-30 07:55:51 INFO: Downloading default packages for language: es (Spanish) ...\n",
      "2025-04-30 07:55:53 INFO: File exists: /home/jupyter-lquijano/stanza_resources/es/default.zip\n",
      "2025-04-30 07:55:56 INFO: Finished downloading models and saved to /home/jupyter-lquijano/stanza_resources\n",
      "2025-04-30 07:55:56 INFO: Checking for updates to resources.json in case models have been updated.  Note: this behavior can be turned off with download_method=None or download_method=DownloadMethod.REUSE_RESOURCES\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12494cb0a44944a99c18a1db19211da1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.10.0.json:   0%|  …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-30 07:55:56 INFO: Downloaded file to /home/jupyter-lquijano/stanza_resources/resources.json\n",
      "2025-04-30 07:55:56 WARNING: Language es package default expects mwt, which has been added\n",
      "2025-04-30 07:55:57 INFO: Loading these models for language: es (Spanish):\n",
      "===============================\n",
      "| Processor | Package         |\n",
      "-------------------------------\n",
      "| tokenize  | combined        |\n",
      "| mwt       | combined        |\n",
      "| sentiment | tass2020_charlm |\n",
      "===============================\n",
      "\n",
      "2025-04-30 07:55:57 WARNING: GPU requested, but is not available!\n",
      "2025-04-30 07:55:57 INFO: Using device: cpu\n",
      "2025-04-30 07:55:57 INFO: Loading: tokenize\n",
      "2025-04-30 07:55:57 INFO: Loading: mwt\n",
      "2025-04-30 07:55:57 INFO: Loading: sentiment\n",
      "2025-04-30 07:55:58 INFO: Done loading processors!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Procesando tweet 1/1000\n",
      "Procesando tweet 2/1000\n",
      "Procesando tweet 3/1000\n",
      "Procesando tweet 4/1000\n",
      "Procesando tweet 5/1000\n",
      "Procesando tweet 6/1000\n",
      "Procesando tweet 7/1000\n",
      "Procesando tweet 8/1000\n",
      "Procesando tweet 9/1000\n",
      "Procesando tweet 10/1000\n",
      "Procesando tweet 11/1000\n",
      "Procesando tweet 12/1000\n",
      "Procesando tweet 13/1000\n",
      "Procesando tweet 14/1000\n",
      "Procesando tweet 15/1000\n",
      "Procesando tweet 16/1000\n",
      "Procesando tweet 17/1000\n",
      "Procesando tweet 18/1000\n",
      "Procesando tweet 19/1000\n",
      "Procesando tweet 20/1000\n",
      "Procesando tweet 21/1000\n",
      "Procesando tweet 22/1000\n",
      "Procesando tweet 23/1000\n",
      "Procesando tweet 24/1000\n",
      "Procesando tweet 25/1000\n",
      "Procesando tweet 26/1000\n",
      "Procesando tweet 27/1000\n",
      "Procesando tweet 28/1000\n",
      "Procesando tweet 29/1000\n",
      "Procesando tweet 30/1000\n",
      "Procesando tweet 31/1000\n",
      "Procesando tweet 32/1000\n",
      "Procesando tweet 33/1000\n",
      "Procesando tweet 34/1000\n",
      "Procesando tweet 35/1000\n",
      "Procesando tweet 36/1000\n",
      "Procesando tweet 37/1000\n",
      "Procesando tweet 38/1000\n",
      "Procesando tweet 39/1000\n",
      "Procesando tweet 40/1000\n",
      "Procesando tweet 41/1000\n",
      "Procesando tweet 42/1000\n",
      "Procesando tweet 43/1000\n",
      "Procesando tweet 44/1000\n",
      "Procesando tweet 45/1000\n",
      "Procesando tweet 46/1000\n",
      "Procesando tweet 47/1000\n",
      "Procesando tweet 48/1000\n",
      "Procesando tweet 49/1000\n",
      "Procesando tweet 50/1000\n",
      "Procesando tweet 51/1000\n",
      "Procesando tweet 52/1000\n",
      "Procesando tweet 53/1000\n",
      "Procesando tweet 54/1000\n",
      "Procesando tweet 55/1000\n",
      "Procesando tweet 56/1000\n",
      "Procesando tweet 57/1000\n",
      "Procesando tweet 58/1000\n",
      "Procesando tweet 59/1000\n",
      "Procesando tweet 60/1000\n",
      "Procesando tweet 61/1000\n",
      "Procesando tweet 62/1000\n",
      "Procesando tweet 63/1000\n",
      "Procesando tweet 64/1000\n",
      "Procesando tweet 65/1000\n",
      "Procesando tweet 66/1000\n",
      "Procesando tweet 67/1000\n",
      "Procesando tweet 68/1000\n",
      "Procesando tweet 69/1000\n",
      "Procesando tweet 70/1000\n",
      "Procesando tweet 71/1000\n",
      "Procesando tweet 72/1000\n",
      "Procesando tweet 73/1000\n",
      "Procesando tweet 74/1000\n",
      "Procesando tweet 75/1000\n",
      "Procesando tweet 76/1000\n",
      "Procesando tweet 77/1000\n",
      "Procesando tweet 78/1000\n",
      "Procesando tweet 79/1000\n",
      "Procesando tweet 80/1000\n",
      "Procesando tweet 81/1000\n",
      "Procesando tweet 82/1000\n",
      "Procesando tweet 83/1000\n",
      "Procesando tweet 84/1000\n",
      "Procesando tweet 85/1000\n",
      "Procesando tweet 86/1000\n",
      "Procesando tweet 87/1000\n",
      "Procesando tweet 88/1000\n",
      "Procesando tweet 89/1000\n",
      "Procesando tweet 90/1000\n",
      "Procesando tweet 91/1000\n",
      "Procesando tweet 92/1000\n",
      "Procesando tweet 93/1000\n",
      "Procesando tweet 94/1000\n",
      "Procesando tweet 95/1000\n",
      "Procesando tweet 96/1000\n",
      "Procesando tweet 97/1000\n",
      "Procesando tweet 98/1000\n",
      "Procesando tweet 99/1000\n",
      "Procesando tweet 100/1000\n",
      "Procesando tweet 101/1000\n",
      "Procesando tweet 102/1000\n",
      "Procesando tweet 103/1000\n",
      "Procesando tweet 104/1000\n",
      "Procesando tweet 105/1000\n",
      "Procesando tweet 106/1000\n",
      "Procesando tweet 107/1000\n",
      "Procesando tweet 108/1000\n",
      "Procesando tweet 109/1000\n",
      "Procesando tweet 110/1000\n",
      "Procesando tweet 111/1000\n",
      "Procesando tweet 112/1000\n",
      "Procesando tweet 113/1000\n",
      "Procesando tweet 114/1000\n",
      "Procesando tweet 115/1000\n",
      "Procesando tweet 116/1000\n",
      "Procesando tweet 117/1000\n",
      "Procesando tweet 118/1000\n",
      "Procesando tweet 119/1000\n",
      "Procesando tweet 120/1000\n",
      "Procesando tweet 121/1000\n",
      "Procesando tweet 122/1000\n",
      "Procesando tweet 123/1000\n",
      "Procesando tweet 124/1000\n",
      "Procesando tweet 125/1000\n",
      "Procesando tweet 126/1000\n",
      "Procesando tweet 127/1000\n",
      "Procesando tweet 128/1000\n",
      "Procesando tweet 129/1000\n",
      "Procesando tweet 130/1000\n",
      "Procesando tweet 131/1000\n",
      "Procesando tweet 132/1000\n",
      "Procesando tweet 133/1000\n",
      "Procesando tweet 134/1000\n",
      "Procesando tweet 135/1000\n",
      "Procesando tweet 136/1000\n",
      "Procesando tweet 137/1000\n",
      "Procesando tweet 138/1000\n",
      "Procesando tweet 139/1000\n",
      "Procesando tweet 140/1000\n",
      "Procesando tweet 141/1000\n",
      "Procesando tweet 142/1000\n",
      "Procesando tweet 143/1000\n",
      "Procesando tweet 144/1000\n",
      "Procesando tweet 145/1000\n",
      "Procesando tweet 146/1000\n",
      "Procesando tweet 147/1000\n",
      "Procesando tweet 148/1000\n",
      "Procesando tweet 149/1000\n",
      "Procesando tweet 150/1000\n",
      "Procesando tweet 151/1000\n",
      "Procesando tweet 152/1000\n",
      "Procesando tweet 153/1000\n",
      "Procesando tweet 154/1000\n",
      "Procesando tweet 155/1000\n",
      "Procesando tweet 156/1000\n",
      "Procesando tweet 157/1000\n",
      "Procesando tweet 158/1000\n",
      "Procesando tweet 159/1000\n",
      "Procesando tweet 160/1000\n",
      "Procesando tweet 161/1000\n",
      "Procesando tweet 162/1000\n",
      "Procesando tweet 163/1000\n",
      "Procesando tweet 164/1000\n",
      "Procesando tweet 165/1000\n",
      "Procesando tweet 166/1000\n",
      "Procesando tweet 167/1000\n",
      "Procesando tweet 168/1000\n",
      "Procesando tweet 169/1000\n",
      "Procesando tweet 170/1000\n",
      "Procesando tweet 171/1000\n",
      "Procesando tweet 172/1000\n",
      "Procesando tweet 173/1000\n",
      "Procesando tweet 174/1000\n",
      "Procesando tweet 175/1000\n",
      "Procesando tweet 176/1000\n",
      "Procesando tweet 177/1000\n",
      "Procesando tweet 178/1000\n",
      "Procesando tweet 179/1000\n",
      "Procesando tweet 180/1000\n",
      "Procesando tweet 181/1000\n",
      "Procesando tweet 182/1000\n",
      "Procesando tweet 183/1000\n",
      "Procesando tweet 184/1000\n",
      "Procesando tweet 185/1000\n",
      "Procesando tweet 186/1000\n",
      "Procesando tweet 187/1000\n",
      "Procesando tweet 188/1000\n",
      "Procesando tweet 189/1000\n",
      "Procesando tweet 190/1000\n",
      "Procesando tweet 191/1000\n",
      "Procesando tweet 192/1000\n",
      "Procesando tweet 193/1000\n",
      "Procesando tweet 194/1000\n",
      "Procesando tweet 195/1000\n",
      "Procesando tweet 196/1000\n",
      "Procesando tweet 197/1000\n",
      "Procesando tweet 198/1000\n",
      "Procesando tweet 199/1000\n",
      "Procesando tweet 200/1000\n",
      "Procesando tweet 201/1000\n",
      "Procesando tweet 202/1000\n",
      "Procesando tweet 203/1000\n",
      "Procesando tweet 204/1000\n",
      "Procesando tweet 205/1000\n",
      "Procesando tweet 206/1000\n",
      "Procesando tweet 207/1000\n",
      "Procesando tweet 208/1000\n",
      "Procesando tweet 209/1000\n",
      "Procesando tweet 210/1000\n",
      "Procesando tweet 211/1000\n",
      "Procesando tweet 212/1000\n",
      "Procesando tweet 213/1000\n",
      "Procesando tweet 214/1000\n",
      "Procesando tweet 215/1000\n",
      "Procesando tweet 216/1000\n",
      "Procesando tweet 217/1000\n",
      "Procesando tweet 218/1000\n",
      "Procesando tweet 219/1000\n",
      "Procesando tweet 220/1000\n",
      "Procesando tweet 221/1000\n",
      "Procesando tweet 222/1000\n",
      "Procesando tweet 223/1000\n",
      "Procesando tweet 224/1000\n",
      "Procesando tweet 225/1000\n",
      "Procesando tweet 226/1000\n",
      "Procesando tweet 227/1000\n",
      "Procesando tweet 228/1000\n",
      "Procesando tweet 229/1000\n",
      "Procesando tweet 230/1000\n",
      "Procesando tweet 231/1000\n",
      "Procesando tweet 232/1000\n",
      "Procesando tweet 233/1000\n",
      "Procesando tweet 234/1000\n",
      "Procesando tweet 235/1000\n",
      "Procesando tweet 236/1000\n",
      "Procesando tweet 237/1000\n",
      "Procesando tweet 238/1000\n",
      "Procesando tweet 239/1000\n",
      "Procesando tweet 240/1000\n",
      "Procesando tweet 241/1000\n",
      "Procesando tweet 242/1000\n",
      "Procesando tweet 243/1000\n",
      "Procesando tweet 244/1000\n",
      "Procesando tweet 245/1000\n",
      "Procesando tweet 246/1000\n",
      "Procesando tweet 247/1000\n",
      "Procesando tweet 248/1000\n",
      "Procesando tweet 249/1000\n",
      "Procesando tweet 250/1000\n",
      "Procesando tweet 251/1000\n",
      "Procesando tweet 252/1000\n",
      "Procesando tweet 253/1000\n",
      "Procesando tweet 254/1000\n",
      "Procesando tweet 255/1000\n",
      "Procesando tweet 256/1000\n",
      "Procesando tweet 257/1000\n",
      "Procesando tweet 258/1000\n",
      "Procesando tweet 259/1000\n",
      "Procesando tweet 260/1000\n",
      "Procesando tweet 261/1000\n",
      "Procesando tweet 262/1000\n",
      "Procesando tweet 263/1000\n",
      "Procesando tweet 264/1000\n",
      "Procesando tweet 265/1000\n",
      "Procesando tweet 266/1000\n",
      "Procesando tweet 267/1000\n",
      "Procesando tweet 268/1000\n",
      "Procesando tweet 269/1000\n",
      "Procesando tweet 270/1000\n",
      "Procesando tweet 271/1000\n",
      "Procesando tweet 272/1000\n",
      "Procesando tweet 273/1000\n",
      "Procesando tweet 274/1000\n",
      "Procesando tweet 275/1000\n",
      "Procesando tweet 276/1000\n",
      "Procesando tweet 277/1000\n",
      "Procesando tweet 278/1000\n",
      "Procesando tweet 279/1000\n",
      "Procesando tweet 280/1000\n",
      "Procesando tweet 281/1000\n",
      "Procesando tweet 282/1000\n",
      "Procesando tweet 283/1000\n",
      "Procesando tweet 284/1000\n",
      "Procesando tweet 285/1000\n",
      "Procesando tweet 286/1000\n",
      "Procesando tweet 287/1000\n",
      "Procesando tweet 288/1000\n",
      "Procesando tweet 289/1000\n",
      "Procesando tweet 290/1000\n",
      "Procesando tweet 291/1000\n",
      "Procesando tweet 292/1000\n",
      "Procesando tweet 293/1000\n",
      "Procesando tweet 294/1000\n",
      "Procesando tweet 295/1000\n",
      "Procesando tweet 296/1000\n",
      "Procesando tweet 297/1000\n",
      "Procesando tweet 298/1000\n",
      "Procesando tweet 299/1000\n",
      "Procesando tweet 300/1000\n",
      "Procesando tweet 301/1000\n",
      "Procesando tweet 302/1000\n",
      "Procesando tweet 303/1000\n",
      "Procesando tweet 304/1000\n",
      "Procesando tweet 305/1000\n",
      "Procesando tweet 306/1000\n",
      "Procesando tweet 307/1000\n",
      "Procesando tweet 308/1000\n",
      "Procesando tweet 309/1000\n",
      "Procesando tweet 310/1000\n",
      "Procesando tweet 311/1000\n",
      "Procesando tweet 312/1000\n",
      "Procesando tweet 313/1000\n",
      "Procesando tweet 314/1000\n",
      "Procesando tweet 315/1000\n",
      "Procesando tweet 316/1000\n",
      "Procesando tweet 317/1000\n",
      "Procesando tweet 318/1000\n",
      "Procesando tweet 319/1000\n",
      "Procesando tweet 320/1000\n",
      "Procesando tweet 321/1000\n",
      "Procesando tweet 322/1000\n",
      "Procesando tweet 323/1000\n",
      "Procesando tweet 324/1000\n",
      "Procesando tweet 325/1000\n",
      "Procesando tweet 326/1000\n",
      "Procesando tweet 327/1000\n",
      "Procesando tweet 328/1000\n",
      "Procesando tweet 329/1000\n",
      "Procesando tweet 330/1000\n",
      "Procesando tweet 331/1000\n",
      "Procesando tweet 332/1000\n",
      "Procesando tweet 333/1000\n",
      "Procesando tweet 334/1000\n",
      "Procesando tweet 335/1000\n",
      "Procesando tweet 336/1000\n",
      "Procesando tweet 337/1000\n",
      "Procesando tweet 338/1000\n",
      "Procesando tweet 339/1000\n",
      "Procesando tweet 340/1000\n",
      "Procesando tweet 341/1000\n",
      "Procesando tweet 342/1000\n",
      "Procesando tweet 343/1000\n",
      "Procesando tweet 344/1000\n",
      "Procesando tweet 345/1000\n",
      "Procesando tweet 346/1000\n",
      "Procesando tweet 347/1000\n",
      "Procesando tweet 348/1000\n",
      "Procesando tweet 349/1000\n",
      "Procesando tweet 350/1000\n",
      "Procesando tweet 351/1000\n",
      "Procesando tweet 352/1000\n",
      "Procesando tweet 353/1000\n",
      "Procesando tweet 354/1000\n",
      "Procesando tweet 355/1000\n",
      "Procesando tweet 356/1000\n",
      "Procesando tweet 357/1000\n",
      "Procesando tweet 358/1000\n",
      "Procesando tweet 359/1000\n",
      "Procesando tweet 360/1000\n",
      "Procesando tweet 361/1000\n",
      "Procesando tweet 362/1000\n",
      "Procesando tweet 363/1000\n",
      "Procesando tweet 364/1000\n",
      "Procesando tweet 365/1000\n",
      "Procesando tweet 366/1000\n",
      "Procesando tweet 367/1000\n",
      "Procesando tweet 368/1000\n",
      "Procesando tweet 369/1000\n",
      "Procesando tweet 370/1000\n",
      "Procesando tweet 371/1000\n",
      "Procesando tweet 372/1000\n",
      "Procesando tweet 373/1000\n",
      "Procesando tweet 374/1000\n",
      "Procesando tweet 375/1000\n",
      "Procesando tweet 376/1000\n",
      "Procesando tweet 377/1000\n",
      "Procesando tweet 378/1000\n",
      "Procesando tweet 379/1000\n",
      "Procesando tweet 380/1000\n",
      "Procesando tweet 381/1000\n",
      "Procesando tweet 382/1000\n",
      "Procesando tweet 383/1000\n",
      "Procesando tweet 384/1000\n",
      "Procesando tweet 385/1000\n",
      "Procesando tweet 386/1000\n",
      "Procesando tweet 387/1000\n",
      "Procesando tweet 388/1000\n",
      "Procesando tweet 389/1000\n",
      "Procesando tweet 390/1000\n",
      "Procesando tweet 391/1000\n",
      "Procesando tweet 392/1000\n",
      "Procesando tweet 393/1000\n",
      "Procesando tweet 394/1000\n",
      "Procesando tweet 395/1000\n",
      "Procesando tweet 396/1000\n",
      "Procesando tweet 397/1000\n",
      "Procesando tweet 398/1000\n",
      "Procesando tweet 399/1000\n",
      "Procesando tweet 400/1000\n",
      "Procesando tweet 401/1000\n",
      "Procesando tweet 402/1000\n",
      "Procesando tweet 403/1000\n",
      "Procesando tweet 404/1000\n",
      "Procesando tweet 405/1000\n",
      "Procesando tweet 406/1000\n",
      "Procesando tweet 407/1000\n",
      "Procesando tweet 408/1000\n",
      "Procesando tweet 409/1000\n",
      "Procesando tweet 410/1000\n",
      "Procesando tweet 411/1000\n",
      "Procesando tweet 412/1000\n",
      "Procesando tweet 413/1000\n",
      "Procesando tweet 414/1000\n",
      "Procesando tweet 415/1000\n",
      "Procesando tweet 416/1000\n",
      "Procesando tweet 417/1000\n",
      "Procesando tweet 418/1000\n",
      "Procesando tweet 419/1000\n",
      "Procesando tweet 420/1000\n",
      "Procesando tweet 421/1000\n",
      "Procesando tweet 422/1000\n",
      "Procesando tweet 423/1000\n",
      "Procesando tweet 424/1000\n",
      "Procesando tweet 425/1000\n",
      "Procesando tweet 426/1000\n",
      "Procesando tweet 427/1000\n",
      "Procesando tweet 428/1000\n",
      "Procesando tweet 429/1000\n",
      "Procesando tweet 430/1000\n",
      "Procesando tweet 431/1000\n",
      "Procesando tweet 432/1000\n",
      "Procesando tweet 433/1000\n",
      "Procesando tweet 434/1000\n",
      "Procesando tweet 435/1000\n",
      "Procesando tweet 436/1000\n",
      "Procesando tweet 437/1000\n",
      "Procesando tweet 438/1000\n",
      "Procesando tweet 439/1000\n",
      "Procesando tweet 440/1000\n",
      "Procesando tweet 441/1000\n",
      "Procesando tweet 442/1000\n",
      "Procesando tweet 443/1000\n",
      "Procesando tweet 444/1000\n",
      "Procesando tweet 445/1000\n",
      "Procesando tweet 446/1000\n",
      "Procesando tweet 447/1000\n",
      "Procesando tweet 448/1000\n",
      "Procesando tweet 449/1000\n",
      "Procesando tweet 450/1000\n",
      "Procesando tweet 451/1000\n",
      "Procesando tweet 452/1000\n",
      "Procesando tweet 453/1000\n",
      "Procesando tweet 454/1000\n",
      "Procesando tweet 455/1000\n",
      "Procesando tweet 456/1000\n",
      "Procesando tweet 457/1000\n",
      "Procesando tweet 458/1000\n",
      "Procesando tweet 459/1000\n",
      "Procesando tweet 460/1000\n",
      "Procesando tweet 461/1000\n",
      "Procesando tweet 462/1000\n",
      "Procesando tweet 463/1000\n",
      "Procesando tweet 464/1000\n",
      "Procesando tweet 465/1000\n",
      "Procesando tweet 466/1000\n",
      "Procesando tweet 467/1000\n",
      "Procesando tweet 468/1000\n",
      "Procesando tweet 469/1000\n",
      "Procesando tweet 470/1000\n",
      "Procesando tweet 471/1000\n",
      "Procesando tweet 472/1000\n",
      "Procesando tweet 473/1000\n",
      "Procesando tweet 474/1000\n",
      "Procesando tweet 475/1000\n",
      "Procesando tweet 476/1000\n",
      "Procesando tweet 477/1000\n",
      "Procesando tweet 478/1000\n",
      "Procesando tweet 479/1000\n",
      "Procesando tweet 480/1000\n",
      "Procesando tweet 481/1000\n",
      "Procesando tweet 482/1000\n",
      "Procesando tweet 483/1000\n",
      "Procesando tweet 484/1000\n",
      "Procesando tweet 485/1000\n",
      "Procesando tweet 486/1000\n",
      "Procesando tweet 487/1000\n",
      "Procesando tweet 488/1000\n",
      "Procesando tweet 489/1000\n",
      "Procesando tweet 490/1000\n",
      "Procesando tweet 491/1000\n",
      "Procesando tweet 492/1000\n",
      "Procesando tweet 493/1000\n",
      "Procesando tweet 494/1000\n",
      "Procesando tweet 495/1000\n",
      "Procesando tweet 496/1000\n",
      "Procesando tweet 497/1000\n",
      "Procesando tweet 498/1000\n",
      "Procesando tweet 499/1000\n",
      "Procesando tweet 500/1000\n",
      "Procesando tweet 501/1000\n",
      "Procesando tweet 502/1000\n",
      "Procesando tweet 503/1000\n",
      "Procesando tweet 504/1000\n",
      "Procesando tweet 505/1000\n",
      "Procesando tweet 506/1000\n",
      "Procesando tweet 507/1000\n",
      "Procesando tweet 508/1000\n",
      "Procesando tweet 509/1000\n",
      "Procesando tweet 510/1000\n",
      "Procesando tweet 511/1000\n",
      "Procesando tweet 512/1000\n",
      "Procesando tweet 513/1000\n",
      "Procesando tweet 514/1000\n",
      "Procesando tweet 515/1000\n",
      "Procesando tweet 516/1000\n",
      "Procesando tweet 517/1000\n",
      "Procesando tweet 518/1000\n",
      "Procesando tweet 519/1000\n",
      "Procesando tweet 520/1000\n",
      "Procesando tweet 521/1000\n",
      "Procesando tweet 522/1000\n",
      "Procesando tweet 523/1000\n",
      "Procesando tweet 524/1000\n",
      "Procesando tweet 525/1000\n",
      "Procesando tweet 526/1000\n",
      "Procesando tweet 527/1000\n",
      "Procesando tweet 528/1000\n",
      "Procesando tweet 529/1000\n",
      "Procesando tweet 530/1000\n",
      "Procesando tweet 531/1000\n",
      "Procesando tweet 532/1000\n",
      "Procesando tweet 533/1000\n",
      "Procesando tweet 534/1000\n",
      "Procesando tweet 535/1000\n",
      "Procesando tweet 536/1000\n",
      "Procesando tweet 537/1000\n",
      "Procesando tweet 538/1000\n",
      "Procesando tweet 539/1000\n",
      "Procesando tweet 540/1000\n",
      "Procesando tweet 541/1000\n",
      "Procesando tweet 542/1000\n",
      "Procesando tweet 543/1000\n",
      "Procesando tweet 544/1000\n",
      "Procesando tweet 545/1000\n",
      "Procesando tweet 546/1000\n",
      "Procesando tweet 547/1000\n",
      "Procesando tweet 548/1000\n",
      "Procesando tweet 549/1000\n",
      "Procesando tweet 550/1000\n",
      "Procesando tweet 551/1000\n",
      "Procesando tweet 552/1000\n",
      "Procesando tweet 553/1000\n",
      "Procesando tweet 554/1000\n",
      "Procesando tweet 555/1000\n",
      "Procesando tweet 556/1000\n",
      "Procesando tweet 557/1000\n",
      "Procesando tweet 558/1000\n",
      "Procesando tweet 559/1000\n",
      "Procesando tweet 560/1000\n",
      "Procesando tweet 561/1000\n",
      "Procesando tweet 562/1000\n",
      "Procesando tweet 563/1000\n",
      "Procesando tweet 564/1000\n",
      "Procesando tweet 565/1000\n",
      "Procesando tweet 566/1000\n",
      "Procesando tweet 567/1000\n",
      "Procesando tweet 568/1000\n",
      "Procesando tweet 569/1000\n",
      "Procesando tweet 570/1000\n",
      "Procesando tweet 571/1000\n",
      "Procesando tweet 572/1000\n",
      "Procesando tweet 573/1000\n",
      "Procesando tweet 574/1000\n",
      "Procesando tweet 575/1000\n",
      "Procesando tweet 576/1000\n",
      "Procesando tweet 577/1000\n",
      "Procesando tweet 578/1000\n",
      "Procesando tweet 579/1000\n",
      "Procesando tweet 580/1000\n",
      "Procesando tweet 581/1000\n",
      "Procesando tweet 582/1000\n",
      "Procesando tweet 583/1000\n",
      "Procesando tweet 584/1000\n",
      "Procesando tweet 585/1000\n",
      "Procesando tweet 586/1000\n",
      "Procesando tweet 587/1000\n",
      "Procesando tweet 588/1000\n",
      "Procesando tweet 589/1000\n",
      "Procesando tweet 590/1000\n",
      "Procesando tweet 591/1000\n",
      "Procesando tweet 592/1000\n",
      "Procesando tweet 593/1000\n",
      "Procesando tweet 594/1000\n",
      "Procesando tweet 595/1000\n",
      "Procesando tweet 596/1000\n",
      "Procesando tweet 597/1000\n",
      "Procesando tweet 598/1000\n",
      "Procesando tweet 599/1000\n",
      "Procesando tweet 600/1000\n",
      "Procesando tweet 601/1000\n",
      "Procesando tweet 602/1000\n",
      "Procesando tweet 603/1000\n",
      "Procesando tweet 604/1000\n",
      "Procesando tweet 605/1000\n",
      "Procesando tweet 606/1000\n",
      "Procesando tweet 607/1000\n",
      "Procesando tweet 608/1000\n",
      "Procesando tweet 609/1000\n",
      "Procesando tweet 610/1000\n",
      "Procesando tweet 611/1000\n",
      "Procesando tweet 612/1000\n",
      "Procesando tweet 613/1000\n",
      "Procesando tweet 614/1000\n",
      "Procesando tweet 615/1000\n",
      "Procesando tweet 616/1000\n",
      "Procesando tweet 617/1000\n",
      "Procesando tweet 618/1000\n",
      "Procesando tweet 619/1000\n",
      "Procesando tweet 620/1000\n",
      "Procesando tweet 621/1000\n",
      "Procesando tweet 622/1000\n",
      "Procesando tweet 623/1000\n",
      "Procesando tweet 624/1000\n",
      "Procesando tweet 625/1000\n",
      "Procesando tweet 626/1000\n",
      "Procesando tweet 627/1000\n",
      "Procesando tweet 628/1000\n",
      "Procesando tweet 629/1000\n",
      "Procesando tweet 630/1000\n",
      "Procesando tweet 631/1000\n",
      "Procesando tweet 632/1000\n",
      "Procesando tweet 633/1000\n",
      "Procesando tweet 634/1000\n",
      "Procesando tweet 635/1000\n",
      "Procesando tweet 636/1000\n",
      "Procesando tweet 637/1000\n",
      "Procesando tweet 638/1000\n",
      "Procesando tweet 639/1000\n",
      "Procesando tweet 640/1000\n",
      "Procesando tweet 641/1000\n",
      "Procesando tweet 642/1000\n",
      "Procesando tweet 643/1000\n",
      "Procesando tweet 644/1000\n",
      "Procesando tweet 645/1000\n",
      "Procesando tweet 646/1000\n",
      "Procesando tweet 647/1000\n",
      "Procesando tweet 648/1000\n",
      "Procesando tweet 649/1000\n",
      "Procesando tweet 650/1000\n",
      "Procesando tweet 651/1000\n",
      "Procesando tweet 652/1000\n",
      "Procesando tweet 653/1000\n",
      "Procesando tweet 654/1000\n",
      "Procesando tweet 655/1000\n",
      "Procesando tweet 656/1000\n",
      "Procesando tweet 657/1000\n",
      "Procesando tweet 658/1000\n",
      "Procesando tweet 659/1000\n",
      "Procesando tweet 660/1000\n",
      "Procesando tweet 661/1000\n",
      "Procesando tweet 662/1000\n",
      "Procesando tweet 663/1000\n",
      "Procesando tweet 664/1000\n",
      "Procesando tweet 665/1000\n",
      "Procesando tweet 666/1000\n",
      "Procesando tweet 667/1000\n",
      "Procesando tweet 668/1000\n",
      "Procesando tweet 669/1000\n",
      "Procesando tweet 670/1000\n",
      "Procesando tweet 671/1000\n",
      "Procesando tweet 672/1000\n",
      "Procesando tweet 673/1000\n",
      "Procesando tweet 674/1000\n",
      "Procesando tweet 675/1000\n",
      "Procesando tweet 676/1000\n",
      "Procesando tweet 677/1000\n",
      "Procesando tweet 678/1000\n",
      "Procesando tweet 679/1000\n",
      "Procesando tweet 680/1000\n",
      "Procesando tweet 681/1000\n",
      "Procesando tweet 682/1000\n",
      "Procesando tweet 683/1000\n",
      "Procesando tweet 684/1000\n",
      "Procesando tweet 685/1000\n",
      "Procesando tweet 686/1000\n",
      "Procesando tweet 687/1000\n",
      "Procesando tweet 688/1000\n",
      "Procesando tweet 689/1000\n",
      "Procesando tweet 690/1000\n",
      "Procesando tweet 691/1000\n",
      "Procesando tweet 692/1000\n",
      "Procesando tweet 693/1000\n",
      "Procesando tweet 694/1000\n",
      "Procesando tweet 695/1000\n",
      "Procesando tweet 696/1000\n",
      "Procesando tweet 697/1000\n",
      "Procesando tweet 698/1000\n",
      "Procesando tweet 699/1000\n",
      "Procesando tweet 700/1000\n",
      "Procesando tweet 701/1000\n",
      "Procesando tweet 702/1000\n",
      "Procesando tweet 703/1000\n",
      "Procesando tweet 704/1000\n",
      "Procesando tweet 705/1000\n",
      "Procesando tweet 706/1000\n",
      "Procesando tweet 707/1000\n",
      "Procesando tweet 708/1000\n",
      "Procesando tweet 709/1000\n",
      "Procesando tweet 710/1000\n",
      "Procesando tweet 711/1000\n",
      "Procesando tweet 712/1000\n",
      "Procesando tweet 713/1000\n",
      "Procesando tweet 714/1000\n",
      "Procesando tweet 715/1000\n",
      "Procesando tweet 716/1000\n",
      "Procesando tweet 717/1000\n",
      "Procesando tweet 718/1000\n",
      "Procesando tweet 719/1000\n",
      "Procesando tweet 720/1000\n",
      "Procesando tweet 721/1000\n",
      "Procesando tweet 722/1000\n",
      "Procesando tweet 723/1000\n",
      "Procesando tweet 724/1000\n",
      "Procesando tweet 725/1000\n",
      "Procesando tweet 726/1000\n",
      "Procesando tweet 727/1000\n",
      "Procesando tweet 728/1000\n",
      "Procesando tweet 729/1000\n",
      "Procesando tweet 730/1000\n",
      "Procesando tweet 731/1000\n",
      "Procesando tweet 732/1000\n",
      "Procesando tweet 733/1000\n",
      "Procesando tweet 734/1000\n",
      "Procesando tweet 735/1000\n",
      "Procesando tweet 736/1000\n",
      "Procesando tweet 737/1000\n",
      "Procesando tweet 738/1000\n",
      "Procesando tweet 739/1000\n",
      "Procesando tweet 740/1000\n",
      "Procesando tweet 741/1000\n",
      "Procesando tweet 742/1000\n",
      "Procesando tweet 743/1000\n",
      "Procesando tweet 744/1000\n",
      "Procesando tweet 745/1000\n",
      "Procesando tweet 746/1000\n",
      "Procesando tweet 747/1000\n",
      "Procesando tweet 748/1000\n",
      "Procesando tweet 749/1000\n",
      "Procesando tweet 750/1000\n",
      "Procesando tweet 751/1000\n",
      "Procesando tweet 752/1000\n",
      "Procesando tweet 753/1000\n",
      "Procesando tweet 754/1000\n",
      "Procesando tweet 755/1000\n",
      "Procesando tweet 756/1000\n",
      "Procesando tweet 757/1000\n",
      "Procesando tweet 758/1000\n",
      "Procesando tweet 759/1000\n",
      "Procesando tweet 760/1000\n",
      "Procesando tweet 761/1000\n",
      "Procesando tweet 762/1000\n",
      "Procesando tweet 763/1000\n",
      "Procesando tweet 764/1000\n",
      "Procesando tweet 765/1000\n",
      "Procesando tweet 766/1000\n",
      "Procesando tweet 767/1000\n",
      "Procesando tweet 768/1000\n",
      "Procesando tweet 769/1000\n",
      "Procesando tweet 770/1000\n",
      "Procesando tweet 771/1000\n",
      "Procesando tweet 772/1000\n",
      "Procesando tweet 773/1000\n",
      "Procesando tweet 774/1000\n",
      "Procesando tweet 775/1000\n",
      "Procesando tweet 776/1000\n",
      "Procesando tweet 777/1000\n",
      "Procesando tweet 778/1000\n",
      "Procesando tweet 779/1000\n",
      "Procesando tweet 780/1000\n",
      "Procesando tweet 781/1000\n",
      "Procesando tweet 782/1000\n",
      "Procesando tweet 783/1000\n",
      "Procesando tweet 784/1000\n",
      "Procesando tweet 785/1000\n",
      "Procesando tweet 786/1000\n",
      "Procesando tweet 787/1000\n",
      "Procesando tweet 788/1000\n",
      "Procesando tweet 789/1000\n",
      "Procesando tweet 790/1000\n",
      "Procesando tweet 791/1000\n",
      "Procesando tweet 792/1000\n",
      "Procesando tweet 793/1000\n",
      "Procesando tweet 794/1000\n",
      "Procesando tweet 795/1000\n",
      "Procesando tweet 796/1000\n",
      "Procesando tweet 797/1000\n",
      "Procesando tweet 798/1000\n",
      "Procesando tweet 799/1000\n",
      "Procesando tweet 800/1000\n",
      "Procesando tweet 801/1000\n",
      "Procesando tweet 802/1000\n",
      "Procesando tweet 803/1000\n",
      "Procesando tweet 804/1000\n",
      "Procesando tweet 805/1000\n",
      "Procesando tweet 806/1000\n",
      "Procesando tweet 807/1000\n",
      "Procesando tweet 808/1000\n",
      "Procesando tweet 809/1000\n",
      "Procesando tweet 810/1000\n",
      "Procesando tweet 811/1000\n",
      "Procesando tweet 812/1000\n",
      "Procesando tweet 813/1000\n",
      "Procesando tweet 814/1000\n",
      "Procesando tweet 815/1000\n",
      "Procesando tweet 816/1000\n",
      "Procesando tweet 817/1000\n",
      "Procesando tweet 818/1000\n",
      "Procesando tweet 819/1000\n",
      "Procesando tweet 820/1000\n",
      "Procesando tweet 821/1000\n",
      "Procesando tweet 822/1000\n",
      "Procesando tweet 823/1000\n",
      "Procesando tweet 824/1000\n",
      "Procesando tweet 825/1000\n",
      "Procesando tweet 826/1000\n",
      "Procesando tweet 827/1000\n",
      "Procesando tweet 828/1000\n",
      "Procesando tweet 829/1000\n",
      "Procesando tweet 830/1000\n",
      "Procesando tweet 831/1000\n",
      "Procesando tweet 832/1000\n",
      "Procesando tweet 833/1000\n",
      "Procesando tweet 834/1000\n",
      "Procesando tweet 835/1000\n",
      "Procesando tweet 836/1000\n",
      "Procesando tweet 837/1000\n",
      "Procesando tweet 838/1000\n",
      "Procesando tweet 839/1000\n",
      "Procesando tweet 840/1000\n",
      "Procesando tweet 841/1000\n",
      "Procesando tweet 842/1000\n",
      "Procesando tweet 843/1000\n",
      "Procesando tweet 844/1000\n",
      "Procesando tweet 845/1000\n",
      "Procesando tweet 846/1000\n",
      "Procesando tweet 847/1000\n",
      "Procesando tweet 848/1000\n",
      "Procesando tweet 849/1000\n",
      "Procesando tweet 850/1000\n",
      "Procesando tweet 851/1000\n",
      "Procesando tweet 852/1000\n",
      "Procesando tweet 853/1000\n",
      "Procesando tweet 854/1000\n",
      "Procesando tweet 855/1000\n",
      "Procesando tweet 856/1000\n",
      "Procesando tweet 857/1000\n",
      "Procesando tweet 858/1000\n",
      "Procesando tweet 859/1000\n",
      "Procesando tweet 860/1000\n",
      "Procesando tweet 861/1000\n",
      "Procesando tweet 862/1000\n",
      "Procesando tweet 863/1000\n",
      "Procesando tweet 864/1000\n",
      "Procesando tweet 865/1000\n",
      "Procesando tweet 866/1000\n",
      "Procesando tweet 867/1000\n",
      "Procesando tweet 868/1000\n",
      "Procesando tweet 869/1000\n",
      "Procesando tweet 870/1000\n",
      "Procesando tweet 871/1000\n",
      "Procesando tweet 872/1000\n",
      "Procesando tweet 873/1000\n",
      "Procesando tweet 874/1000\n",
      "Procesando tweet 875/1000\n",
      "Procesando tweet 876/1000\n",
      "Procesando tweet 877/1000\n",
      "Procesando tweet 878/1000\n",
      "Procesando tweet 879/1000\n",
      "Procesando tweet 880/1000\n",
      "Procesando tweet 881/1000\n",
      "Procesando tweet 882/1000\n",
      "Procesando tweet 883/1000\n",
      "Procesando tweet 884/1000\n",
      "Procesando tweet 885/1000\n",
      "Procesando tweet 886/1000\n",
      "Procesando tweet 887/1000\n",
      "Procesando tweet 888/1000\n",
      "Procesando tweet 889/1000\n",
      "Procesando tweet 890/1000\n",
      "Procesando tweet 891/1000\n",
      "Procesando tweet 892/1000\n",
      "Procesando tweet 893/1000\n",
      "Procesando tweet 894/1000\n",
      "Procesando tweet 895/1000\n",
      "Procesando tweet 896/1000\n",
      "Procesando tweet 897/1000\n",
      "Procesando tweet 898/1000\n",
      "Procesando tweet 899/1000\n",
      "Procesando tweet 900/1000\n",
      "Procesando tweet 901/1000\n",
      "Procesando tweet 902/1000\n",
      "Procesando tweet 903/1000\n",
      "Procesando tweet 904/1000\n",
      "Procesando tweet 905/1000\n",
      "Procesando tweet 906/1000\n",
      "Procesando tweet 907/1000\n",
      "Procesando tweet 908/1000\n",
      "Procesando tweet 909/1000\n",
      "Procesando tweet 910/1000\n",
      "Procesando tweet 911/1000\n",
      "Procesando tweet 912/1000\n",
      "Procesando tweet 913/1000\n",
      "Procesando tweet 914/1000\n",
      "Procesando tweet 915/1000\n",
      "Procesando tweet 916/1000\n",
      "Procesando tweet 917/1000\n",
      "Procesando tweet 918/1000\n",
      "Procesando tweet 919/1000\n",
      "Procesando tweet 920/1000\n",
      "Procesando tweet 921/1000\n",
      "Procesando tweet 922/1000\n",
      "Procesando tweet 923/1000\n",
      "Procesando tweet 924/1000\n",
      "Procesando tweet 925/1000\n",
      "Procesando tweet 926/1000\n",
      "Procesando tweet 927/1000\n",
      "Procesando tweet 928/1000\n",
      "Procesando tweet 929/1000\n",
      "Procesando tweet 930/1000\n",
      "Procesando tweet 931/1000\n",
      "Procesando tweet 932/1000\n",
      "Procesando tweet 933/1000\n",
      "Procesando tweet 934/1000\n",
      "Procesando tweet 935/1000\n",
      "Procesando tweet 936/1000\n",
      "Procesando tweet 937/1000\n",
      "Procesando tweet 938/1000\n",
      "Procesando tweet 939/1000\n",
      "Procesando tweet 940/1000\n",
      "Procesando tweet 941/1000\n",
      "Procesando tweet 942/1000\n",
      "Procesando tweet 943/1000\n",
      "Procesando tweet 944/1000\n",
      "Procesando tweet 945/1000\n",
      "Procesando tweet 946/1000\n",
      "Procesando tweet 947/1000\n",
      "Procesando tweet 948/1000\n",
      "Procesando tweet 949/1000\n",
      "Procesando tweet 950/1000\n",
      "Procesando tweet 951/1000\n",
      "Procesando tweet 952/1000\n",
      "Procesando tweet 953/1000\n",
      "Procesando tweet 954/1000\n",
      "Procesando tweet 955/1000\n",
      "Procesando tweet 956/1000\n",
      "Procesando tweet 957/1000\n",
      "Procesando tweet 958/1000\n",
      "Procesando tweet 959/1000\n",
      "Procesando tweet 960/1000\n",
      "Procesando tweet 961/1000\n",
      "Procesando tweet 962/1000\n",
      "Procesando tweet 963/1000\n",
      "Procesando tweet 964/1000\n",
      "Procesando tweet 965/1000\n",
      "Procesando tweet 966/1000\n",
      "Procesando tweet 967/1000\n",
      "Procesando tweet 968/1000\n",
      "Procesando tweet 969/1000\n",
      "Procesando tweet 970/1000\n",
      "Procesando tweet 971/1000\n",
      "Procesando tweet 972/1000\n",
      "Procesando tweet 973/1000\n",
      "Procesando tweet 974/1000\n",
      "Procesando tweet 975/1000\n",
      "Procesando tweet 976/1000\n",
      "Procesando tweet 977/1000\n",
      "Procesando tweet 978/1000\n",
      "Procesando tweet 979/1000\n",
      "Procesando tweet 980/1000\n",
      "Procesando tweet 981/1000\n",
      "Procesando tweet 982/1000\n",
      "Procesando tweet 983/1000\n",
      "Procesando tweet 984/1000\n",
      "Procesando tweet 985/1000\n",
      "Procesando tweet 986/1000\n",
      "Procesando tweet 987/1000\n",
      "Procesando tweet 988/1000\n",
      "Procesando tweet 989/1000\n",
      "Procesando tweet 990/1000\n",
      "Procesando tweet 991/1000\n",
      "Procesando tweet 992/1000\n",
      "Procesando tweet 993/1000\n",
      "Procesando tweet 994/1000\n",
      "Procesando tweet 995/1000\n",
      "Procesando tweet 996/1000\n",
      "Procesando tweet 997/1000\n",
      "Procesando tweet 998/1000\n",
      "Procesando tweet 999/1000\n",
      "Procesando tweet 1000/1000\n",
      "✅ Análisis de sentimiento con Stanza añadido a todas las replies.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import stanza\n",
    "\n",
    "# Descargar el modelo español (solo la primera vez)\n",
    "stanza.download(\"es\")\n",
    "\n",
    "# Crear el pipeline\n",
    "nlp = stanza.Pipeline(\"es\", processors=\"tokenize,sentiment\", use_gpu=True)\n",
    "\n",
    "# Función para analizar con Stanza\n",
    "def analyze_with_stanza(text):\n",
    "    if not text.strip():\n",
    "        return {\"sentiment\": None}\n",
    "    doc = nlp(text)\n",
    "    sentiments = [{\"text\": s.text, \"sentiment\": s.sentiment} for s in doc.sentences]\n",
    "    overall_sentiment = round(sum(s[\"sentiment\"] for s in sentiments) / len(sentiments)) if sentiments else None\n",
    "    return {\"sentiment\": overall_sentiment, \"sentences\": sentiments}\n",
    "\n",
    "# Ruta del archivo de entrada\n",
    "input_path = \"spain/Completado/tweets_españoles_evaluados_completo.json\"\n",
    "\n",
    "# Cargar datos\n",
    "with open(input_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# Analizar solo replies y añadir sentiment_stanza\n",
    "for idx, item in enumerate(data, start=1):\n",
    "    print(f\"Procesando tweet {idx}/{len(data)}\")\n",
    "    for reply in item.get(\"replies\", []):\n",
    "        texto = reply.get(\"reply\", \"\")\n",
    "        resultado_stanza = analyze_with_stanza(texto)\n",
    "        reply[\"analysis\"][\"sentiment_stanza\"] = resultado_stanza  # Añadir al bloque analysis\n",
    "\n",
    "# Guardar el resultado enriquecido\n",
    "output_path = \"spain/Tweets_conversaciones_con_stanza.json\"\n",
    "with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(data, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "print(\"✅ Análisis de sentimiento con Stanza añadido a todas las replies.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cace5d88-5f86-457a-87e0-ece7e73ef2b5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
