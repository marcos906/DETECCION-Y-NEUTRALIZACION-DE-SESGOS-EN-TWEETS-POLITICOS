{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "156493a8-495f-4892-af80-a1e9cd809a7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” Variables seleccionadas (|d| > 0.1): ['Xwords', 'Xunique', 'Xmax_length', 'Xlength_3', 'Xstop', 'Xcharacter', 'Xcapital', 'Xpunctuation', 'Xword_par', 'Xchar_par', 'Xdet', 'Xprep', 'Xsing', 'Xplural', 'Xadv', 'Xnouns', 'Xconj', 'Xpast', 'Xhashtag', 'Xurl']\n",
      "\n",
      "ğŸ“¦ Fold 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 1 Â· Epoch 1: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:04<00:00, 10.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” Epoch 1 loss: 0.6918\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 1 Â· Epoch 2: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:04<00:00, 10.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” Epoch 2 loss: 0.6702\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 1 Â· Epoch 3: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:04<00:00, 10.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” Epoch 3 loss: 0.5892\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 1 Â· Epoch 4: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:04<00:00, 10.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” Epoch 4 loss: 0.4682\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 1 Â· Epoch 5: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:04<00:00, 10.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” Epoch 5 loss: 0.3538\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 1 Â· Epoch 6: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:04<00:00, 10.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” Epoch 6 loss: 0.2052\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 1 Â· Epoch 7: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:04<00:00, 10.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” Epoch 7 loss: 0.1408\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 1 Â· Epoch 8: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:04<00:00, 10.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” Epoch 8 loss: 0.1302\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 1 Â· Epoch 9: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:04<00:00, 10.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” Epoch 9 loss: 0.0688\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 1 Â· Epoch 10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:04<00:00, 10.39it/s]\n",
      "/tmp/ipykernel_3276282/2556984385.py:189: RuntimeWarning: coroutine 'Translator.translate' was never awaited\n",
      "  tweet_es = \"\"\n",
      "RuntimeWarning: Enable tracemalloc to get the object allocation traceback\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” Epoch 10 loss: 0.0553\n",
      "âœ… F1 Fold 1: 0.6631\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   izquierda       0.79      0.66      0.72       122\n",
      "     derecha       0.54      0.70      0.61        70\n",
      "\n",
      "    accuracy                           0.67       192\n",
      "   macro avg       0.67      0.68      0.66       192\n",
      "weighted avg       0.70      0.67      0.68       192\n",
      "\n",
      "\n",
      "ğŸ“¦ Fold 2/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 2 Â· Epoch 1: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:04<00:00, 10.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” Epoch 1 loss: 0.6939\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 2 Â· Epoch 2: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:04<00:00, 10.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” Epoch 2 loss: 0.6721\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 2 Â· Epoch 3: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:04<00:00, 10.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” Epoch 3 loss: 0.6080\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 2 Â· Epoch 4: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:04<00:00, 10.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” Epoch 4 loss: 0.4928\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 2 Â· Epoch 5: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:04<00:00, 10.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” Epoch 5 loss: 0.3845\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 2 Â· Epoch 6: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:04<00:00, 10.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” Epoch 6 loss: 0.2615\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 2 Â· Epoch 7: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:04<00:00, 10.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” Epoch 7 loss: 0.1827\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 2 Â· Epoch 8: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:04<00:00, 10.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” Epoch 8 loss: 0.1048\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 2 Â· Epoch 9: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:04<00:00, 10.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” Epoch 9 loss: 0.0933\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 2 Â· Epoch 10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:04<00:00, 10.35it/s]\n",
      "/tmp/ipykernel_3276282/2556984385.py:189: RuntimeWarning: coroutine 'Translator.translate' was never awaited\n",
      "  tweet_es = \"\"\n",
      "RuntimeWarning: Enable tracemalloc to get the object allocation traceback\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” Epoch 10 loss: 0.0660\n",
      "âœ… F1 Fold 2: 0.7172\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   izquierda       0.79      0.80      0.80       122\n",
      "     derecha       0.65      0.63      0.64        70\n",
      "\n",
      "    accuracy                           0.74       192\n",
      "   macro avg       0.72      0.72      0.72       192\n",
      "weighted avg       0.74      0.74      0.74       192\n",
      "\n",
      "\n",
      "ğŸ“¦ Fold 3/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 3 Â· Epoch 1: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:04<00:00, 10.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” Epoch 1 loss: 0.6947\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 3 Â· Epoch 2: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:04<00:00, 10.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” Epoch 2 loss: 0.6777\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 3 Â· Epoch 3: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:04<00:00, 10.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” Epoch 3 loss: 0.6285\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 3 Â· Epoch 4: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:04<00:00, 10.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” Epoch 4 loss: 0.5407\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 3 Â· Epoch 5: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:04<00:00, 10.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” Epoch 5 loss: 0.4138\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 3 Â· Epoch 6: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:04<00:00, 10.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” Epoch 6 loss: 0.2971\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 3 Â· Epoch 7: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:04<00:00, 10.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” Epoch 7 loss: 0.2082\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 3 Â· Epoch 8: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:04<00:00, 10.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” Epoch 8 loss: 0.1489\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 3 Â· Epoch 9: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:04<00:00, 10.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” Epoch 9 loss: 0.0763\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 3 Â· Epoch 10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:04<00:00, 10.34it/s]\n",
      "/tmp/ipykernel_3276282/2556984385.py:189: RuntimeWarning: coroutine 'Translator.translate' was never awaited\n",
      "  tweet_es = \"\"\n",
      "RuntimeWarning: Enable tracemalloc to get the object allocation traceback\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” Epoch 10 loss: 0.0479\n",
      "âœ… F1 Fold 3: 0.6511\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   izquierda       0.73      0.80      0.76       122\n",
      "     derecha       0.58      0.50      0.54        70\n",
      "\n",
      "    accuracy                           0.69       192\n",
      "   macro avg       0.66      0.65      0.65       192\n",
      "weighted avg       0.68      0.69      0.68       192\n",
      "\n",
      "\n",
      "ğŸ“¦ Fold 4/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 4 Â· Epoch 1: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:04<00:00, 10.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” Epoch 1 loss: 0.6913\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 4 Â· Epoch 2: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:04<00:00, 10.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” Epoch 2 loss: 0.6742\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 4 Â· Epoch 3: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:04<00:00, 10.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” Epoch 3 loss: 0.6040\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 4 Â· Epoch 4: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:04<00:00, 10.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” Epoch 4 loss: 0.4797\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 4 Â· Epoch 5: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:04<00:00, 10.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” Epoch 5 loss: 0.3511\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 4 Â· Epoch 6: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:04<00:00, 10.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” Epoch 6 loss: 0.2368\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 4 Â· Epoch 7: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:04<00:00, 10.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” Epoch 7 loss: 0.1560\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 4 Â· Epoch 8: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:04<00:00, 10.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” Epoch 8 loss: 0.0996\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 4 Â· Epoch 9: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:04<00:00, 10.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” Epoch 9 loss: 0.0634\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 4 Â· Epoch 10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:04<00:00, 10.36it/s]\n",
      "/tmp/ipykernel_3276282/2556984385.py:189: RuntimeWarning: coroutine 'Translator.translate' was never awaited\n",
      "  tweet_es = \"\"\n",
      "RuntimeWarning: Enable tracemalloc to get the object allocation traceback\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” Epoch 10 loss: 0.0291\n",
      "âœ… F1 Fold 4: 0.6380\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   izquierda       0.73      0.75      0.74       122\n",
      "     derecha       0.54      0.53      0.54        70\n",
      "\n",
      "    accuracy                           0.67       192\n",
      "   macro avg       0.64      0.64      0.64       192\n",
      "weighted avg       0.66      0.67      0.67       192\n",
      "\n",
      "\n",
      "ğŸ“¦ Fold 5/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 5 Â· Epoch 1: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:04<00:00, 10.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” Epoch 1 loss: 0.7002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 5 Â· Epoch 2: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:04<00:00, 10.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” Epoch 2 loss: 0.6803\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 5 Â· Epoch 3: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:04<00:00, 10.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” Epoch 3 loss: 0.6094\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 5 Â· Epoch 4: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:04<00:00, 10.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” Epoch 4 loss: 0.5107\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 5 Â· Epoch 5: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:04<00:00, 10.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” Epoch 5 loss: 0.3894\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 5 Â· Epoch 6: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:04<00:00, 10.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” Epoch 6 loss: 0.2871\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 5 Â· Epoch 7: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:04<00:00, 10.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” Epoch 7 loss: 0.1696\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 5 Â· Epoch 8: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:04<00:00, 10.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” Epoch 8 loss: 0.1150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 5 Â· Epoch 9: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:04<00:00, 10.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” Epoch 9 loss: 0.1215\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 5 Â· Epoch 10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [00:04<00:00, 10.35it/s]\n",
      "/tmp/ipykernel_3276282/2556984385.py:189: RuntimeWarning: coroutine 'Translator.translate' was never awaited\n",
      "  tweet_es = \"\"\n",
      "RuntimeWarning: Enable tracemalloc to get the object allocation traceback\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” Epoch 10 loss: 0.0635\n",
      "âœ… F1 Fold 5: 0.6790\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   izquierda       0.76      0.80      0.78       122\n",
      "     derecha       0.61      0.56      0.58        70\n",
      "\n",
      "    accuracy                           0.71       192\n",
      "   macro avg       0.68      0.68      0.68       192\n",
      "weighted avg       0.70      0.71      0.71       192\n",
      "\n",
      "\n",
      "ğŸ“Š F1 macro por fold: [0.6631, 0.7172, 0.6511, 0.638, 0.679]\n",
      "ğŸ F1 macro promedio final: 0.6697\n",
      "ğŸ“ Guardados 628 tweets claros en /home/jupyter-lquijano/marcos/ingleses/outputs/clear_tweets_ideology.json\n",
      "ğŸ”’ Guardado modelo completo en best_model.pt (fold 2, F1=0.7172)\n",
      "ğŸ’¾ Guardado StandardScaler en scaler.pkl\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "\"\"\"\n",
    "Fine-tuning multimodal RoBERTa + tabular para IDEOLOGY,\n",
    "guarda checkpoints por fold, guarda el mejor modelo y\n",
    "genera un JSON con los tweets que el modelo acierta con\n",
    "alta confianza (â‰¥ 0.80) incluyendo su traducciÃ³n automÃ¡tica al espaÃ±ol.\n",
    "\"\"\"\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ IMPORTS â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "import pathlib, json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import f1_score, classification_report\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from tqdm import tqdm\n",
    "\n",
    "from googletrans import Translator  # pip install googletrans==4.0.0-rc1\n",
    "from joblib import dump\n",
    "\n",
    "tr = Translator()\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ CONFIG â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "MODEL_NAME      = \"cardiffnlp/twitter-roberta-base\"\n",
    "TARGET          = \"age_group\"\n",
    "COHENS_D_FILE   = \"../cohens_d_completo.csv\"\n",
    "INPUT_CSV       = \"features_linguisticas_en_con_glove.csv\"\n",
    "\n",
    "BATCH_SIZE      = 16\n",
    "EPOCHS          = 10\n",
    "LR              = 1e-5\n",
    "FOLDS           = 5\n",
    "COHEN_THRESHOLD = 0.10\n",
    "CONF_TH         = 0.70\n",
    "\n",
    "ckpt_dir = pathlib.Path(\"checkpoints_age\")\n",
    "ckpt_dir.mkdir(exist_ok=True)\n",
    "out_dir = pathlib.Path(\"outputs_age\")\n",
    "out_dir.mkdir(exist_ok=True)\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ DATA â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "df = pd.read_csv(INPUT_CSV)\n",
    "cohen_df = pd.read_csv(COHENS_D_FILE)\n",
    "\n",
    "df = df[df[TARGET].isin([\"mayor\", \"menor\"])].copy()\n",
    "df[\"label\"] = df[TARGET].map({\"menor\": 0, \"mayor\": 1})\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ DATA â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "df = pd.read_csv(INPUT_CSV)\n",
    "cohen_df = pd.read_csv(COHENS_D_FILE)\n",
    "\n",
    "df = df[df[\"ideology\"].isin([\"izquierda\", \"derecha\"])].copy()\n",
    "df[\"label\"] = df[\"ideology\"].map({\"izquierda\": 0, \"derecha\": 1})\n",
    "\n",
    "selected_vars = cohen_df[\n",
    "    (cohen_df[\"target\"] == TARGET) &\n",
    "    (cohen_df[\"cohens_d\"].abs() > COHEN_THRESHOLD) &\n",
    "    (~cohen_df[\"variable\"].str.startswith(\"XWE-\"))\n",
    "][\"variable\"].unique().tolist()\n",
    "\n",
    "print(f\"ğŸ” Variables seleccionadas (|d| > {COHEN_THRESHOLD}): {selected_vars}\")\n",
    "\n",
    "text_col = \"clean_text\"\n",
    "assert text_col in df.columns, f\"{text_col} no estÃ¡ en el CSV\"\n",
    "df = df[[text_col, \"label\"] + selected_vars].dropna().reset_index(drop=True)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "df[selected_vars] = scaler.fit_transform(df[selected_vars])\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ DATASET â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "class MultiModalDataset(Dataset):\n",
    "    def __init__(self, texts, nums, labels):\n",
    "        self.texts = texts\n",
    "        self.nums = nums\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        enc = tokenizer(\n",
    "            self.texts[idx],\n",
    "            truncation=True, padding=\"max_length\", max_length=128,\n",
    "            return_tensors=\"pt\"\n",
    "        )\n",
    "        item = {k: v.squeeze() for k, v in enc.items()}\n",
    "        item[\"nums\"] = torch.tensor(self.nums[idx], dtype=torch.float32)\n",
    "        item[\"labels\"] = torch.tensor(self.labels[idx], dtype=torch.long)\n",
    "        return item\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ MODELO â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "class TransformerWithTabular(nn.Module):\n",
    "    def __init__(self, transformer_name, num_tabular_features):\n",
    "        super().__init__()\n",
    "        self.transformer = AutoModel.from_pretrained(transformer_name)\n",
    "        self.tabular_net = nn.Sequential(\n",
    "            nn.Linear(num_tabular_features, 64),\n",
    "            nn.ReLU(), nn.Dropout(0.2),\n",
    "            nn.Linear(64, 32)\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(768 + 32, 64),\n",
    "            nn.ReLU(), nn.Dropout(0.2),\n",
    "            nn.Linear(64, 2)\n",
    "        )\n",
    "\n",
    "    def forward(self, input_ids, attention_mask, nums):\n",
    "        out = self.transformer(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        cls_emb = out.last_hidden_state[:, 0]\n",
    "        tab_emb = self.tabular_net(nums)\n",
    "        combined = torch.cat([cls_emb, tab_emb], dim=1)\n",
    "        return self.classifier(combined)\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ TRAIN / EVAL â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "texts = df[text_col].tolist()\n",
    "features = df[selected_vars].values.astype(np.float32)\n",
    "labels = df[\"label\"].values\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "class_w = compute_class_weight(\"balanced\", classes=np.unique(labels), y=labels)\n",
    "weights_tensor = torch.tensor(class_w, dtype=torch.float32).to(device)\n",
    "\n",
    "skf = StratifiedKFold(n_splits=FOLDS, shuffle=True, random_state=42)\n",
    "f1_scores = []\n",
    "selected = []\n",
    "\n",
    "# inicializar mejor modelo\n",
    "best_f1 = 0.0\n",
    "best_state = None\n",
    "best_fold = None\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(skf.split(texts, labels), 1):\n",
    "    print(f\"\\nğŸ“¦ Fold {fold}/{FOLDS}\")\n",
    "    train_ds = MultiModalDataset([texts[i] for i in train_idx], features[train_idx], labels[train_idx])\n",
    "    val_ds = MultiModalDataset([texts[i] for i in val_idx], features[val_idx], labels[val_idx])\n",
    "    train_dl = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True)\n",
    "    val_dl = DataLoader(val_ds, batch_size=BATCH_SIZE)\n",
    "\n",
    "    model = TransformerWithTabular(MODEL_NAME, len(selected_vars)).to(device)\n",
    "    opt = torch.optim.AdamW(model.parameters(), lr=LR)\n",
    "    loss_fn = nn.CrossEntropyLoss(weight=weights_tensor)\n",
    "\n",
    "    model.train()\n",
    "    for epoch in range(1, EPOCHS + 1):\n",
    "        total_loss = 0\n",
    "        for batch in tqdm(train_dl, desc=f\"Fold {fold} Â· Epoch {epoch}\"):\n",
    "            input_ids = batch[\"input_ids\"].to(device)\n",
    "            attn = batch[\"attention_mask\"].to(device)\n",
    "            nums = batch[\"nums\"].to(device)\n",
    "            lbls = batch[\"labels\"].to(device)\n",
    "\n",
    "            logits = model(input_ids=input_ids, attention_mask=attn, nums=nums)\n",
    "            loss = loss_fn(logits, lbls)\n",
    "\n",
    "            opt.zero_grad()\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "            total_loss += loss.item()\n",
    "        print(f\"ğŸ” Epoch {epoch} loss: {total_loss/len(train_dl):.4f}\")\n",
    "\n",
    "    model.eval()\n",
    "    all_preds, all_lbls = [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for b, batch in enumerate(val_dl):\n",
    "            input_ids = batch[\"input_ids\"].to(device)\n",
    "            attn = batch[\"attention_mask\"].to(device)\n",
    "            nums = batch[\"nums\"].to(device)\n",
    "            lbls = batch[\"labels\"].to(device)\n",
    "\n",
    "            logits = model(input_ids=input_ids, attention_mask=attn, nums=nums)\n",
    "            probs = torch.softmax(logits, dim=1)\n",
    "            confs, preds = probs.max(dim=1)\n",
    "\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_lbls.extend(lbls.cpu().numpy())\n",
    "\n",
    "            for j in range(len(preds)):\n",
    "                if preds[j] == lbls[j] and confs[j] >= CONF_TH:\n",
    "                    idx_global = val_idx[b * BATCH_SIZE + j]\n",
    "                    tweet_en = texts[idx_global]\n",
    "                    try:\n",
    "                        tweet_es = tr.translate(tweet_en, dest=\"es\").text\n",
    "                    except Exception:\n",
    "                        tweet_es = \"\"\n",
    "\n",
    "                    selected.append({\n",
    "                        \"row\": int(idx_global),\n",
    "                        \"text_en\": tweet_en,\n",
    "                        \"text_es\": tweet_es,\n",
    "                        \"prob\": round(float(confs[j]), 4),\n",
    "                        \"pred\": int(preds[j]),\n",
    "                        \"true\": int(lbls[j]),\n",
    "                        \"fold\": fold\n",
    "                    })\n",
    "\n",
    "    f1 = f1_score(all_lbls, all_preds, average=\"macro\")\n",
    "    f1_scores.append(f1)\n",
    "    print(f\"âœ… F1 Fold {fold}: {f1:.4f}\")\n",
    "    print(classification_report(all_lbls, all_preds, target_names=[\"izquierda\", \"derecha\"]))\n",
    "\n",
    "    if f1 > best_f1:\n",
    "        best_f1 = f1\n",
    "        best_fold = fold\n",
    "        best_state = {\n",
    "            \"model_state\": model.state_dict(),\n",
    "            \"backbone\": MODEL_NAME,\n",
    "            \"selected_vars\": selected_vars\n",
    "        }\n",
    "\n",
    "    # checkpoint parcial\n",
    "    fold_ckpt = ckpt_dir / f\"fold{fold}\"\n",
    "    fold_ckpt.mkdir(exist_ok=True)\n",
    "    model.transformer.save_pretrained(fold_ckpt)\n",
    "    tokenizer.save_pretrained(fold_ckpt)\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ RESULTADOS FINALES â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "print(\"\\nğŸ“Š F1 macro por fold:\", [round(f, 4) for f in f1_scores])\n",
    "print(f\"ğŸ F1 macro promedio final: {np.mean(f1_scores):.4f}\")\n",
    "\n",
    "json_path = out_dir / \"clear_tweets_ideology.json\"\n",
    "with open(json_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(selected, f, ensure_ascii=False, indent=2)\n",
    "print(f\"ğŸ“ Guardados {len(selected)} tweets claros en {json_path.resolve()}\")\n",
    "\n",
    "# Guardar mejor modelo\n",
    "if best_state is not None:\n",
    "    torch.save(best_state, out_dir / \"best_model.pt\")\n",
    "    print(f\"ğŸ”’ Guardado modelo completo en best_model.pt (fold {best_fold}, F1={best_f1:.4f})\")\n",
    "\n",
    "# Guardar scaler\n",
    "dump(scaler, out_dir / \"scaler.pkl\")\n",
    "print(\"ğŸ’¾ Guardado StandardScaler en scaler.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c312dbf7-dcb4-48aa-a0ba-62928bc257d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“Š F1 macro por fold: [0.6631, 0.7172, 0.6511, 0.638, 0.679]\n",
      "ğŸ F1 macro promedio final: 0.6697\n",
      "ğŸ“ Guardados 628 tweets claros en /home/jupyter-lquijano/marcos/ingleses/outputs/clear_tweets_ideology.json\n",
      "ğŸ”’ Guardado modelo completo en best_model.pt (fold 2, F1=0.7172)\n",
      "ğŸ’¾ Guardado StandardScaler en scaler.pkl\n"
     ]
    }
   ],
   "source": [
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ RESULTADOS FINALES â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "print(\"\\nğŸ“Š F1 macro por fold:\", [round(f, 4) for f in f1_scores])\n",
    "print(f\"ğŸ F1 macro promedio final: {np.mean(f1_scores):.4f}\")\n",
    "out_dir    = pathlib.Path(\"outputs\")\n",
    "# ----------- JSON con tweets claros --------------\n",
    "json_path = out_dir / \"clear_tweets_ideology.json\"\n",
    "with open(json_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(selected, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "print(f\"ğŸ“ Guardados {len(selected)} tweets claros en {json_path.resolve()}\")\n",
    "\n",
    "# ----------- Guardar mejor modelo ---------------\n",
    "# Guardamos el mejor fold completo: arquitectura + pesos + vars\n",
    "torch.save(best_state, out_dir / \"best_model.pt\")\n",
    "print(f\"ğŸ”’ Guardado modelo completo en best_model.pt (fold {best_fold}, F1={best_f1:.4f})\")\n",
    "\n",
    "# ----------- Guardar scaler ---------------------\n",
    "from joblib import dump\n",
    "dump(scaler, out_dir / \"scaler.pkl\")\n",
    "print(\"ğŸ’¾ Guardado StandardScaler en scaler.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bd77f97-52aa-4a06-b950-5b1c98e5a2bd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
